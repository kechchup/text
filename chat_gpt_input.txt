\documentclass{ifacconf}

\usepackage{graphicx}      % include this line if your document contains figures
\usepackage{natbib}        % required for bibliography
%\usepackage{natbib}        % required for bibliography
%\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{braket}
%\usepackage{subcaption}
%\usepackage[superscript]{cite}
\usepackage{placeins}
\usepackage{siunitx}
%\usepackage{lineno,hyperref}
\usepackage{amsmath}                    % AMS Math package
\usepackage{graphicx}                    % EPS figures
\usepackage{epstopdf}                    % EPS to PDF
\usepackage[T1]{fontenc}                % For font encodings
\usepackage{float}                        % Float package for H option on fig float
%\usepackage{caption}                    % Use for captionof command
\usepackage{titlesec}                    % Change section headings
\usepackage{paracol}                    % (Easily) Split page into columns
%\usepackage{booktabs}                    % Publication style tables
%\usepackage[margin=1in]{geometry}        % Page margins
\usepackage{atbegshi}
\usepackage{url}
\setcounter{secnumdepth}{4}
\sloppy

%% Page size, margins
%\special{papersize=8.5in,11.0in}
%\topmargin -0.8in
%\oddsidemargin -0.2in
%\textwidth 7in
%\textheight 9.2in
%\footskip 0.75in
%\allowdisplaybreaks
%\providecommand{\keywords}[1]{\noindent\textit{Keywords:} #1}
\renewcommand{\refname}{Literature Cited}

% Theorem styles
\theoremstyle{plain}
\newtheorem{asm}{Assumption}
\newtheorem{Proposition}{Proposition}
%\newtheorem{thm}{Theorem}
%\newtheorem{cor}{Corollary}
%\newtheorem{lem}{Lemma}
%\newtheorem{rem}{Remark}
%\newtheorem{defn}{Definition}
\newtheorem{proof}{Proof}
\newtheorem{assump}{Assumption}

% Macros
\newcommand{\m}{\mathbb}
\providecommand{\keywords}[1]{\noindent\textit{Keywords:} #1}
\renewcommand{\refname}{Literature Cited}

% Operators
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\newcommand{\R}{\mathbb{R}}				% Real numbers
\newcommand{\sett}[1]{\mathbb{#1}}		% Set notation
\newcommand{\sr}{\Omega_{\rho}}			% Omega_{rho}
\newcommand{\sre}{\Omega_{\rho_e}}		% Omega_{rho_e}
\newcommand{\srarg}[1]{\Omega_{#1}}
%===============================================================================
\begin{document}
\begin{frontmatter}

\title{Actuator Cyberattack Handling Using Lyapunov-based Economic Model Predictive Control} 
% Title, preferably not more than 10 words.

\author[First]{Keshav Kasturi Rangan} 
\author[First]{Henrique Oyama} 
\author[First]{Helen Durand}

\address[First]{Department of Chemical Engineering and Materials Science, Wayne State University, Detroit, MI 48202 USA (e-mail: keshav@wayne.edu, hcoyama@wayne.edu, helen.durand@wayne.edu)}

\begin{abstract}               
	Cybersecurity has gained increasing interest as a consequence of the potential impacts of cyberattacks on profits and safety.  While attacks can affect various components of a plant, prior work from our group has focused on the impact of cyberattacks on control components such as process sensors and actuators and the development of detection strategies for cybersecurity derived from control theory.  In this work, we provide greater focus on actuator attacks; specifically, we extend a detection and control strategy previously applied for sensor attacks and based on an optimization-based control technique called Lyapunov-based economic model predictive control (LEMPC) to detect attacks 
	impacting the control action applied by the actuators when the state measurements provided to the controller are accurate.  Closed-loop stability guarantees are rigorously derived.  A continuous stirred tank reactor is simulated to elucidate aspects of the detection strategy proposed.
\end{abstract}
\begin{keyword}
	Nonlinear processes, model predictive control, cybersecurity, nonlinear control, actuators
\end{keyword}

\end{frontmatter}
%===============================================================================

\section{Introduction}
Smart/next-generation manufacturing, which can lead to an increase in automation, enhanced safety, and greater operational efficiency, has received increasing attention in recent years.  Due to its criticality, cybersecurity of control systems has been an active research area, with research covering topics ranging from control for linear systems in the presence of actuator or sensor attacks~\cite{fawzi2014secure} to using optimization to predict attack behavior~\cite{vamvoudakis2013formulating}.  One of the topics that has received attention is active cyberattack detection schemes which attempt to force cyberattacks to become visible through changes to the system or operating policy.  Examples of strategies in this category have included dynamic watermarking~\cite{satchidanandan2016dynamic}, adjusting process dynamics~\cite{teixeira2012revealing}, or watermarking measurement and input signals~\cite{ghaderi2020blended}.

This work uses a type of model predictive control (MPC) design called Lyapunov-based economic model predictive control (LEMPC)~\cite{Heidarinejad2012855}, which is a formulation with strong closed-loop stability and feasibility properties in the presence of sufficiently small bounded disturbances and measurement noise.  Other formulations that use LEMPC include machine learning detection strategies combined with LEMPC and implemented in both centralized~\cite{chen2020cyber} and distributed~\cite{chen2021cyber} fashions for maintaining closed-loop stability during normal process operation, with the possibility of maintaining closed-loop stability after an attack.  Our group has analyzed cybersecurity for control systems from a nonlinear systems perspective~\cite{durand2018nonlinear}.  This led to  the development of detection strategies for handling sensor measurement cyberattacks with safety guarantees for scenarios when process dynamics are constant~\cite{oyama2020integrated} as well as when they are changing over time~\cite{rangan2021integrated,oyama2021handling}.  While our recent work~\cite{oyama2022} addressed multiple detection strategies to handle simultaneous cyberattacks on both process sensors and actuators, this work did not provide a thorough discussion of attack detection for the case of actuator attacks only.  Motivated by this gap, this work will provide details with an in-depth discussion of an LEMPC-based strategy for handling actuator attacks on nonlinear systems with guaranteed safety in the presence of undetected attacks.


%is an attractive control law for use in next-generation manufacturing due to its ability to select control actions for a process which optimize an objective function subject to constraints, and it therefore is an important control law to explore from a cyberattack-resilience perspective.  A variant of MPC known as economic model predictive control (EMPC)~\cite{Ellis20141156,Rawlings20123851} utilizes a potentially economics-based objective function in the controller optimization problem, which makes this control law interesting for next-generation manufacturing applications.  The question of how to secure processes operated under EMPC has received attention in the context of 

% This paper is organized such that after presenting preliminaries which cover topics in nonlinear systems theory and LEMPC, a detection algorithm for actuator cyberattacks based on LEMPC is presented in which components of the LEMPC are updated while following state trajectories for which it is known that a Lyapunov function must decrease over time in accordance to the detection strategy.  This strategy will be demonstrated to prevent safety issues when attacks are not detected.  In addition, a process example that showcases some of the limitations of the strategy from a profit analysis standpoint is discussed. 

\section{Preliminaries}

\subsection{Notation}
The Euclidean norm of a vector $x$ is denoted by $|\cdot|$, and the transpose of $x$ is denoted by $x^T$.  A class $\mathcal{K}$ function $\alpha : [0,a) \rightarrow [0,\infty)$ is strictly increasing with $\alpha(0) = 0$.  Set subtraction is signified by `` / '' such that $x \in A / B := \{ x\in R^n : x\in A, x \notin B\}$.  A level set of a positive definite function $V$ is denoted by $\Omega_{\rho} := \{ x\in R^n : V(x) \leq \rho \}$.  $\mathbb{R}_{+}$ signifies the set of non-negative real numbers.  A state measurement is available at every $t_k := k \Delta$, where $k=0,1,\ldots$, where $\Delta$ is the sampling period.

% Process state measurements are assumed to be available synchronously and each is separated by a sampling period of length $\Delta$ 

\subsection{Class of Systems} \label{sec:ClassOfSystems}

This work addresses systems of the form:
\begin{equation} \label{eq:ClassofSystems}
	\begin{aligned}
		\dot{x}(t)= f(x(t),u(t),w(t)) 
	\end{aligned}
\end{equation}
where $x \in X \subset \mathbb{R}^n$, $u \in U \subset \mathbb{R}^m$, and $w \in W \subset \mathbb{R}^z$ are the state, input, and disturbance vectors, respectively, and $f$ is locally Lipschitz on $X \times U \times W$, and $W := \{ w \in \mathbb{R}^{z} : |w| \le \theta_{w}, \theta_{w} > 0 \}$.  It is assumed that there exists a sufficiently smooth Lyapunov function $V: \mathbb{R}^n \rightarrow \mathbb{R}_{+}$, functions $\alpha_{j}(\cdot)$, $j=1,\ldots,4$, of class $\mathcal{K}$, and a controller $h(x) = [\bar{h}_{1}(x)~\ldots~\bar{h}_{m}(x)]^T$ capable of asymptotically stabilizing the closed-loop system to the origin of Eq.~\ref{eq:ClassofSystems} in the absence of disturbances such that the following inequalities are satisfied:
\begin{subequations} \label{eq:LyapunovConstraints}
	\begin{align}
		&\alpha_{1} (|x|) \le V(x) \le \alpha_{2} (|x|) \label{eq:constraintsLyapunov1} \\
		&\frac {\partial V(x)} {\partial x} \; f (x,h(x),0) \le -\alpha_{3}(|x|) \label{eq:constraintsLyapunov2} \\
		&\biggl|\frac {\partial V(x)} {\partial x} \biggl| \le \alpha_{4}(|x|) \label{eq:constraintsLyapunov3} \\
		&h(x) \in U \label{eq:constraintsLyapunov4}
	\end{align}
\end{subequations}

$\forall x\in D \subset \mathbb{R}^n$ and $D$ is an open neighborhood of the origin. $\Omega_{\rho} \subset D$ is considered to be the stability region of the nominal closed-loop system under the controller $h(x)$ where $x \in X$,  $\forall x \in \Omega_{\rho} $.  Furthermore, we consider that the components of $h(x)$ satisfy:
\begin{equation}
	|\bar{h}_{i}(x) - \bar{h}_{i}(\hat{x})| \leq L_h|x - \hat{x}| \label{eq:Lipschitzh}
\end{equation}
for all $x,\hat{x} \in \Omega_{\rho}$, $i = 1,\ldots,m$, and $L_h>0$.  The smoothness of $V$ and local Lipschitz property of $f$ give:
\begin{subequations} 
	\label{eq:Lipschitz}
	\begin{align}
		&|f(x_1,u_1,w) - f(x_2,u_2,0)| \nonumber \\
		& \qquad \qquad \le L_x |x_1 - x_2| + L_u|u_1 - u_2| + L_w |w| \label{eq:Lipschitz1}\\
		&\biggl|\frac {\partial V(x_1)} {\partial x} \; f ({x_1},u,w) - \frac {\partial V(x_2)} {\partial x} \; f ({x_2},u,0)\biggl| \nonumber \\
		& \qquad \qquad \le L_{x}' |x_1 - x_2| + L_{w}'|w| 	\label{eq:Lipschitz2} 
	\end{align}
\end{subequations}
\begin{equation}
	|f(x,u,w)| \le M_f \label{eq:FBound}
\end{equation}
$ \forall x_1,x_2 \in \Omega_{\rho}$, $u, u_1, u_2 \in U$ and $w \in W$, where $L_x, L_{x}', L_{u}, L_{w},$ $ L_{w}'$, and $M_f$ are positive constants.

\subsection{Lyapunov-Based Economic Model Predictive Control (LEMPC)}  \label{sec:LEMPC_Formulation}

In this work, we utilize an optimization-based control design known as LEMPC~\cite{Heidarinejad2012855}, which is formulated as follows:
\begin{subequations} \label{eq:LEMPCEqn}
	\begin{align}
		\min_{u(t) \in S(\Delta)}\hspace{3mm} & \int_{t_k}^{t_{k+N}} L_{e}(\tilde{x}(\tau),u(\tau)) \, d\tau  \label{eq:LEMPCEqn:Objective} \\
		\text{s.t.} \hspace{3mm} & \dot{\tilde{x}}(t) = f(\tilde{x}(t),u(t),0)  \label{eq:LEMPCEqn:Model} \\
		& \tilde{x}(t_k) = x(t_k)  \label{eq:LEMPCEqn:Measurement} \\
		& \tilde{x}(t) \in X, \, \forall \, t \in [t_k, t_{k+N}) \label{eq:LEMPCEqn:StateConstraint}  \\
		& u(t) \in U, ~ \forall \, t \in [t_k, t_{k+N}) \label{eq:LEMPCEqn:InputConstraint}	\\
		& V(\tilde{x}(t)) \le \rho_{e},\; \; \forall \, t \in [t_k, t_{k+N}),  \nonumber \\
		& ~~~~~ \text {if}~ x(t_k) ~ \in ~\Omega_{\rho_{e}} \label{eq:LEMPCEqn:Constraint 1} \\
		& \frac{\partial V(x(t_k))} {\partial x}f({x}(t_k),u(t_k),0) \nonumber \\
		& \qquad \qquad \le \frac {\partial V(x(t_k))} {\partial x} \; f({x}(t_k),h(x(t_k)),0), \nonumber \\
		& ~~~~~ \text {if} \;\; x(t_k) \in \Omega_{\rho} / \Omega_{\rho_{e}} \label{eq:LEMPCEqn:Constraint 2}
	\end{align}
\end{subequations}

where $u(t) \in S(\Delta)$ signifies that the optimal solution is a piecewise-constant input vector.  $N$ represents the length of the prediction horizon in terms of sampling periods, where each sampling period is of length $\Delta$.  The objective function is the time-integral of the economic stage cost $L_e$ of Eq.~\ref{eq:LEMPCEqn:Objective}, evaluated throughout the prediction horizon.  The predictions $\tilde{x}(t)$ are obtained from the nominal model of Eq.~\ref{eq:LEMPCEqn:Model}.  The state and input constraints are given by Eqs.~\ref{eq:LEMPCEqn:StateConstraint}-\ref{eq:LEMPCEqn:InputConstraint} respectively.  The two Lyapunov-based stability constraints are given by Eqs.~\ref{eq:LEMPCEqn:Constraint 1} and~\ref{eq:LEMPCEqn:Constraint 2}. 

\section{Detecting and Handling Actuator Cyberattacks using LEMPC} \label{sec:Detection_Strategy1}

Cyberattacks on control systems pose a threat due to their ability to directly manipulate physical systems resulting in effects ranging from reduced profits to loss of life.  In our prior works~\cite{oyama2020integrated, rangan2021integrated}, three strategies were developed to detect cyberattacks on sensor measurements.  \cite{oyama2022} extended these to handle attacks on actuators and on sensors and actuators at the same time.  Because the focus of \cite{oyama2022} was on this simultaneous actuator and sensor attack case, less attention was given to discussing handling of attacks on process actuators alone.  In this manuscript, we provide further details on a detection strategy for the case that only actuators are attacked. 

The strategy that will be analyzed in the subsequent sections is inspired by the first detection strategy presented in~\cite{oyama2020integrated} (developed for sensor measurement cyberattacks).  In~\cite{oyama2020integrated}, a detection strategy was developed that probes for attacks on sensors by modifying the control design in Eq.~\ref{eq:LEMPCEqn} at random times.  Specifically, at random times, a new steady-state is selected around which the LEMPC of Eq.~\ref{eq:LEMPCEqn} is designed (creating new Lyapunov functions around this steady-state designated by $V_i$ to reflect that they are designed with respect to the $i$-th steady-state), and then the constraint of Eq.~\ref{eq:LEMPCEqn:Constraint 2} is enforced throughout the subsequent sampling period (without Eq.~\ref{eq:LEMPCEqn:Constraint 1} being considered) to drive the closed-loop state toward that steady-state.  The motivation for this is that when Eq.~\ref{eq:LEMPCEqn:Constraint 2} is enforced, under sufficient conditions, the closed-loop state moves toward the $i$-th steady-state and $V_i$ decreases over the sampling period.  If it does not, an attack could be flagged.

When this strategy is extended to the case that actuators are attacked, we will no longer consider probing randomly, but instead will consider probing for attacks at every sampling time.  In the absence of an attack, this will cause $V_i$ to decrease, and the closed-loop state will be maintained within the stability region corresponding to the $i$-th steady-state.  However, unlike in the sensor cyberattack case, the sensor measurements are now considered to be accurate; this means that if $V_i$ does not actually decrease, an attack will be flagged. 
Though there is no guarantee that an attack cannot cause $V_i$ to decrease (i.e., an attack may be ``stealthy'' in the sense that it evades the detection mechanism based on $\dot{V}_i$ being negative), a decrease in the value of $V_i$ over a sampling period following the activation of the $i$-th LEMPC formulation under a rogue actuator signal sent to the process would still maintain the closed-loop state inside the $i$-th stability region under sufficient conditions.  This discussion implies that the $i$-th LEMPC formulation detection strategy holds particular value for handling actuator attacks when sensor measurements are not falsified.  Specifically, though a major drawback of the detection strategy presented in~\cite{oyama2020integrated} for state measurement cyberattacks is that it did not guarantee safety when a falsified state measurement is provided to the $i$-th LEMPC (because even if the falsified state measurements decrease $V_i$, it does not imply that these false sensor measurements are translated by the controller into stabilizing control actions), safety is maintained in the presence of actuator attacks under this strategy.  This is because the decrease in $V_i$ (which is based on the state measurements) is ``real'' in the case of the actuator attack (since the state measurements are not falsified), resulting in the actual closed-loop state remaining within a characterizable region $\Omega_{\rho_i}$ (a level set of $V_i$ around the $i$-th steady-state) of state-space over a sampling period when the attack is not detected.  
A consideration that must be made, however, is the impact that the constant probing for attacks could have on profits, since it causes the operating strategy to deviate from what would otherwise be observed.  One idea for attempting to handle this would be to make use of an auxiliary LEMPC with the form of Eq.~\ref{eq:LEMPCEqn}.  This LEMPC could be used at the start of every sampling period to predict the economically-optimal state at the end of the current sampling period (in the absence of plant-model mismatch, and subject to the prediction horizon length).  If this state is a steady-state for the process with the input in the input bounds (and meeting other sufficient conditions to be described below), it could be used as the $i$-th steady-state.  Though this may sound attractive as a means for attempting to reduce profit loss while handling actuator cyberattacks, profit guarantees cannot be made in the presence of plant/model mismatch, and if the closed-loop state does not reach this $i$-th steady-state in a sampling period, the state prediction from the LEMPC of Eq.~\ref{eq:LEMPCEqn} will be different than it would have been if the $i$-th steady-state had been reached.  The transient behavior over the sampling period also may not be the same during the probing as under the LEMPC of Eq.~\ref{eq:LEMPCEqn}.  This indicates that the use of the auxiliary LEMPC is unlikely to cause the profits during the probing to match those which would have been obtained without the cyberattack-probing.

\subsection{Probing for Actuator Cyberattacks Using LEMPC: Formulation} \label{sec:Formulation}


The LEMPC formed around the $i$-th steady-state (referred to as the $i$-th LEMPC) has the following form:
\begin{subequations} \label{eq:p-LEMPCEqn2}
	\begin{align}
		\min_{u_i(t) \in S(\Delta)}\hspace{3mm} & \int_{t_k}^{t_{k+N}} L_{e}(\tilde{x}_i(\tau),u_i(\tau)) \, d\tau  \label{eq:p-LEMPCEqn2:Objective} \\
		\text{s.t.} \hspace{3mm} & \dot{\tilde{x}}_i(t) = f_i(\tilde{x}_i(t),u_i(t),0) \label{eq:p-LEMPCEqn2:Model} \\
		& \tilde{x}_i(t_k) = {x}_{i}(t_k)  \label{eq:p-LEMPCEqn2:Measurement} \\
		& \tilde{x}_i(t) \in X_i, \, \forall \, t \in [t_k, t_{k+N}) \label{eq:p-LEMPCEqn2:StateConstraint}  \\
		& u_i(t) \in U_i, ~ \forall \, t \in [t_k, t_{k+N}) \label{eq:p-LEMPCEqn2:InputConstraint} \\
		& \frac{\partial V_i(\tilde{x}_i(t_k))} {\partial x} f_i(\tilde{x}_i(t_k),u_i(t_k),0) \nonumber \\
		& ~~~\le \frac{\partial V_i(\tilde{x}_i(t_k))} {\partial x} \;  f_i(\tilde{x}_i(t_k),h_i(\tilde{x}_i(t_k)),0)  \label{eq:p-LEMPCEqn2constraints:2}
		%& \quad \text {if} \;\; x(t_k) \in \Omega_{\rho,j} / \Omega_{\rho_{e,j}} ~ or ~ t_{s,i} 	\leq t_k \leq t_{e,i} \label{eq:p-LEMPCEqn1constraints:2}
	\end{align}
\end{subequations}
where ${x}_{i}(t_k)$ represents the state measurement in deviation variable form from the $i$-th steady-state, and $f_i$ represents the right-hand side of Eq.~\ref{eq:ClassofSystems} when it is written in deviation variable form from the $i$-th steady-state.  $u_i$ represents the input vector in deviation variable form from the steady-state input associated with the $i$-th steady-state.  $X_i$ and $U_i$ represent the state and control constraint sets in deviation variable form from the $i$-th steady-state.  When an actuator attack is performed, the control action computed by Eq.~\ref{eq:p-LEMPCEqn2} is not the one which is actually applied to the process. Rather, it is replaced by a rouge control action.

\subsection{Probing for Actuator Cyberattacks Using LEMPC: Implementation Strategy} \label{sec:Detection_Strategy1:Implementation}

The implementation strategy for the detection concept of Section~\ref{sec:Formulation} is described below (in the case that an attempt is made to use the auxiliary LEMPC of Eq.~\ref{eq:LEMPCEqn} to compute the $i$-th steady-state at every sampling time as described above):
\begin{enumerate}
	\item \label{step:Step0} An auxiliary LEMPC (``A-LEMPC'') with the form in Eq.~\ref{eq:LEMPCEqn} receives the state measurement $\tilde{x}(t_k)$ and is used to determine the steady-state to be used for the subsequent sampling period.  Go to Step~\ref{step:Step2}.
	
	\item \label{step:Step2} Verify that the $i$-th steady-state determined in Step~\ref{step:Step0} satisfies several conditions: 1) The $i$-th region $\Omega_{\rho_i}$ must be a subset of the safe operating region $\Omega_{\rho}$, designed to contain several level sets of $V_i$ to be described in the following section; 2) The steady-state input required to maintain the closed-loop state at the $i$-th steady-state must be within the input bounds; 3) The state measurement $\tilde{x}(t_k)$ must be contained within $\Omega_{\rho_i}$ (specifically, it must be within a subset $\Omega_{\rho_i'}$ to be defined in the following section; and 4) $\tilde{x}(t_k)$ must not be in a neighborhood $\Omega_{\rho_{s,i}}$ of the $i$-th steady-state.  If these requirements are not met for the steady-state determined in Step~\ref{step:Step0}, select an alternative steady-state meeting these requirements.  Go to Step~\ref{step:Step3}.	
	
% 	(where $\tilde{x}(t_k) \in \Omega_{\rho_{h,i}} \subset \Omega_{\rho_{i'}} \subset \Omega_{\rho_i} \subset \Omega_{\rho_{samp2,1}}$, where $\Omega_{\rho_{h,i}}$ is selected such that if the state measurement at $t_k$ is in $\Omega_{\rho_{h,i}}$ then the closed-loop state and the state measurement are maintained in $\Omega_{\rho_i}$ over the subsequent sampling period under sufficient conditions, and $\Omega_{\rho_{i'}}$ is selected so that if the state measurement is within $\Omega_{\rho_{h,i}}$, then the actual closed-loop state must be within $\Omega_{\rho_{i'}}$).  The $i$-th steady state must be such that $\tilde{x}(t_k)$ is not in a neighborhood $\Omega_{\rho_{s,i}} \subset \Omega_{\rho_{h,i}}$ of the $i$-th steady-state.
	
	\item \label{step:Step3} The control action computed by the $i$-th LEMPC of Eq.~\ref{eq:p-LEMPCEqn2} for the sampling period from $t_k$ to $t_{k+1}$ is used to control the process according to Eq.~\ref{eq:p-LEMPCEqn2}. Go to Step \ref{step:Step4}.
	
	\item \label{step:Step4} Evaluate the Lyapunov function value at the end of the sampling period. If $V_i$ does not decrease between the beginning and end of a sampling period, flag a potential cyberattack and apply mitigating actions.  Go to Step~\ref{step:Step5}.
	
	\item \label{step:Step5} ($t_k \leftarrow t_{k+1}$).   Go to Step \ref{step:Step0}.
\end{enumerate}

\subsection{Probing for Actuator Cyberattacks Using LEMPC: Stability and Feasibility Analysis}  \label{sec:Detection_Strategy1:Stability}

For the time period until an actuator attack is detected, this section will prove recursive feasibility of the A-LEMPC and the $i$-th LEMPC's for the process of Eq.~\ref{eq:ClassofSystems} under the implementation strategy of Section~\ref{sec:Detection_Strategy1:Implementation} in the presence of bounded process noise.
Because the state measurements are assumed not to be impacted by the attacks, the sensor measurements are impacted only by noise, where the maximum bound on the norm of the difference between the measured state and the actual state is $\theta_v$.
%(i.e., the $\max(\delta) := \theta_{v}$ in Proposition~\ref{prop:TrajectoryDifm}).
The theorem below also provides a guarantee of safety of the process of Eq.~\ref{eq:ClassofSystems} under the implementation strategy of Section~\ref{sec:Detection_Strategy1:Implementation} before an actuator cyberattack is detected (i.e., even if a stealthy attack is occurring).  In the following theorem, subscripts are added to some of the prior notation (e.g., the functions $\alpha_j$, $j=1,2,3,4$, and $h$, or the constants $M_f$, $L_x'$, and $L_w'$) to indicate that the functions and parameters are considered for the model and Lyapunov functions corresponding to the $i$-th steady-state or a steady-state of the A-LEMPC.

\begin{thm} \label{thm:DS1_Stability}
	Consider the closed-loop system of Eq. \ref{eq:ClassofSystems} under the implementation strategy of Section~\ref{sec:Detection_Strategy1:Implementation} where no cyberattack is detected, and each control formulation, i.e., the A-LEMPC and the $i$-th LEMPC, use controllers $h_A(\cdot)$ and $h_i(\cdot)$, $i \ge 1$, respectively, that satisfy the inequalities in Eqs. \ref{eq:constraintsLyapunov1}-\ref{eq:constraintsLyapunov4} and~\ref{eq:Lipschitzh}.  Let $\epsilon_{W_i} >0$, $\Delta >0$, $N \ge 1$, $\Omega_{\rho_i} \subset \Omega_{\rho_{A}'} \subset \Omega_{\rho_A} \subset X_A$ for $i \ge 1$, $\rho_i > \rho_{i}' > \rho_{\min,i} > \rho_{s,i} >  0$, where $\Omega_{\rho_{i}'}$ is defined as a level set of $\Omega_{\rho_i}$ that guarantees that if $V_i(\tilde{x}_{i}(t_k)) \leq \rho_{i}'$, then $V_i(x_{i}(t_k)) \leq \rho_{samp,i}$, for $i=A$ or $i\geq 1$.  Additionally, $\rho = \rho_A > \rho_{A}' > \rho_{e,A} > \rho_{\min,A} > \rho_{s,A} > 0$. Let the following inequalities be satisfied:

	\begin{equation} %Eq 19
		\begin{aligned}
			& -\alpha_{3,i}(\alpha_{2,i}^{-1}(\rho_{s,i})) + L'_{x,i} M_{f,i} \Delta + L'_{x,i}\theta_v + L'_{w,i}\theta_w \\ 
			& \qquad \qquad \leq -\epsilon_{w,i}'/\Delta, ~ i = A,1,2,\ldots \label{eq:Thm2Eq4b}
		\end{aligned}
	\end{equation}
	\begin{equation} %Eq 20
	\begin{aligned}
		\rho_{\min,i} & = \max\{V_i(x_{i}(t)): x_{i}(t_k) \in \Omega_{\rho_{s,i}}, t \in [t_k,t_{k+1}), \\
		& w \in W\}, ~ i = A,1,2,\ldots \label{eq:Thm2Eq6}
		\end{aligned}
	\end{equation}

	\begin{equation}
\begin{aligned}
& \epsilon_{w,i}'  > \max_{\tilde{x}_i(t_k) \in \Omega_{\rho_{i}'}/\Omega_{\rho_{s,i}}} \left| \min \{ V_i(\tilde{x}_i(t_k)) : \tilde{x}_i(t_k) \in \Omega_{\rho_{i}'}/\Omega_{\rho_{s,i}} \} \right. \\
 & \left. - \max \{ V_i(\tilde{x}_i(t_{k+1})) : \tilde{x}_i(t_{k}) \in \Omega_{\rho_{i}'}/\Omega_{\rho_{s,i}}, ~u_i \in U_i, \right.  \\
 & \left. w\in W, ~|x_i(t_p) - \tilde{x}_i(t_p)| \leq \theta_v,~p=k,k+1 \}\right|, i=A,1,2,\ldots  \label{eq:epswjbound}
\end{aligned}
\end{equation} 
\begin{equation}
    \begin{aligned}
        & \rho_{samp,i} = \max \{ V_i(x_i(t_k)) : \tilde{x}_i(t_k) \in \Omega_{\rho_i'}, i = A,1,2,\ldots, \\
        & |x_i(t_k) - \tilde{x}_i(t_k)| \leq \theta_v \} \label{eq:rhosampi}
    \end{aligned}
\end{equation}
\begin{equation}
    \begin{aligned}
        & \rho_{h,i} = \max \{ V_i(\tilde{x}_i(t_{k+1})) : x_i(t_k) \in \Omega_{\rho_{samp,i}}, i = A,1,2,\ldots, \\
        & u_i \in U_i, w\in W \} \label{eq:rhohi}
    \end{aligned}
\end{equation}
\begin{equation}
    \begin{aligned}
        & \rho_{i} = \max \{ V_i(x_i(t_{k+1})) : \tilde{x}_i(t_{k+1}) \in \Omega_{\rho_{h,i}}, \\
        & |x_i(t_{k+1}) - \tilde{x}_i(t_{k+1})| \leq \theta_v  \} \label{eq:rhoi}
    \end{aligned}
\end{equation}
	If $\tilde{x}_{i}(t_0) \in \Omega_{\rho_{i}'} / \Omega_{\rho_{s,i}}$, $x_{i}(t_0) \in \Omega_{\rho_{i}} \subset \Omega_{\rho_{A}'}$, $|\tilde{x}_{i}(t_0) - x_{i}(t_0)| \leq \theta_v$, and steady-states meeting the conditions in Step~\ref{step:Step2} of the implementation strategy are able to be found at every sampling time, then the closed-loop state and state measurement are maintained in $\Omega_{\rho_A}$ at all times before an attack is detected.  Furthermore, if $\tilde{x}_{i}(t_k) \in \Omega_{\rho_i'} / \Omega_{\rho_{s,i}}$ and no attack occurs, $V_i$ decreases along the measured state trajectory.
\end{thm}
\begin{pr}
	The proof consists of three parts.  In the first part, recursive feasibility of both Eq.~\ref{eq:LEMPCEqn} and Eq.~\ref{eq:p-LEMPCEqn2} at every sampling time under the implementation strategy is demonstrated. In the second part, we demonstrate that the state measurement remains within $\Omega_{\rho_i} \subset \Omega_{\rho_A}$ under the implementation strategy in Section~\ref{sec:Detection_Strategy1:Implementation} before an attack occurs or if an attack will not lead to detection at the next sampling time (allowing feasibility of the A-LEMPC and $i$-LEMPC's at each sampling time before an attack is detected), assuming that steady-states meeting the requirements in Step~\ref{step:Step2} of the implementation strategy can be located at every sampling time.  We also demonstrate that $V_i$ is decreasing for $t\in[t_k,t_{k+1})$ under the implementation strategy either in the absence of actuator attacks or in the presence of actuator attacks that do not lead to detection at the next sampling time.  The third part of the proof demonstrates that if detection will occur at the next sampling time, then the closed-loop state and state measurement will still be within $\Omega_{\rho_A}$ at that time.
	
	\textit{Part 1.} At each sampling time, the A-LEMPC is solved followed by the $i$-th LEMPC. Feasibility of the A-LEMPC at every sampling time is guaranteed when the state measurement is within $\Omega_{\rho_{A}}$ (to be demonstrated in \textit{Part 2}), with the feasible control action as $h_A$ implemented in sample-and-hold throughout the prediction horizon.  Specifically, $h_A(\tilde{x}_A(t_j))$, $j=k,\ldots,k+N-1$, for $t\in[t_j,t_{j+1})$, is a feasible solution to the A-LEMPC of Eq.~\ref{eq:LEMPCEqn} because it trivially satisfies Eq.~\ref{eq:LEMPCEqn:Constraint 2}, satisfies Eq.~\ref{eq:LEMPCEqn:StateConstraint} when $\Omega_{\rho_A} \subset X_A$, and satisfies Eq.~\ref{eq:LEMPCEqn:InputConstraint} by Eq.~\ref{eq:constraintsLyapunov4}. Similarly, this control action satisfies Eq.~\ref{eq:LEMPCEqn:Constraint 1} by the properties of the Lyapunov-based controller~\cite{de2008lyapunov} where, if the conditions of Eqs.~\ref{eq:Thm2Eq4b} and \ref{eq:Thm2Eq6} are met, then if $\tilde{x}_A(t_j) \in \Omega_{\rho_A}/\Omega_{\rho_{s,A}}$, $V_A(\tilde{x}_A)$ decreases throughout the following sampling period (keeping the closed-loop state in $\Omega_{\rho_A}$), or if $\tilde{x}_A(t_j) \in \Omega_{\rho_{s,A}}$, then  $\tilde{x}_A(t) \in \Omega_{\rho_{\min,A}} \subset \Omega_{\rho_A} $ for $t\in[t_j,t_{j+1})$.  By the same arguments, $h_i(\tilde{x}_i(t_j))$, $j=k,\ldots,k+N-1$, $t \in [t_j,t_{j+1})$, is a feasible solution to Eq.~\ref{eq:p-LEMPCEqn2} at every sampling time. 
	 
	\textit{Part 2.} To demonstrate that the closed-loop state and state measurement are always maintained within $\Omega_{\rho_i} \subset \Omega_{\rho_A}$ under the conditions of the theorem until a sampling time where an attack is performed that will be detected at the subsequent sampling time, we begin by examining $t_0$.  At $t_0$, from the statement of the theorem, $\tilde{x}_i(t_0) \in \Omega_{\rho_{i}'}$ (so that $x(t_0) \in \Omega_{\rho_{samp,i}} \subset \Omega_{\rho_A}$ from the implementation strategy and definition of $\Omega_{\rho_{i}'}$).  Eqs.~\ref{eq:p-LEMPCEqn2constraints:2} and Eq.~\ref{eq:constraintsLyapunov2} give:
	\begin{equation}
	\begin{aligned}
	& \frac{\partial V_i(\tilde{x}_{i}(t_0))}{\partial x}f_i(\tilde{x}_{i}(t_0),u_i(t_0),0)  \leq -\alpha_{3,i}(|\tilde{x}_{i}(t_0)|) \label{eq:ProofPart3}
	\end{aligned}
	\end{equation}
	Furthermore, defining:
	\begin{equation}
	\begin{aligned}
	&\dot{V}_i(x_{i}(\tau)) = \frac{\partial V_i(x_{i}(\tau))}{\partial x} f_i(x_{i}(\tau),u_i(t_0),w(\tau)) \\
	\end{aligned} \label{eq:Eq24}
	\end{equation}
	for $\tau \in [t_0,t_1)$, and adding and subtracting $\frac{\partial V_i(\tilde{x}_{i}(t_0))}{\partial x}f_i(\tilde{x}_{i}(t_0),u_i(t_0),0)$ from the right-hand side of Eq.~\ref{eq:Eq24}, applying the triangle inequality, Eq.~\ref{eq:ProofPart3}, Eq.~\ref{eq:FBound}, Eq.~\ref{eq:constraintsLyapunov1} and $\tilde{x}_{i}(t_0)\in \Omega_{\rho_i}' / \Omega_{\rho_{s,i}}$ gives:
	\begin{equation}
	    \begin{aligned}
	& \dot{V}_i(x_{i}(\tau)) \leq -\alpha_{3,i}(\alpha_{2,i}^{-1}(\rho_{s,i})) \\
	& \quad + L_{x,i}' M_{f,i} \Delta + L_{x,i}'\theta_v + L_{w,i}'\theta_w \label{eq:ProofCase2Eq3}
	\end{aligned}
	\end{equation}
	for $\tau \in [t_0,t_1)$.  When Eq.~\ref{eq:Thm2Eq4b} holds, this indicates that the Lyapunov function value for the actual closed-loop state will be less at the end of the sampling period than at the beginning, and thus $x_i(t_1) \in \Omega_{\rho_{samp,i}} \subset \Omega_{\rho_A}$.  However, because of measurement noise at the beginning and end of the sampling period, it does not guarantee that the measurement will decrease.  This is ensured, however, if Eq.~\ref{eq:epswjbound} holds, which enables the measured value of $V_i$ to decrease between two sampling periods and therefore to be used in detecting whether an attack occurs.  This also ensures that $\tilde{x}_i(t_1)$ is within $\Omega_{\rho_i'} \subset \Omega_{\rho_A}$.  
	
	Applying this recursively, it is demonstrated that when an attack will not be detected at the next sampling time, the closed-loop state measurement at the next sampling time will be within $\Omega_{\rho_i'}$ and the closed-loop state will be within $\Omega_{\rho_{samp,i}}$.  Specifically, at $t_1$, a new steady-state will be generated.  By the assumption of the theorem that it is possible to generate a new steady-state meeting the requirements of Step~\ref{step:Step2} of the implementation strategy, $\tilde{x}_i(t_1) \in \Omega_{\rho_i'} / \Omega_{\rho_{s,i}}$ for the new value of $i$ (and by the definition of $\Omega_{\rho_{samp,i}}$, $x_i(t_1) \in \Omega_{\rho_{samp,i}}$).  The same arguments as were applied at $t_0$ then continue to hold so that the closed-loop state is maintained within $\Omega_{\rho_{samp,i}}$ throughout the next sampling period, while the next state measurement is in $\Omega_{\rho_i'}$.  Finally, because the closed-loop state is maintained within each $\Omega_{\rho_i}$ before an attack that would be detected at the next sampling time occurs, it is also maintained in $\Omega_{\rho_A}$, guaranteeing feasibility of the A-LEMPC at every sampling time before an attack is detected.  Finally, without an attack detected at the next sampling time, $V_i$ must decrease or else the attack would be detected.
	
	\textit{Part 3.} Because an attack can only be detected at the end of a sampling period using the method in Section~\ref{sec:Detection_Strategy1:Implementation} because it is based on evaluating whether $V_i$ for the measurement at $t_{k+1}$ decreased compared to its value for the measurement at $t_k$, it is possible that an attack is not detected over the sampling period before an increase in $V_i$ is detected.  Eqs.~\ref{eq:rhosampi}-\ref{eq:rhoi} ensure that the closed-loop state and measurement are within $\Omega_{\rho_i} \subset \Omega_{\rho_{A}'}$ when the attack is detected.  Specifically, Eqs.~\ref{eq:rhosampi}-\ref{eq:rhohi} ensure that if the measurement at $t_k$ is within $\Omega_{\rho_i'}$, then the state measurement is within $\Omega_{\rho_{samp,i}}$ so that the measurement by $t_{k+1}$ could in a worst-case be within $\Omega_{\rho_{h,i}}$.  Since this measurement can have noise, Eq.~\ref{eq:rhoi} dictates that the farthest that the actual closed-loop state could be at $t_{k+1}$ when the measurement is within $\Omega_{\rho_{h,i}}$ is $\Omega_{\rho_i}$, and thus the actual and measured states are within $\Omega_{\rho_A}$.

\subsection{Probing for Actuator Cyberattacks Using LEMPC: Chemical Process Example} \label{sec:ProcessExample}

In this section, we present a process example to illustrate the concepts described above, but without ensuring that control-theoretic conditions are met (i.e., the designs are not verified to be resilient to cyberattacks, but serve to demonstrate aspects of the implementation strategy apart from the theory).  The example used is a continuous stirred tank reactor (CSTR) in which a second-order, irreversible, exothermic reaction $A \to B$ occurs.  The dynamics of the CSTR are as follows:
\begin{equation}
	\dot C_A = \frac{F}{V} (C_{A0}-C_A) -k_0 e^{-\frac{E}{R_gT}} C_A^2 \label{eq:ExampleSystem:Ca}
\end{equation}
\begin{equation}
	\dot T = \frac{F}{V} (T_{0}-T) -\frac{\Delta H k_0}{\rho_{L} C_p} e^{-\frac{E}{R_gT}}C_A^2 + \frac{Q}{\rho_{L} C_p V} \label{eq:ExampleSystem:T}
\end{equation}
Here, the state of the system is given by the reactant concentration of species $A$, $C_A$ and temperature in the reactor, $T$. The manipulated inputs are the reactant feed concentration of species $A$, $C_{A0}$, and the heat rate $Q$.  The values of the parameters used in the simulation are $V = 1m^3$, $T_0 = 300K$, $C_p = 0.231kJ/kg\cdot K$, $k_0 = 8.46\times 10^6m^3$/h\cdot$kmol$, $F = 5m^3/h$, $\rho_L = 1000kg/m^3$, $E = 5\times10^4kJ/kmol$, $R_g = 8.314kJ/kmol\cdot K$, $\Delta H = -1.15\times10^4kJ/kmol$. The vectors of the state and input of the process in deviation variable form are given by, $x_1 = [x_{1,1} ~ x_{1,2}]^T =  [C_A - C_{As}~ T - T_s]^T$ and $u_1 = [u_{1,1} ~ u_{1,2}]^T = [C_{A0} - C_{A0s} ~ Q - Q_s]^T$ where the steady-state values are $x_{1s} = [C_{As} ~ T_s]^T = [1.22~ \text{kmol/m}^3 ~ 438.2~\text{K}]^T$, $[C_{A0s} ~ Q_s]^T = [4.0~ \text{kmol/m}^3 ~ 0 ~\text{kJ/h}]^T$. The Explicit Euler method is used to numerically integrate the process model, Eqs.~\ref{eq:ExampleSystem:Ca}-\ref{eq:ExampleSystem:T}, by using an integration step of $10^{-4}$ h. The economic cost function is selected to be $L_e = k_0 e^{-E/(RT)} C_A^2$. 

We first demonstrate the concept that attacks can be undetected while decreasing the Lyapunov function when a constraint inspired by that in Eq.~\ref{eq:p-LEMPCEqn2constraints:2} is used.  We consider a case with no noise or disturbances (i.e., no plant/model mismatch).  For these simulations, $\Omega_{\rho_1}$ was developed using the Lyapunov function $V_1 = x_{1}^T P x_{1}$, where $P= [1200 ~5; 5~0.1]$, the Lyapunov-based controller $h_1(x_{1}) = [\bar{h}_{1,1}(x_{1}) ~ \bar{h}_{1,2}(x_{1})]^T$ with components $\bar{h}_{1,1}(x_{1})$ set to 0 kmol/m$^3$ and $\bar{h}_{1,2}(x_{1})$ designed via Sontag's control law~\cite{Lin1991393}, ${\rho_1} = 300$, and $\rho_{e,1} = 225$.  A second stability region $\Omega_{\rho_2}$ was also developed that is contained within $\Omega_{\rho_1}$.  A variety of methods could be used to obtain an alternative steady-state; here, no attempt was made to optimize economics, and a random alternative steady-state $x_{2s} = [1.22~$kmol/m$^3~450~$K$]^T$ was selected for the design of $\Omega_{\rho_2}$, where $V_2(x) = x_2^T P_2 x_2$, with $x_2 = x_1 + x_{1s} - x_{2s}$, $P_2= [2100 ~10; 10~0.25]$, and $\rho_2 = 100$.  The $i$-th LEMPC design using $\Omega_{\rho_2}$ was designed using a Lyapunov-based controller with components $h_{2,1}(x_{2}) = 0$ kmol/m$^3$ and $h_{2,2}(x_{2})$ selected using Sontag's control law with respect to $V_2(x_{2})$.  In each LEMPC, $N = 10$ and $\Delta=0.01$ h, and the value of the decision variable corresponding to $Q$ was scaled down by $10^5$.  The LEMPC optimization problems were solved in MATLAB using fmincon.

The process was initialized at the state $x_{1,init} = [x_{1,1}(t_0)~x_{1,2}(t_0)]^T = [-0.21$ kmol/m$^3$ 28.89 K$]^T$ (in deviation variable form from $x_{1s}$) and simulated over 0.1 h of operation under four different cases: 1) at $t_0$, the LEMPC used for probing was designed using the $i=1$ steady-state and $\Omega_{\rho_1}$ (i.e., the LEMPC of Eq.~\ref{eq:p-LEMPCEqn2} was used with $i=1$ and implemented by enforcing Eq.~\ref{eq:p-LEMPCEqn2constraints:2} at the end of the first sampling period), but the falsified input applied to the process in place of the LEMPC's input was a constant actuator output of $u_{1,1} = 0 $ kmol/m$^3$ and $u_{1,2} = 0~\text{kJ/h}$ (``Attack 1''); 2) at $t_0$, the LEMPC used for probing was designed using the $i=2$ steady-state and $\Omega_{\rho_2}$ with the falsified input of Attack 1; 3) at $t_0$, the LEMPC used for probing was designed using the $i=1$ steady-state and $\Omega_{\rho_1}$, but the falsified input applied to the process in place of the LEMPC's input was a constant actuator output of $u_{1,1} = 1.657 $ kmol/m$^3$ and $u_{1,2} = -1.141 \times 10^5~\text{kJ/h}$ (``Attack 2''); and 4) at $t_0$, the LEMPC used for probing was designed using the $i=2$ steady-state and $\Omega_{\rho_2}$ with the falsified input of Attack 2.  It can be observed in Fig.~\ref{fig:ActAttackSim} that under Attack 1, whether the value of $V_1$ or $V_2$ is evaluated over time, the attack would be flagged as the Lyapunov function increases over the subsequent sampling period. However, Attack 2 would not be detected by either of the two LEMPC formulations in that sampling period. 

  \begin{figure}
  	\centering
  	\includegraphics[width=1\columnwidth,clip]{fig/HenriquePartNoNoise.eps}
  	\caption{$V_1$ (top plots) and $V_2$ (bottom plots) profiles over 0.1 h of operation for the process example in the presence of different actuator cyberattack policies, with no plant/model mismatch.}
  	\label{fig:ActAttackSim}
  \end{figure}
  
We now consider attempting to use a control law in the spirit of LEMPC for developing the steady-state to track (instead of random steady-state selection).  In this case, the closed-loop system is again initialized from $x_{1,init}$, but a controller with a form inspired by Eq.~\ref{eq:LEMPCEqn} with $\tilde{x}(t_k)$ set to $x_{1,init}$ is solved.  The first control action is then used to simulate the closed-loop system in open-loop to investigate whether the state prediction at $t_{k+1}$ would serve as a suitable $x_{2s}$.  Even for this case where the control theory is not rigorously met, it would be required that for driving the closed-loop state to a neighborhood of a steady-state, that steady-state must be able to be reached with inputs within the input bounds.  In this case, however, the predicted state after a single sampling period is at $C_A = 1.016$ kmol/m$^3$ and $T = 491.52$ K, which would require an input outside of the input bounds to maintain the closed-loop state at this condition.  Therefore, though the closed-loop state prediction might pass through this condition, it would not be able to remain at it.  Various strategies might be considered at this point for selecting a new steady-state, such as exploring whether there are steady-states within a ball around the predicted state from the LEMPC that have the largest steady-state profit while meeting the input constraints.  However, as noted above, it would be challenging in general to make profit guarantees.

\section{Conclusion}
This work discusses an actuator cyberattack-handling procedure for next-generation manufacturing systems in the context of economic model predictive control.  Using a Lyapunov-based formulation of this control framework with guarantees on the decrease of the Lyapunov function over a sampling period following activation of a constraint in the controller, we developed a strategy for detecting actuator attacks.  The reformulation of the controller is performed in a manner that guarantees feasibility of both an auxiliary and reformulated LEMPC's at every sampling time, and also maintains the closed-loop state and state measurement within a characterizable region at all times when an attack is not detected (even in the presence of bounded measurement noise).

\begin{ack}
	Financial support from the National Science Foundation CNS-1932026 and Wayne State University is gratefully acknowledged.
\end{ack}

\bibliography{MLHazardBiblioCherd, AIChEJBib1Cherd,AIChEJBib2Cherd, DurandCPSBibCherd, DurandRealDBibCherd,MatlsBiblioCherd, MLHazardBib, MLHazardBiblio, MLHazardBiblioAct,   } % bib file to produce the bibliography % with bibtex (preferred) % in the appendices.
\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[numbers,12pt]{elsarticle}

%\usepackage[definethebibliography]{easybib}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{subcaption}
%\usepackage[superscript]{cite}
\usepackage{placeins}
\usepackage{siunitx}
%\usepackage{lineno,hyperref}
\usepackage{xcolor}
\usepackage{amsmath}                    % AMS Math package
\usepackage{graphicx}                    % EPS figures
\usepackage{epstopdf}                    % EPS to PDF
\usepackage[T1]{fontenc}                % For font encodings
\usepackage{float}                        % Float package for H option on fig float
\usepackage{caption}                    % Use for captionof command
\usepackage{titlesec}                    % Change section headings
\usepackage{paracol}                    % (Easily) Split page into columns
\usepackage{booktabs}                    % Publication style tables
\usepackage[margin=1in]{geometry}        % Page margins
\usepackage{atbegshi}
\setcounter{secnumdepth}{4}
%\setcitestyle{numbers}
\usepackage[superscript]{cite}
%\usepackage[super]{natbib}

% Page size, margins
\special{papersize=8.5in,11.0in}
\topmargin -0.8in
\oddsidemargin -0.2in
\textwidth 7in
\textheight 9.2in
\footskip 0.75in
\allowdisplaybreaks
\providecommand{\keywords}[1]{\noindent\textit{Keywords:} #1}
\renewcommand{\refname}{Literature Cited}

% Theorem styles
\theoremstyle{plain}
\newtheorem{asm}{Assumption}
\newtheorem{Proposition}{Proposition}
\newtheorem{thm}{Theorem}
\newtheorem{cor}{Corollary}
\newtheorem{lem}{Lemma}
\newtheorem{rem}{Remark}
\newtheorem{defn}{Definition}
\newtheorem{Proof}{Proof}
\newtheorem{assump}{Assumption}

% Macros
\newcommand{\m}{\mathbb}
\providecommand{\keywords}[1]{\noindent\textit{Keywords:} #1}
\renewcommand{\refname}{Literature Cited}

% Operators
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\newcommand{\R}{\mathbb{R}}				% Real numbers
\newcommand{\set}[1]{\mathbb{#1}}		% Set notation
\newcommand{\sr}{\Omega_{\rho}}			% Omega_{rho}
\newcommand{\sre}{\Omega_{\rho_e}}		% Omega_{rho_e}
\newcommand{\srarg}[1]{\Omega_{#1}}

\journal{Journal of Advanced Manufacturing and Processing}

\bibliographystyle{model2-names}

\begin{document}
	\baselineskip 24pt
	\titleformat{\paragraph}[runin]
	{\bfseries}
	{\theparagraph}
	{1em}
	{\addperiod}
	\titlespacing{\paragraph}{0pt}{0.5pt}{4pt}	
\begin{frontmatter}
		
		\author[mymainaddress]{Henrique Oyama}
		\author[mymainaddress]{Keshav Kasturi Rangan}
		\author[mymainaddress]{Helen Durand\corref{mycorrespondingauthor3}}\cortext[mycorrespondingauthor3]{Corresponding author: Tel: +1 (313) 577-3475; E-mail: helen.durand@wayne.edu.}
		\address[mymainaddress]{Department of Chemical Engineering and Materials Science, Wayne State University, Detroit, MI 48202.}

		\title{Handling of Stealthy Sensor and Actuator Cyberattacks on Evolving Nonlinear Process Systems}
	
	\begin{abstract}
		Cyberattacks on control systems in the chemical process industries cause concern regarding how they can impact finances, safety, and production levels of companies.  A key practical challenge for cyberattack detection and handling using process information is that process behavior evolves over time.  Conceivably, changes in process dynamics might cause some detection strategies to flag a change in the dynamics as an attack due to the new data appearing abnormal compared to data from before the dynamics changed.  In this work, we utilize several case studies to probe the question of what might be the impacts, benefits, and limitations of cyberattack detection and handling policies when the process dynamics change over time.  The goal of this work is to characterize, through simulation studies, characteristics which might be desirable and undesirable in cyberattack detection and handling procedures when process evolution is inevitable.  We demonstrate challenges with cyberattack detection when process dynamics change and subsequently, discuss two concepts for handling attacks - one which utilizes a two-tier detection strategy in which model re-identification is triggered when it is not clear whether an attack or a change in the process dynamics has occurred, and one in which control signals are injected at intervals by the actuators.  We utilize simulations to elucidate characteristics of these strategies and demonstrate that verifiability of attack-handling methods is key to their implementation (i.e., \textit{ad hoc} tuning has potential to leave vulnerabilities which an attacker might locate and exploit). 
		\end{abstract}	
	\end{frontmatter}

\section{Introduction}
Cyber-physical systems (CPS) combine control components, physical processes, and computer and communication networks to advance control implementation and process operability \cite{DING20181674}. In the industrial control system context, this may represent a step towards the next generation of manufacturing by connecting data collected across the production floor to the Internet \cite{lezzi2018}. While important advances in sensing, control, and wireless technologies can enhance manufacturing operations, cyberattacks take advantage of networked devices and systems and pose a consequent threat to the manufacturing industry \cite{Ren2017CyberSI}. The outcome of an attack could be disastrous, ranging from loss of product/production quality and excessive wear and tear on equipment to risks to the health and safety of human lives, which may have different intentions as examined in \cite{TUPTUK201893}. The vulnerabilities identified in CPS motivate the design of control/detection methodologies that are capable of signaling an attack when it happens and that respond quickly to the resulting abnormal process behavior in order to maintain safe operation.

In an attempt to prevent and mitigate cyberattacks, the cybersecurity literature has addressed several perspectives, which include vulnerability identification and assessment in cyber-physical/manufacturing systems (e.g., \cite{WU20183}), and detection mechanisms and countermeasures to deal with cyber threats (e.g.,~\cite{satchidanandan2017dynamic, pasqualetti2013attack}). Specifically for detecting and handling cyberattacks, \cite{satchidanandan2017dynamic} uses an active defense in which a private excitation superimposed onto the control policy is injected into the system to reveal malicious signal tampering. A variety of cyberattack scenarios are considered in \cite{pasqualetti2013attack} allowing the definition and notions of systems-theoretic monitoring limitations relative to attack identification. Stealthy attacks are threats in industrial control systems \cite{mclaughlin2016cybersecurity} and can be characterized according to \cite{teixeira2012revealing}, in which a stealthy attack cannot be flagged based on control inputs and measurement data. There has also been work on exploring cyberattack resilient control from a nonlinear systems perspective \cite{Durand2018169} and with equipment design considerations~\cite{durand2020mitigating}. In addition to CPS, cyberattack detection methods have been studied in other contexts such as power/smart grids \cite{karimipour2019deep} and automotive platforms \cite{taylor2018probing}.

Integrated cyberattack detection and advanced control methods using model predictive control (MPC \cite{Qin2003733}) also have been developed as an attempt to identify attacks while guaranteeing closed-loop stability even in the presence of cyberattacks~\cite{wu2020post, Wu20186}. In \cite{Wu20186}, a neural network-based detection method combined with a model predictive controller for nonlinear systems was designed to potentially detect sensor tampering. After the detection of cyberattacks, to retain control of the system and ensure safe operation, \cite{wu2020post} proposes a state reconstruction algorithm using machine learning methods based on the falsified state measurements. Moreover, cyberattack detection and MPC techniques with economics-based objective functions, named economic model predictive controllers (EMPC~\cite{ellis2014tutorial}), have been investigated in light of Lyapunov-based constraint properties (Lyapunov-based EMPC or LEMPC~\cite{Heidarinejad2012855}) to maintain closed-loop stability of the system, under sufficient conditions, both in the absence of and in the presence of cyberattacks \cite{Oyama072020}. 

Conditions under which cyberattack resilience can be guaranteed are important as part of the process of verifying safety of systems.  Consideration for changing process behavior over time can be important for guaranteeing safety in uncertain environments.  For example, theoretical conditions have been developed for guaranteeing safe operation in the presence of process dynamics changes for LEMPC \cite{durand2020responsive}. In \cite{Zhang2015}, to address model uncertainty and process dynamics anomalies, based on Lyapunov stability theory, data-driven modeling for an online adaptive learning controller was used with an upper bound on the detection time to flag problematic behavior due to model inaccuracies. In \cite{Alanqar2017b}, an LEMPC framework accounting for faults via online model updates was implemented based on a moving horizon error detector. A challenge for handling physical changes when cyberattacks on the sensors can occur is that it may be difficult to distinguish between the cyberattack and changes in the dynamics of the process when sensor measurements are used for detection of both.  

This work utilizes a chemical process example to probe a number of questions highlighted above.  Specifically, we discuss stealthy attacks on the process in Section~\ref{sec:defineDiscoverability}, and a two-tier detection concept for cases when attacks are performed on sensors in Section~\ref{sec:ChangingDyn}. In this concept, after initial detection thresholds are breached, it is unclear if an attack or a change in the process dynamics has occurred.  Subsequently, the detection thresholds are modified, and model re-identification occurs after data has been collected since the initial detection thresholds were breached.  The potential for this technique to maintain the closed-loop state within a safe operating region for a period of time after the potential model change or attack is detected is discussed through several case studies using the chemical process under different attacks and model changes. Finally, in Section~\ref{sec:ActuatorHandling}, actuator attack compensation using injected actuator signals at pre-specified intervals is investigated.

\section{Preliminaries} \label{sec:Preliminaries}
%\subsection{Notation}
%The Euclidean norm of a vector is denoted by $|\cdot|$.   A level set of a positive definite function $V$ is denoted by $\Omega_{\rho} := \{ x\in R^n : V(x) \leq \rho \}$.

%A class $\mathcal{K}$ function $\alpha : [0,a) \rightarrow [0,\infty)$ is strictly increasing with $\alpha(0) = 0$.
% The transpose of a vector $x$ is denoted by $x^T$.  Set subtraction is signified by `` / '' such that $x \in A / B := \{ x\in R^n : x\in A, x \notin B\}$. 
\subsection{Class of Nonlinear Empirical Systems} \label{sec:ClassOfSystems}

This work focuses on empirical models that sufficiently capture the dynamics of a nonlinear process, and which can be written as a system of nonlinear ordinary differential equations in the following form:
\begin{equation} \label{eq:f_NL}
\begin{aligned}
\dot{\bar{x}}_{b,q}(t)= \bar{f}_{NL,q} (\bar{x}_{b,q}(t),\bar{u}_q(t))
\end{aligned}
\end{equation}
where $\bar{f}_{NL,q}$ is a locally Lipschitz nonlinear vector function of its argument with $\bar{f}_{NL,q}(0,0) = 0$, and $\bar{x}_{b,q}\in \mathbb{R}^n $ and  $\bar{u}_q\in \mathbb{R}^m$ denote the state and input vectors, respectively, in deviation variable form from a steady-state at $x_{b,q,s}$ and $u_{q,s}$.  The subscript $q$ represents the $q$-th empirical model.  $U_q$ and $X_q$ are the allowable sets for the inputs and states when they are in deviation form from $u_{q,s}$ and $x_{b,q,s}$, respectively.  

We consider that for the $q$-th empirical model in Eq.~\ref{eq:f_NL}, there exists a locally Lipschitz explicit stabilizing controller $h_{NL,q}(\bar{x}_{b,q})$ that can render the origin asymptotically stable for all $\bar{x}_{b,q} \in D_{NL,q}$ (where $D_{NL,q}$ is a neighborhood of the origin of $\bar{f}_{NL,q}$ contained in $X_q$). We define $\Omega_{\hat{\rho}_q} \subset D_{NL,q}$ as the stability region of the system of Eq. \ref{eq:f_NL} under $h_{NL,q}$, and $\Omega_{\hat{\rho}_{safe,q}}$ as a superset of $\Omega_{\hat{\rho}_q}$ contained in $D_{NL,q}$ and $X_q$.  We also assume that the dynamics of the actual process (represented by $\dot{\bar{x}}_{a,i} = \bar{f}_i(\bar{x}_{a,i}(t),\bar{u}_i(t),w_i(t))$, where $\bar{f}_i(0,0,0) = 0$, the origin is at $\bar{x}_{b,q,s}$ and a corresponding steady-state value of the input, $\bar{f}_i$ is a locally Lipschitz nonlinear vector function of its arguments, $\bar{x}_{a,i} \in R^n$, $\bar{u}_i \in R^m$, and $w_i\in W_i \subset R^l$ denote the state, input, and disturbance vectors, respectively, where $W_i := \{ w_i \in R^l ~:~ |w_i| \leq \theta, ~ \theta > 0 \}$, for $i=1,2,\ldots$, and changes in the subscript $i$ reflect that the underlying process dynamics can change over time) are also stabilizable in the sense that there exists a controller that can asymptotically stabilize the origin for all $\bar{x}_{a,i} \in D_i$, where $D_{NL,q} \subseteq D_i$ for the $i$-th dynamics used while the $q$-th empirical model is used.  We also assume that there are $M$ sets of measurements $y_{p} \in R^{q_p}$, $p=1,\ldots,M$, available continuously as follows:
%(i.e., $v_{p} \in V_{p} :=\{ v_{p} \in R^{q_{p}} ~:~ |v_{p}| \leq \theta_{v,p},~\theta_{v,p} > 0$)
\begin{equation}
y_{p}(t) = k_{p}(\bar{x}_{a,i}(t)) + v_{p}(t) \label{eq:Measurementi}
\end{equation}
where $k_{p}$ is a vector-valued function, and $v_{p}$ represents the measurement noise associated with the measurements $y_{p}$.  We assume that the measurement noise is bounded and for each of the $M$ sets of measurements when the $q$-th empirical model is used, a deterministic observer exists. When a controller $h_{NL,q}(z_{p,q})$ is used to control the closed-loop system of Eq.~\ref{eq:f_NL}, we assume that when there is sufficiently small plant/model mismatch, disturbances, and noise, the norm of the difference between the state estimate ($z_{p,q}$, $p=1,\ldots,M$) and the actual state becomes bounded after a certain time period, and for all initial conditions within a sufficiently conservative subset of $\Omega_{\hat{\rho}_{safe,q}}$, $h_{NL,q}(z_{p,q})$ maintains the closed-loop state within $\Omega_{\hat{\rho}_{safe,q}}$ for all $t \geq 0$.  An observer which can satisfy such assumptions under sufficient conditions is a high-gain observer~\cite{ahrens2009high}.

\subsection{Lyapunov-based Economic Model Predictive Control with Empirical Models}

This work utilizes an LEMPC~\cite{Heidarinejad2012855}, which is an optimization-based control design with an economics-based objective function, to control the nonlinear process. Specifically, this control formulation includes two constraints that guarantee that the closed-loop state can be maintained within the defined operating region $\Omega_{\hat{\rho}_q}$ over time when there is no model change, which is beneficial from the perspective of being able to guarantee safe operation in the sense of boundedness of the closed-loop state. In particular, this control law has the form:

\begin{subequations} \label{eq:LEMPCEmpirical}
	\begin{align}
	\min_{\bar{u}_q(t) \in S(\Delta)}\hspace{3mm} & \int_{t_k}^{t_{k+N}} [L_{e}(\bar{x}_{b,q}(\tau),\bar{u}_q(\tau))] d\tau \label{eq:LEMPCEmpirical:Obj}  \\
	\text{s.t.}\hspace{5mm} &  \dot{\bar{x}}_{b,q}= {\bar{f}_{NL,q}}(\bar{x}_{b,q}(t),\bar{u}_q(t)) \label{eq:LEMPCEmpirical:model} \\
	& \bar{x}_{b,q}(t_k) = x(t_k) \label{eq:LEMPCEmpirical:Measurement} \\
	& \bar{x}_{b,q}(t) \in X_q, \, \forall \, t \in [t_k, t_{k+N}) \label{eq:LEMPCEmpirical:XBound} \\
	& \bar{u}_q(t) \in U_q, ~ \forall \, t \in [t_k, t_{k+N}) \label{eq:LEMPCEmpirical:UBound} \\
	& \hat V_q(\bar{x}_{b,q}(t)) \le \hat{\rho}_{e,q},\; \; \forall \, t \in [t_k, t_{k+N})~~ \text{if}~~ x(t_k)~ \in~ \Omega_{{\hat{\rho}_ {e,q}}} \label{eq:LEMPCEmpirical:Constraint1}\\ 
	&\frac {\partial \hat V_q(x(t_k))} {\partial x} ( \bar{f}_{NL,q}({x}(t_k),\bar{u}_q(t_k))) \; \le \frac {\partial \hat V_q(x(t_k))} {\partial x} \;  (\bar{f}_{NL,q}({x}(t_k), h_{NL,q}(x(t_k)))) \; \;  \nonumber\\ 
	& \quad \quad \quad \quad \text{if} \;\; x(t_k) \notin \Omega_{\hat\rho_{e,q}} \text{or}~t_k \ge t' \label{eq:LEMPCEmpirical:Constraint2}
	\end{align}
\end{subequations}
where $L_e(\cdot,\cdot)$ represents a free-form stage cost that is optimized in Eq.~\ref{eq:LEMPCEmpirical} and $\hat{V}_q : \mathbb{R}^n \rightarrow \mathbb{R}_{+}$ represents a sufficiently smooth Lyapunov function.  The notation $\bar{u}_{q}(t)\in S(\Delta)$ signifies that $\bar{u}_q$ is a piecewise-constant input trajectory with period $\Delta$.  The prediction horizon is denoted by $N$.  $x(t_k)$ in Eq.~\ref{eq:LEMPCEmpirical:Measurement} signifies that the predicted state of the empirical model (Eq.~\ref{eq:LEMPCEmpirical:model}) at $t_k$ is equal to the measured state.  Eqs.~\ref{eq:LEMPCEmpirical:UBound} and~\ref{eq:LEMPCEmpirical:XBound} represent the input and state constraints, respectively.   $\Omega_{\hat{\rho}_{e,q}} \subset \Omega_{\hat{\rho}_q}$ is selected such that the closed-loop state is maintained within $\Omega_{\hat{\rho}_q}$ over time when the process of Eq.~\ref{eq:f_NL} is operated under the LEMPC of Eq.~\ref{eq:LEMPCEmpirical}.  $t'$ is a time after which the constraint of Eq.~\ref{eq:LEMPCEmpirical:Constraint2} is always applied, regardless of the value of $\hat{V}_q(x(t_k))$.  

\section{Handling of Stealthy Sensor and Actuator Cyberattacks on Evolving Nonlinear Process Systems}

For processes under MPC, when the dynamics of the process can change over time, the mismatch between the model used for making state predictions in the MPC and the actual dynamics increases.  Once the mismatch is large enough, the MPC may begin to compute control actions that might stabilize the dynamics of the system it is simulating, but might not stabilize the actual system dynamics or could lead to sub-optimal performance.  As a result, as the process dynamics change over time for a process under MPC, there may be a need to update the dynamic model of the system in the controller over time.  However, when cyberattacks can occur on sensors, attacks may create characteristics in process data that could be difficult to distinguish from changes in the process dynamics itself.  Therefore, both detection as well as handling of attacks must be analyzed for situations in which the process dynamics can evolve.  Furthermore, attacks may also occur on actuators themselves.  One idea for detecting this is to develop an expected mapping between the control signal that should be computed by an MPC for a given state measurement and the measured value of the actuator output.  These could be compared when sensor measurements are accurate to detect if there are any discrepancies which might indicate an attack.  However, actuator dynamics can also change over time (e.g., valves can develop stiction~\cite{durand2016actuator}), such that this method (which essentially again relies on accuracy of the process model unless the signals to the actuators themselves, rather than process variables like flow rates, are evaluated for closeness with expected values) could also fail in the presence of changing dynamics.  Therefore, in this section, we begin with discussion of the characteristics of attacks on the sensors and actuators which might bypass any reasonable detection strategy, elucidating through the discussion the complexities arising in detection when process dynamics can change over time.  Subsequently, we focus on the more restrictive assumption that only sensor measurement cyberattacks occur, and we utilize a process example to demonstrate how an example of an attack detection strategy might flag dynamics changes as attacks, and propose a strategy for preventing such false alarms while still providing a potential means for maintaining the closed-loop state in a safe operating region for at least some time period after either a dynamics change or an undetected attack occurs.  Next, we broaden our scope to examine actuator attacks, which force the process to ``drive blind,'' evaluating potential strategies for maintaining closed-loop stability of a nonlinear process in the presence of sensor and/or actuator attacks in this circumstance using pre-specified input injection by the actuators.  Throughout, we comment on what the results indicate about general techniques for attack-handling that go beyond the specific strategies exemplified here.

\subsection{Cyberattack Discoverability with Sensor and Actuator Hijacking} \label{sec:defineDiscoverability}

Before beginning to probe some of the issues which might occur for attack detection when process dynamics change, we begin by discussing the concept of ``stealthy'' cyberattacks in the context of the chemical process system we will be evaluating throughout.  Stealthy attacks have been discussed in prior works (e.g.,~\cite{Cardenas2011} defines a number of different types of stealthy attacks, which are those which fly under the radar of a detection scheme), and a notion of which attacks are able to be detected for certain systems has been defined theoretically in~\cite{pasqualetti2013attack}.  In the present manuscript, we call that concept ``discoverability'' of an attack (rather than ``detectability,'' which has been considered in the context of control more closely related to observability~\cite{moreno2012observability}), and discuss how a fundamental nonlinear systems perspective on this concept aids in showcasing why changes in the process dynamics can make it difficult to detect an attack.   

Detection of an attack is generally considered to imply that there is something abnormal in the process data that indicates that it is not coming from the actual process, but rather from malicious activity (depending on what is being monitored, however, it may not be possible to tell whether an attack is occurring).  If it is possible for a reasonable detection mechanism (i.e., one which does not flag normal disturbances as attacks) to distinguish any attack on the system, then the system is cyberattack discoverable.  For example, if the system $\dot{\bar{x}}_{a,i} = \bar{f}_i(\bar{x}_{a,i}(t),\bar{u}_i(t),w_i(t))$ is perfectly known and has no disturbance or measurement noise ($w_i = 0,v_p=0$), a cyberattack on the sensors of this system is cyberattack discoverable since any deviation of the measurement away from the state trajectory of the predicted value can be flagged by a cyberattack detection mechanism.  However, if there are disturbances and measurement noise, then though sensor measurement attacks might be detected if they are inconsistent with the potential set of state trajectories which might reasonably be developed under different realizations of the noise and disturbances, there are some attacks which would mimic the state trajectory over time as if under a different realization of the disturbances and noise, and therefore should not be discovered by a detection mechanism seeking to flag attacks based on deviation from apparently allowable behavior.  Another way to look at this is that with noise and/or disturbances, there always exist some cyberattacks that are undiscoverable, but without noise and disturbances, all cyberattacks are discoverable.

Stealthy cyberattacks aim to develop attack policies for which is not possible to distinguish between actual and false measurement trajectories using detection methods that would not flag normal process data as attacks.  One could consider a stealthy attack to essentially be ``dynamics-based.''  Effectively, it uses the knowledge of the process model, disturbance and noise distributions, and detection strategy to design an attack that cannot be flagged as ``unexpected.''  Detecting a cyberattack purely from process data may be challenging because it requires developing ``expectations'' of what the process data should be, which should be derived either from experience or a model.  If data from which predictions are made or conclusions are drawn is falsified, it may be difficult to determine the appropriate expectation.  Furthermore, when changes in the process dynamics are possible, it becomes more difficult to design a detection method that can detect the attack.  For example, it would be desirable that the attack detection method not flag model changes as attacks; this means that the attack detection method would now need to not only avoid flagging normal process data as coming from an attack, but also data that might be consistent with a change in the process dynamics.  Effectively, this broadens the scope of what types of measurement trajectories should be ``not flagged,'' leaving attackers with potentially more ``allowable'' state measurements that would fly under the radar of the detection policy.

Actuator attacks, in contrast, do not falsify state measurements.  Therefore, if the measurements of the actuator outputs were to be measured at any given time and predictions of the state made, then as long as the process dynamic model is sufficiently accurate to provide adequate predictions, no significant discrepancy will be noted between what states are measured and those which are predicted under that actuator output.  Detection of actuator attacks, therefore, must compare the signals that the actuator should have generated for a (correct) state measurement with the signal utilized in adjusting the actuator.  One way to try to achieve this might be by developing a relatively fast method for generating an expected value of the actuator output for a given state measurement using, for example, explicit or multi-parametric MPC~\cite{oberdieck2017explicit} or a neural network~\cite{lucia2018deep}.  If the actual signal received by the actuator is evaluated against this expected value (essentially through a redundant control computation), that may ensure that it receives the correct signal from the controller, but if there is any computing performed on the signal at the actuator level, then if that code becomes compromised, there is still a need to evaluate what the actual actuator output was.  If the actuator output is measured from a process variable, however, such as flow rate downstream of a process valve, that could also be impacted by dynamics of the actuator, which could change over time, so that once again there would need to be consideration for the point at which the attack will be flagged by a detection strategy via the actuator output versus assumed to be the potential result of a change in actuator dynamics.

\subsubsection{Cyberattack Discoverability with Sensor Hijacking: Process Example Demonstration}

The scenario in this section is exemplified using the general model of a continuous stirred tank reactor (CSTR) in which a second-order reaction $A \rightarrow B$ occurs.  The states are the reactant concentration of $A$ ($C_A$) and the temperature ($T$), where the dynamics are given by:
\begin{equation}
\dot C_A = \frac{F}{V} (C_{A0}-C_A) -k_0 e^{-\frac{E}{R_gT}} C_A^2\label{eq:CSTRDynamicsNumericallyEvaluated_Conc} 
\end{equation}
\begin{equation} 
\dot T = \frac{F}{V} (T_{0}-T) -\frac{\Delta H k_0}{\rho_{L} C_p} e^{-\frac{E}{R_gT}}C_A^2 + \frac{Q}{\rho_{L} C_p V} \label{eq:CSTRDynamicsNumericallyEvaluated_Temp}
\end{equation}
Here, $R_g$ is the ideal gas constant, $E$ is the activation energy, $\Delta H$ is the enthalpy of reaction, and $k_0$ is the pre-exponential constant.  The inlet/outlet volumetric flow rate, $F$, is considered fixed, as are the liquid density, $\rho_L$, heat capacity, $C_p$, and liquid volume in the tank, $V$.  The parameter values are as shown in Table~\ref{tbl:CSTRParameters_1}.
\begin{table}[h] 
	\begin{center}
		\begin{tabular}{cccccc}
			\textbf{Parameter} & \textbf{Value} & \textbf{Unit} & \textbf{Parameter} & \textbf{Value} & \textbf{Unit} \\ \hline
			$V$ & 1 & m$^3$ & $T_0$ & 300 & $K$ \\ \hline
			$C_p$ & $0.231$ & kJ/kg$\cdot$K & $k_0$ & $8.46\times 10^6$ & m$^3$/h$\cdot$kmol \\ \hline
			$F$ & $5$ & m$^3$/h & $\rho_L$ & $1000$ & kg/m$^3$ \\ \hline
			$E$ & $5 \times 10^4$ & kJ/kmol & $R_g$ & $8.314$ & kJ/kmol$\cdot$K \\  \hline
			$\Delta H$ & $-1.15 \times 10^4$ & kJ/kmol \\ \hline
		\end{tabular}
		\caption{Parameters for the CSTR model of Eqs.~\ref{eq:CSTRDynamicsNumericallyEvaluated_Conc}-\ref{eq:CSTRDynamicsNumericallyEvaluated_Temp}} \label{tbl:CSTRParameters_1}
	\end{center}
\end{table}
The manipulated inputs are the inlet reactant $A$ concentration ($C_{A0}$, which is bounded as follows: $0.5 \leq C_{A0} \leq 7.5$ kmol/m$^3$) and the rate of heat transferred to the system ($Q$, which is bounded as follows: $-5\times 10^5 \leq Q \leq 5\times 10^5$ kJ/h).   Vectors of deviation variables for the states and inputs from their steady-state values, $C_{As} = 1.22$ kmol/m$^3$, $T_s = 438.2~\text{K}$, $C_{A0s} = 4.0$ kmol/m$^3$, and $Q_s = 0$ kJ/h, respectively, are $x^T = [x_1~x_2] = [\bar{C_A} ~ \bar{T}]$, where $\bar{C_A} = C_A - C_{As}$ and $\bar{T} = T - T_s$, and $u^T = [u_1 ~ u_2] = [\bar{C}_{A0} ~ \bar{Q}]$, where $\bar{C}_{A0} = C_{A0} - C_{A0s}$ and $\bar{Q} = Q - Q_s$.  

The controller used is a model predictive controller that has a quadratic objective function of the form $x^T Q x + u^T R u$, where $Q = diag(10^4, 100)$ and $R = diag(10^4, 10^{-12})$ (for $u$ in MJ/h).  Disturbances and measurement noise are considered.  Specifically, the controller receives measurements impacted by noise and the process is subject to disturbances. The noise is a random variable characterized by a standard normal distribution with mean zero and standard deviations and bounds of 0.03 kmol/m$^3$ h and 5 K/h for the concentration of the reactant and reactor temperature, respectively. In addition, process disturbances were added to the right-hand side of the differential equations describing the rates of change of $C_A$ and $T$ with zero mean and standard deviations of 100 kmol/m$^3$ h and 2200 K/h, and bounds of 50 kmol/m$^3$ h and 500 K/h, respectively (Case 1).  The false state trajectory provided as a measurement sequence from the sensors to the controller is developed via a secondary simulation of $C_A$ and $T$ using Eqs.~\ref{eq:CSTRDynamicsNumericallyEvaluated_Conc}-\ref{eq:CSTRDynamicsNumericallyEvaluated_Temp}.  In this secondary simulation, which would be difficult to implement as it assumes the actual value of the state is known at the first time that the attack starts, which is not possible given the limitations of measuring devices, disturbances are added to the right-hand side of Eqs.~\ref{eq:CSTRDynamicsNumericallyEvaluated_Conc}-\ref{eq:CSTRDynamicsNumericallyEvaluated_Temp} taken from the same normal distribution as the disturbances impacting the process (and bounded with the same bounds), but different realizations of the random variable.  The noise added to this falsified prediction of $C_A$ and $T$ is similarly taken from the same bounded normal distribution as the noise impacting the process, but is a different realization.  The attack starts after 30 sampling periods.  Despite the difficulty of implementing this specific attack, the goal of this simulation is to demonstrate the consequences of well-designed attacks, and this simulation provides a good example of what can readily be understood as a well-designed attack, since it would not be detectable by a reasonable detection strategy (i.e., given the inputs, it is a reasonable trajectory for the state because the right-hand side and noise is generated in the same way as for the process).  The subsequent examples demonstrate what the consequences might be of a well-designed attack, and show that though it may be hard to detect this, consequences could potentially still be that the state is not stabilized around the desired equilibrium.  Specifically, the controller continues to receive false state measurements over time (which implies loss of feedback) and, as a result, the closed-loop state trajectory under the attack may eventually not track a desired steady-state.  %The noise and disturbances were simulated for this example using the MATLAB function randn and a seed of 10.

We simulate the control system hypothesized above over 5 h of operation and with the proposed stealthy attack policy implemented after 0.3 h of operation. The system state was initialized off steady-state at $x_{init} = [-0.4$ kmol/m$^3$ 8 K$]^T$ and the simulations were performed in MATLAB R2016b and fmincon. Fig.~\ref{fig:StealthyAttackLargeDN} shows the attack policy for which the false state trajectory appears to be subject to noise/disturbances but to have a reasonable behavior. We can see that both process states $C_A$ and $T$ start to deviate more significantly from the false states as time progresses.  The trajectories reflect that closed-loop stability may be compromised by a stealthy attack.  

\begin{figure}
	\centering
	\includegraphics[width=0.5\columnwidth,clip]{fig/StealthyLargeRev.eps}
	\caption{Comparison between the false closed-loop state trajectory (dashed lines) and the system closed-loop state trajectory (solid lines) with the process under a cyberattack policy implemented after 0.3 h that mimics the disturbance and measurement noise distributions in Case 1.}
	\label{fig:StealthyAttackLargeDN}
\end{figure}

However, for a different stealthy attack, the closed-loop state may not deviate as significantly from the steady-state operating trajectory in the same time period.  For example, consider the same process example discussed above but with the process disturbances added to the right-hand side of the differential equations having bounds of 10 kmol/m$^3$ h and 100 K/h for the rates of change of $C_A$ and $T$, respectively (Case 2).  We again simulate the control system over 5 h of operation and with the proposed stealthy attack policy implemented after 0.3 h of operation. The system state was initialized off steady-state at $x_{init} = [-0.4$ kmol/m$^3$ 8 K$]^T$ and the simulations were conducted in MATLAB R2016b using fmincon. Fig.~\ref{fig:StealthyAttackSmallDN} depicts the cyberattack policy and both process states $C_A$ and $T$ do not deviate considerably from the false states.  Detection mechanisms which rely on data ``appearing'' abnormal may not notice the attacks in this section because the false state trajectory emulates what the process state trajectory might be with the noise distribution but different realizations of the noise.

\begin{figure}
	\centering
	\includegraphics[width=0.5\columnwidth,clip]{fig/StealthySmallRev.eps}
	\caption{Comparison between the false closed-loop state trajectory (dashed lines) and the system closed-loop state trajectory (solid lines) with the process under a cyberattack policy implemented after 0.3 h that mimics the disturbance and measurement noise distributions in Case 2.}
	\label{fig:StealthyAttackSmallDN}
\end{figure}


\subsection{Challenges in Cyberattack-Handling with Changing Process Dynamics} \label{sec:ChangingDyn}

As noted in the prior section, changes in the process dynamics, if they are not to be flagged immediately by an attack detection strategy, may broaden the set of state measurement trajectories which might not be flagged by the detection policy (i.e., be ``stealthy''), which may give an attacker greater flexibility to attempt to cause harm for a process.  However, changes in the process dynamics, even in the absence of an attack, may pose challenges in terms of maintaining the closed-loop state in a desired operating region.  Prior work from our group \cite{DurandIFACWC2020,durand2020responsive} suggested a technique for handling changes in the process dynamics in the absence of attacks via control design.  The specific control design utilized in that context was an LEMPC that is able to maintain the process closed-loop state within a pre-defined region of state-space, as long as the disturbances/plant-model mismatch are sufficiently small.  However, as the process dynamics change, the plant-model mismatch grows, which could eventually result in the closed-loop state leaving the expected region of state-space ($\Omega_{\hat{\rho}_q}$).  In~\cite{durand2020responsive,DurandIFACWC2020}, we suggested that when the closed-loop state leaves $\Omega_{\hat{\rho}_q}$, this initiates a model re-identification procedure where, within a defined timeframe after the first detection of the closed-loop state leaving $\Omega_{\hat{\rho}_q}$ (to prevent the closed-loop state from leaving a safe operating region $\Omega_{\hat{\rho}_{safe,q}}$ by allowing it to operate for too long under a controller that can no longer maintain the closed-loop state in $\Omega_{\hat{\rho}_q}$), the model must be re-identified with the most recent input/output process data.

Though this method has benefits in terms of allowing changes in the process dynamics to be flagged and handled before they might cause safety issues for a nonlinear system, the situation becomes harder to deal with when cyberattacks on the control system are also considered possible.  Specifically, in our prior work~\cite{Oyama072020}, we presented a concept for detecting cyberattacks using redundant observers based on different process state measurements in the absence of changes in the process dynamics.  In this concept, the redundant observers serve as a validation for one another by ensuring that there is some degree of ``consensus'' among the observers regarding the current state measurement when there is no attack, and then flagging the lack of that ``consensus'' as an attack.  However, an important issue mentioned in~\cite{DurandIFACWC2020} is that there may be some challenges with handling cyberattacks in the case that the process dynamics also change over time.  Specifically, as the process dynamics change, the observers may no longer estimate the state as accurately as before the process dynamics changed, which may cause an observer-based detection strategy to flag a change in the process dynamics as an attack.  This raises the question of what might be a viable strategy for detecting both cyberattacks as well as model changes and then handling each in an appropriate manner.
% attacks are detected if the norm of the difference between the state estimates from any two of the different observers becomes greater than a threshold value which might be expected to bound the difference in the absence of an attack.  Essentially, 

One idea for doing this could be to develop a two-tier strategy for detecting attacks or model changes.  Specifically, we can develop an original threshold on the difference between any two state estimates and an original region $\Omega_{\hat{\rho}_q}$.  The characteristics of these detection strategies should be such that, if there is no attack or model change, the threshold on the norm of the difference between the state estimates should not be crossed (this threshold might be determined, for example, from process data) and the closed-loop state should not leave $\Omega_{\hat{\rho}_q}$.  Then, if the closed-loop state either leaves $\Omega_{\hat{\rho}_q}$ or the threshold on the difference between the state estimates is crossed (or both), a secondary detection strategy is implemented for attacks with a higher bound as the threshold.  This higher bound should be selected to ensure that as long as the norms of the state estimate differences are within the larger bound, the closed-loop state does not leave $\Omega_{\hat{\rho}_{safe,q}}$ before a certain time period $\Delta_{per}$ has passed even if there was a dynamics change, and that the closed-loop state does not leave $\Omega_{\hat{\rho}_{safe,q}}$ at any point in time if there was no dynamics change and only an attack.  Before $\Delta_{per}$ time units pass after the first threshold is breached or the state measurement leaves $\Omega_{\hat{\rho}_q}$, the model should be re-identified with the most recent input/output process data and used to update the LEMPC formulation to reflect a new model and new Lyapunov-based controller, as well as a new $\Omega_{\hat{\rho}_{q+1}}$.  The goal of this strategy would be to prevent attacks within the thresholds from being able to create safety issues, while also facilitating model re-identification when the closed-loop state leaves $\Omega_{\hat{\rho}_q}$ so that a new $\Omega_{\hat{\rho}_{q+1}}$ can be identified in which an updated LEMPC can maintain the closed-loop state until the next model change.  This provides some buffer time between each significant change in the process dynamics within which the dynamics change can be detected and handled in a way that allows a buffer time for re-identification to again be present after the next significant change in the dynamics, while preventing attacks from taking advantage of that strategy to impact safety for the closed-loop system.   

This strategy is proposed for the following reasons: 1) If there is an attack and no model change that drives the state measurement out of $\Omega_{\hat{\rho}_q}$, then as long as the state estimates are required to still be within a bounded distance (represented by a norm of their difference) of one another (though within a larger bound than was used before the falsified measurements exited $\Omega_{\hat{\rho}_q}$), it is reasonable to expect that the attacker is still not able to provide measurements that differ too significantly from the actual state (assuming that at least one of the observers is not impacted by the attacks) so that the larger threshold on the norm of the estimate differences essentially functions like allowing greater levels of noise in the system.  As long as the control actions computed after the closed-loop state leaves $\Omega_{\hat{\rho}_q}$ prevent the closed-loop state from leaving $\Omega_{\hat{\rho}_{safe,q}}$ in the presence of the increased levels of noise, closed-loop stability should not be compromised.  2) If there is a model change and no attack that drives the closed-loop state out of $\Omega_{\hat{\rho}_q}$, then there is greater plant-model mismatch (this can be considered to be like greater levels of disturbances).  As long as the control actions computed after the closed-loop state leaves $\Omega_{\hat{\rho}_q}$ are able to handle these greater levels of disturbances without the closed-loop state leaving $\Omega_{\hat{\rho}_{safe,q}}$ before $\Delta_{per}$, this strategy will prevent the closed-loop state from leaving the safe operating region.  3) If both an attack and a model change occur, then as long as the control actions computed can handle the compounding effect of both sets of disturbances/noise, the closed-loop state will not leave $\Omega_{\hat{\rho}_{safe,q}}$ before $\Delta_{per}$.

Though the logic of the prior section suggests this strategy may have some merit, the description alone makes it unclear how such a policy might be designed for a system, as well as how parameters of the strategy impact when it might be successful.  The next section uses a chemical process example to analyze some of these considerations under $\Delta_{per}$ time units after the state measurement is outside of $\Omega_{\hat{\rho}_q}$ or the first cyberattack detection threshold is breached.

\subsubsection{Challenges in Cyberattack-Handling with Changing Process Dynamics: Process Example Demonstration}

We utilize a CSTR to explore the concept of the prior section.  The process dynamic model continues to follow that in Eqs.~\ref{eq:CSTRDynamicsNumericallyEvaluated_Conc}-\ref{eq:CSTRDynamicsNumericallyEvaluated_Temp}.  The objective function, which is the time integral of the product production rate, is as follows:
\begin{equation}
\begin{aligned}
\int_{t_k}^{t_k+N} L_e = \int_{t_k}^{t_k+N} \hspace{3mm}[-k_{0}e^{-\frac{E}{RT(\tau)}}C_{A}(\tau)^2]d\tau \label{eq:CSTR_Objective_Func}
\end{aligned}
\end{equation}	
The parameters of the CSTR follow those in Table~\ref{tbl:CSTRParameters_1} except that $k_0$ is 13.93 m$^3$/h$\cdot$kmol, and $E$ and $\Delta H$ have also been updated to $5 \times 10^3$  kJ/kmol and $1.15 \times 10^4$ kJ/kmol, respectively.  The steady-state is at $C_{As} = 2.00$ kmol/m$^3$, $T_s = 350.20$ K.  In addition, bounded process disturbances and sensor noise were added; disturbances were added to the right-hand side of Eqs.~\ref{eq:CSTRDynamicsNumericallyEvaluated_Conc}-\ref{eq:CSTRDynamicsNumericallyEvaluated_Temp} with zero mean and standard deviations of 0.5 kmol/m$^3$ h and 2 K/h, and bounds of 2 kmol/m$^3$ h and 5 K/h.  Sensor noise was added to the measurements of $C_A$ and $T$ with standard normal distribution with mean zero, standard deviations of 0.01 kmol/m$^3$ and 0.5 K, and bounds of 0.02 kmol/m$^3$ and 0.5 K.

The process is controlled by an LEMPC, so that it is necessary to design the Lyapunov-based controller and stability region.  Only the value of $C_{A0}$ is computed by the controller.  The Lyapunov-based controller for the deviation variable form of $C_{A0}$ is:
\begin{equation}
h_{NL,q} = -1.6(C_A - C_{As})- 0.01(T - T_s)
\end{equation}
which has input bounds (in deviation variable form) of -3.5 kmol/m$^3$ and 3.5 kmol/m$^3$ and a steady-state value of 4 kmol/m$^3$.  The Lyapunov function utilized was quadratic ($\hat{V}_q = x^T P x$, with $P=[110.11 ~0; 0~ 0.12]$).  $\hat{\rho}_{e,q}$, $\hat{\rho}_{q}$, and $\hat{\rho}_{safe,q}$ were obtained by discretizing the state-space and locating a region where $\dot{\hat{V}}_q$ is negative.  The initial values selected for these parameters were, respectively, $247.5$, $330$, and $440$.  The Lyapunov-based stability constraints are enforced such that that of Eq.~\ref{eq:LEMPCEmpirical:Constraint1} is enforced at the end of each sampling period, and Eq.~\ref{eq:LEMPCEmpirical:Constraint2} is enforced only at $t_k$, but if that constraint is enforced, constraints of the form of Eqs.~\ref{eq:LEMPCEmpirical:Constraint1} are enforced at the end of subsequent sampling periods until the end of the prediction horizon.  The problem is solved using fmincon in MATLAB R2016b.  
%(i.e., starting at $t_{k+1}$)
State estimates for this process were obtained using a high-gain observer for the system in transformed coordinates~\cite{Khalil2002}:
\begin{equation}
\begin{aligned}
\dot{\hat{z}} = A \hat{z} + L (y - C \hat{z})  \label{eq:observereqn}
\end{aligned}
\end{equation}
where $A=[0~1;0~0]$, $C = [1~0]$, and $L = [100~10000]^T$, and $\hat{z}$ denotes the state estimate vector in the new coordinates, with $y$ as the process output. To obtain the state estimate, $z$ is obtained by applying an inverse transformation $T^{-1}(\hat{z})$ (this observer design and process model are taken from~\cite{heidarinejad2012state}).  This estimator uses an output of temperature to estimate the full state, and is used as the redundant estimator, with the LEMPC receiving full state feedback (the full state feedback is considered to be the secondary ``observer'' in the sense that it is the other estimate of the state besides that taken from the high-gain observer for the purpose of the attack detection strategy).  The strategy for detecting both sensor measurement cyberattacks as well as changes in the process dynamics is as follows: if the state measurement is outside of $\Omega_{\hat{\rho}_q}$ or the norm of the difference between the state estimate from the high-gain observer and the state measurement is greater than a threshold $\epsilon_{\max,1}$, the upper bound on the norm of the difference between the state estimate from the high-gain observer and the state measurement is switched to a new bound $\epsilon_{\max,2}$ and the Lyapunov-based controller is utilized in place of the LEMPC.  From the description of this system and the proposed method of the prior section, important parameters in facilitating the use of this method are $\epsilon_{\max,1}$, $\epsilon_{\max,2}$, $\Delta_{per}$, $\Omega_{\hat{\rho}_q}$, $\Omega_{\hat{\rho}_{e,q}}$, and $\Omega_{\hat{\rho}_{safe,q}}$.  In this section, we explore how changing these various parameters can impact the success of the proposed method for some simulated attacks and model changes to elucidate properties of this strategy.

We begin this investigation by simulating the process over 2 h of operation without any change in the process dynamics or any cyberattacks.  In this simulation $\epsilon_{\max,1}$ is set to 1.02,  which in this simulation did not cause any attack to be flagged in the presence of operation under disturbances and measurement noise as desired, and $\epsilon_{\max,2}$ was (arbitrarily) set to 2.54.  The state is initialized from $x_{init,1} = [-0.7 ~\text{kmol}/\text{m}^3,-30~\text{K}]^T$.  The results of this simulation are shown in Fig.~\ref{fig:BaselineCase}, where the state estimate and the state measurement are shown to be close to one another throughout the time of operation, and the closed-loop state is maintained in $\Omega_{\hat{\rho}_q}$.

\begin{figure}
	\centering
	\includegraphics[width=0.5\columnwidth,clip]{fig/BaselineCase.eps}
	\caption{Baseline case: closed-loop state trajectory without any change in the process dynamics or cyberattacks.  Plots show measured and estimated values at the end of each sampling period.}
	\label{fig:BaselineCase}
\end{figure}

As noted in the prior section, when the process dynamics are able to change, this may complicate the design of the detection strategy.  Specifically, it would be desirable that there is some amount of change in the dynamics which is allowable before a cyberattack detection strategy might flag the change in the dynamics as an attack. In addition, the detection thresholds must be large enough to account for the difference between the process state measurement and state estimate. However, if the detection threshold is too large, a cyberattack policy may not be flagged within a reasonable time of operation, and profit loss could occur.  Similarly, it would be desirable that $\Omega_{\hat{\rho}_{e,q}}$ be sufficiently conservative to allow for some amount of potential growth in the plant/model mismatch over time before the closed-loop state might leave $\Omega_{\hat{\rho}_q}$.  To design the threshold on the attacks which might achieve this, as well as $\Omega_{\hat{\rho}_{e,q}}$, closed-loop simulations might be run under a variety of potential ``next'' models from different initial conditions within $\Omega_{\hat{\rho}_q}$ to ensure that for given values of $\epsilon_{\max,1}$ and $\hat{\rho}_{e,q}$, no attack or change in the dynamics is flagged.  To see how such simulations might be carried out, consider that we would like to be able to avoid flagging a model change in which $k_0$ changes from 13.93 m$^3$/h$\cdot$kmol to 18 m$^3$/h$\cdot$kmol as an attack or a change in the dynamics.  We operate the process under the LEMPC described above, with $\epsilon_{\max,1}$ set to 1.02 again.  Figs.~\ref{fig:StateTrajectory_SmallModelChange}-\ref{fig:StateSpace_SmallModelChange} show the result of this simulation, where the change in the underlying dynamics occurs after 0.3 h of operation. In this case, the detection method did not flag the change in the process dynamics as a cyberattack, and Fig.~\ref{fig:StateSpace_SmallModelChange} shows that the value of $\hat{\rho}_{e,q}$ is sufficiently conservative such that the closed-loop state is maintained within $\Omega_{\hat{\rho}_{q}}$ for all times, even after the model change, due to the switch between the two constraints of Eqs.~\ref{eq:LEMPCEmpirical:Constraint1}-\ref{eq:LEMPCEmpirical:Constraint2} (i.e., the plant/model mismatch is sufficiently small).

\begin{figure}
	\centering
	\includegraphics[width=0.5\columnwidth,clip]{fig/StateTrajectory_SmallModelChange.eps}
	\caption{Closed-loop state trajectory under a change in the process dynamics in which $k_0$ changes from 13.93 m$^3$/h$\cdot$kmol to 18 m$^3$/h$\cdot$kmol after 0.3 h of operation.}
	\label{fig:StateTrajectory_SmallModelChange}
\end{figure}


\begin{figure}
	\centering
	\includegraphics[width=0.5\columnwidth,clip]{fig/StateSpace_SmallModelChange.eps}
	\caption{Stability region and closed-loop state under a change in the process dynamics in which $k_0$ changes from 13.93 m$^3$/h$\cdot$kmol to 18 m$^3$/h$\cdot$kmol after 0.3 h of operation.}
	\label{fig:StateSpace_SmallModelChange}
\end{figure}

Though it was considered desirable to not flag the change in $k_0$ from 13.93 m$^3$/h$\cdot$kmol to 18 m$^3$/h$\cdot$kmol, we might consider that if the value of $k_0$ becomes large enough (e.g., 25 m$^3$/h$\cdot$kmol), we would like to flag the change in the dynamics (to avoid designing $\Omega_{\hat{\rho}_{e,q}}$ to need to be conservative enough that with such a change in the dynamics, the closed-loop state still needs to remain within $\Omega_{\hat{\rho}_q}$).  Therefore, we would like the change in $k_0$ to be flagged by either the attack detection strategy or via the closed-loop state leaving $\Omega_{\hat{\rho}_q}$.  Figs.~\ref{fig:StateTrajectory_LargeModelChange}-\ref{fig:PlotLargeModelChange} show the closed-loop state trajectory under this larger change in the process dynamics where $k_0$ changes to 25 m$^3$/h$\cdot$kmol after 0.3 h of operation.  At 0.33 h of operation, the detection method flagged the change in the process dynamics first (demonstrating the concept stated in this work that it may be difficult to tell the difference between a change in the dynamics and an attack from sensor measurements alone), initiating the use of the backup controller $h_{NL,q}$ as well as the change of the upper bound used by the attack detection algorithm to $\epsilon_{\max,2}$.  No subsequent attack was detected with the threshold of $\epsilon_{\max,2}$ set to 2.35.  The process state remains within $\Omega_{{\hat{\rho}_{safe,q}}}$ for the remainder of the 2 h of operation after the detection of the model change.  However, if instead $k_0$ changes to a larger value of 30 m$^3$/h$\cdot$kmol after 0.3 h of operation, then even after 2 hrs of operation, neither strategy detects the change.  This indicates that it may be desirable to make $\hat{\rho}_{e,q}$ larger to attempt to try to cause the larger change in the dynamics to drive the closed-loop state out of $\Omega_{\hat{\rho}_q}$ by getting it potentially closer to the boundary of $\Omega_{\hat{\rho}_q}$ before any mitigating strategy (Eq.~\ref{eq:LEMPCEmpirical:Constraint2}) is activated.  Here, however, when $\hat{\rho}_{e,q}$ is increased to 325 (close to $\rho = 330$), the change in the dynamics is still not detected, but if it is increased to $\hat{\rho}_{e,q} = 326$, the closed-loop state leaves $\Omega_{\hat{\rho}_{q}}$ before the change in the dynamics due to the disturbances and proximity of $\hat{\rho}_{e,q}$ to $\hat{\rho}_{q}$.  This indicates that it may not be straightforward to tune this method to achieve specific detection goals with a given model.  Furthermore, as the value of $\hat{\rho}_{e,q}$ is changed, this can change which inputs are computed by the LEMPC, which may or may not cause changes in the process dynamics to be flagged more readily by the attack detection strategy by causing the closed-loop state to be driven to different conditions than when $\hat{\rho}_{e,q}$ takes another value.  Finally, we note that if $k_0$ changes to 35 m$^3$/h$\cdot$kmol after 0.3 h of operation, then $\epsilon_{\max,1}$ is breached by 0.33 h of operation, but the second threshold is not breached during the remainder of a simulation of 0.5 h total, providing time for the model to be re-identified without an attack being detected with this second detection threshold.


\begin{figure}
	\centering
	\includegraphics[width=0.5\columnwidth,clip]{fig/LargeModelChange.eps}
	\caption{Closed-loop state trajectory under a change in the process dynamics in which $k_0$ changes from 13.93 m$^3$/h$\cdot$kmol to 25 m$^3$/h$\cdot$kmol after 0.3 h of operation.}
	\label{fig:StateTrajectory_LargeModelChange}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.5\columnwidth,clip]{fig/LargeModelChangeStateSpace.eps}
	\caption{Stability region and closed-loop state under a change in the process dynamics in which $k_0$ changes from 13.93 m$^3$/h$\cdot$kmol to 25 m$^3$/h$\cdot$kmol after 0.3 h of operation.}
	\label{fig:PlotLargeModelChange}
\end{figure}

Above, the focus was on tuning the parameters of the control law to handle potential changes in the process model.  Now, we turn our focus to the case that there are attacks instead of model changes.  We first look at the case that there are bias attacks and different thresholds $\epsilon_{\max,1}$ and $\epsilon_{\max,2}$.  The closed-loop state is initialized from $x_{init,1} = [-1.25,~ 20]^T$, with $\epsilon_{\max,1} = 1.02$, but in this case, an attack is flagged before it occurs (i.e., $\epsilon_{\max,1}$ is not large enough to account for the difference between the state estimate and state measurement which might be observed under normal operation when the closed-loop state is initialized at $x_{init,2}$, though it had been large enough in the prior simulations).  Therefore, $\epsilon_{\max,1}$ was increased to 1.24, which is a value where no attack is then flagged before the attack occurs in the revised simulation.  Furthermore, to finish setting up the strategy for attack-handling, the value of $\epsilon_{\max,2}$ must be fixed.  The value of $\epsilon_{\max,2}$ should be such that this bound is not breached when a model change alone occurs within the expected bounds.  One way of attempting to determine it could be by simulating the closed-loop system from various initial conditions on the boundary of $\Omega_{\hat{\rho}_q}$ under different potential model changes, and recording the worst-case upper bound on the difference between the state measurement and the state estimate over the subsequent time period.  $\epsilon_{\max,2}$ should be greater than $\epsilon_{\max,1}$ to avoid flagging acceptable process dynamic behavior as attacks.  In this next set of simulations, $\epsilon_{\max,2}$ is set to 1.25 to be greater than $\epsilon_{\max,1}$, but a more rigorous simulation-based analysis of this parameter could be carried out.

We now look at what happens with these thresholds and several bias attacks on the process sensors.  Specifically, after 0.3 h of operation, a false state measurement begins to be provided to the LEMPC equal to the actual state plus 0.1, 0.3, or 0.6 kmol/m$^3$.  The results are shown in Figs.~\ref{fig:StateSpace_Biases}-\ref{fig:Bias_0_6} for an operation time of 2 h.  Fig.~\ref{fig:StateSpace_Biases} demonstrates that under all three attacks, the control laws applied were able to prevent the closed-loop state from leaving $\Omega_{\hat{\rho}_{safe,q}}$, and hence the fact that the second threshold $\epsilon_{\max,2}$ was not breached (which would have caused the discrepancy to be flagged as attacks instead of potentially as model changes) is not problematic from a safety perspective.  Furthermore, with the smallest two bias attacks, the attacks are not detected, indicating that an attack that is ``stealthy'' can be considered the one in which the attack policy is within the bounds of the detection threshold. For the largest bias attack, the attack was first detected by the measurement leaving $\Omega_{\hat{\rho}_q}$, rather than by the detection threshold, indicating once again that it may be difficult to distinguish between a dynamics change and a sensor measurement cyberattack.  Furthermore, Fig.~\ref{fig:Bias_0_1} and \ref{fig:Bias_0_6} indicate that a good degree of visually problematic bias in the measurement can remain un-detected (i.e., be ``stealthy'' with respect to either the first (Fig.~\ref{fig:Bias_0_1}) or second (Fig.~\ref{fig:Bias_0_6}) bound).  Despite that this is undesirable, if $\epsilon_{\max,1}$ is decreased, there are initial conditions in the stability region from which normal operation might be flagged as an attack, as stated above.  This indicates that part of the reason for the ``stealthy'' attacks getting through in this case is that the disturbances affecting the process and expected model changes are large enough to allow a number of attacks, even those which visually create a large bias in the state measurement compared to the estimate, to not be detected that way.  This suggests that an additional attack detection policy on top of this state estimation-based method (perhaps one which is based on recognizing patterns in the estimate and measurement data) may provide additional leverage to attempt to detect and diagnose attacks.  Another interesting point noted from the above simulations is that in the cases simulated, the value of $\Delta_{per}$ did not need to be evaluated (i.e., all of the attacks and model changes discussed above maintained the closed-loop state within $\Omega_{\hat{\rho}_{safe,q}}$ for all times).  Though this is not necessarily a rule, it indicates the complexity of the design process for the parameters of the suggested attack detection method, and the extent to which the process dynamics under the control laws selected as part of the attack-handling policy dictate their relevance to the safety problem under attacks and model changes.  A similar statement would hold for the sizes of $\Omega_{\hat{\rho}_{safe,q}}$ and $\Omega_{\hat{\rho}_{q}}$.

\begin{figure}
	\centering
	\includegraphics[width=0.5\columnwidth,clip]{fig/AllBias.eps}
	\caption{State-space trajectories under the three different bias attacks in the sensor measurements occurring after 0.3 h of operation.}
	\label{fig:StateSpace_Biases}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.5\columnwidth,clip]{fig/Bias0_1Fig.eps}
	\caption{Trajectories of the state estimate and state feedback under the bias attack of 0.1 in the sensor measurement occurring after 0.3 h of operation.}
	\label{fig:Bias_0_1}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.5\columnwidth,clip]{fig/Bias0_6Fig.eps}
	\caption{Trajectories of the state estimate and state feedback under the bias attack of 0.6 in the sensor measurement occurring after 0.3 h of operation.}
	\label{fig:Bias_0_6}
\end{figure}

From the above discussion, it can be expected that tuning the proposed method to eliminate vulnerabilities which an attacker might exploit (e.g., initial conditions from which certain state measurements which fly under the radar could cause a problematic effect) while seeking to achieve desired goals in model change handling might be challenging with the type of ``trial-and-error'' tuning procedure pursued above, particularly due to the relationships between the control law parameters.  This suggests that a theoretical analysis of the proposed method, which is outside the scope of the present manuscript, may aid in elucidating the relationships between the parameters and how to obtain a sufficient strategy, though this may be theoretical to the point that it could be difficult to utilize in developing the strategy in a non-simulation-based manner without additional research. Specifically, with cybersecurity studies, the viability of a concept lies not in its ability to work for some cases, but in its ability to guarantee that there are no cases in which it does not work (i.e., no vulnerabilities exist). A simulation-based approach may achieve this goal by performing exhaustive case studies that ensure that all vulnerabilities/scenarios have been analyzed.  


%This suggests, furthermore, that control system cybersecurity research simulation studies should be held to different expectations than simulation studies for typical theory-based control laws.  Specifically, it is acceptable to develop a control law with strong theoretical properties under sufficient conditions and then to demonstrate the concept via an example in which all control-theoretic conditions are not checked (and possibly not even met) because the simulation can still demonstrate viability of the concept apart from the theory (i.e., it demonstrates that the concept might work in practice).  With cybersecurity studies, however, the viability of a concept lies not in its ability to work for some cases, but in its ability to guarantee that there are no cases in which it does not work (i.e., no vulnerabilities exist).  Such a concept would not be expected to be possible to demonstrate via simulation alone; therefore, detection and control combinations based on theory may be less valuable when explored via simulation alone than if they can be guaranteed via a theory for which a tractable algorithm exists for finding all parameters required for the control and detection strategy.  

Another observation regarding the proposed strategy is that the detection strategy from~\cite{Oyama072020} which does not account for model changes simultaneously requires that not all estimators can be impacted by false sensor measurements (i.e., at least one must not be attacked).  Such a requirement would still need to be imposed to consider the two-tier detection strategy for the case when model changes may also occur because if all estimators are attacked, there is no longer a ``check'' for any of the measurements.  The impact of this is that the detection strategy cannot handle certain attacks.  For example, a stealthy attack that fully mimics alternative process dynamics would not be guarded against if it was performed in the manner shown in Figs.~\ref{fig:StealthyAttackLargeDN}-\ref{fig:StealthyAttackSmallDN}.  

The results so far have explored cases where either a model change occurs or a cyberattack occurs and demonstrated that the two-tier detection strategy with the parameters utilized in the various simulations above is able to prevent the closed-loop state from leaving $\Omega_{\hat{\rho}_{safe,q}}$ too quickly.  Here, we explore what happens when both a model change and a cyberattack occur at once.  The model change to be investigated is a gradual decrease in $k_0$ to represent, for example, catalyst deactivation.  In this case, the value of $k_0$ is decreased, starting at 0.5 h of operation, every 0.5 h, taking values of 13, 11, 9, 7, 5, and 3  m$^3$/h$\cdot$kmol over time.  An attack is performed on the measurement of $C_A$ (the measurement of $T$ should not be attacked to demonstrate this method in accordance with the above paragraph).  The value of $C_A$ is calculated using Eqs.~\ref{eq:CSTRDynamicsNumericallyEvaluated_Conc}-\ref{eq:CSTRDynamicsNumericallyEvaluated_Temp} and adding a realization of the disturbance to the right-hand side of each of those equations that is different from that applied to the actual process, but from the same distribution.  Noise is then added to the resulting value of $C_A$ from the same distribution as the sensor noise, but again a different realization (i.e., the value of $C_A$ is determined as if it was coming from a stealthy attack of the type in Figs.~\ref{fig:StealthyAttackLargeDN}-\ref{fig:StealthyAttackSmallDN}, but the measured value of $T$ is not).  In addition, the simulation of Eqs.~\ref{eq:CSTRDynamicsNumericallyEvaluated_Conc}-\ref{eq:CSTRDynamicsNumericallyEvaluated_Temp} used to obtain the falsified value of $C_A$ is modified over time to have the value of $k_0$ change.  Specifically, the attack starts at 1.3 h and then for the first 0.5 h after the attack is started, the value of $k_0$ is set to 11 m$^3$/h$\cdot$kmol, for the next 0.5 h it is set to 10 m$^3$/h$\cdot$kmol, for the next 0.5 h it is set to 9 m$^3$/h$\cdot$kmol, for the next 0.5 h it is set to 8 m$^3$/h$\cdot$kmol, and subsequently it is set to 7 m$^3$/h$\cdot$kmol.  The process is simulated for 4 h of operation, and the trajectory for the closed-loop state in Fig.~\ref{fig:StateSpace_Both} results, along with the trajectories in Fig.~\ref{fig:EstState_Both} of the measured values of $C_A$ and $T$ in deviation from their steady-state values (where the measured values are subjected to noise and the attack) and the estimated values of $C_A$ and $T$ in deviation from their steady-state values.  No attack is detected in the time of operation, but the closed-loop state exits $\Omega_{\hat{\rho}_{safe,q}}$ during the time of operation.  If, however, only the model change is simulated for the 4 h, or only a stealthy-type attack for the system with no model change, neither is detected and the closed-loop state does not leave $\Omega_{\hat{\rho}_{safe,q}}$.  This suggests that in Figs.~\ref{fig:StateSpace_Both}-\ref{fig:EstState_Both}, the situation with the model change favors the stealthy-type attack that the attacker performs when the model changed compared to the situation where the model does not change.  However, because the attack is based on the process dynamics, which are different in the scenarios with and without the model change, the attacks are not identical in terms of which false state measurements they provide over time or which dynamic systems they are applied to when implemented, which contributes to the difference here in terms of attack impact.  The fact that the model change and attack combination was able to drive the closed-loop state out of $\Omega_{\hat{\rho}_{safe,q}}$ suggests that the detection strategy developed via the other examples earlier in this section is still not sufficient for achieving attack-handling when there are model changes and must be further modified to handle all of these cases, again highlighting that extensive simulations may be needed to attempt to design this strategy according to the process and its vulnerabilities. 


\begin{figure}
	\centering
	\includegraphics[width=0.5\columnwidth,clip]{fig/Fig11.eps}
	\caption{State-space trajectories under the gradual change in the value of $k_0$ occurring after 0.5 h of operation and the attack occurring after 1.3 h of operation.}
	\label{fig:StateSpace_Both}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.5\columnwidth,clip]{fig/Fig12.eps}
	\caption{Trajectories of the state estimate and state feedback (state measurements including noise and attacks) under the gradual change in the value of $k_0$ occurring after 0.5 h and the attack occurring after 1.3 h of operation.}
	\label{fig:EstState_Both}
\end{figure}

In closing, we note that the above simulations looked only at the system behavior before the model re-identification triggered by the breaching of the thresholds.  However, as demonstrated above, there may be cases where the first detection threshold is breached, but not the second, leaving it ambiguous as to whether the dynamics changed, or there was an attack on the sensors.  In this case, the strategy triggers model re-identification if the second detection threshold is not breached.  If the data from before the model re-identification was falsified, the attacker is essentially forcing an MPC to re-program itself using data that is not correct.  However, if that data is not too far from correct due to the flagging when the redundant observers give significantly different estimates, it is possible that the new model would have mismatch, but not necessarily de-stabilize the system.  This discussion is closely related to that first brought up in~\cite{DurandIFACWC2020}, which provided a simulation in which the mismatch after model re-identification was triggered using some falsified data was not able to cause the closed-loop state to leave a safe operating region under the conditions simulated.  However, a rigorous investigation of how, whether, and when issues after the re-identification might occur within the context of the two-tier detection policy is beyond the scope of this work and can be a subject of future research.

\begin{rem}
 There is no guarantee that, without the proposed two-tier detection strategy, the closed-loop state would behave ``worse'' (i.e., it would exit $\Omega_{\hat{\rho}_{safe,q}}$ more quickly than desired if there was an attack or model change).
\end{rem}

\begin{rem}
	Though the above discussion is based on the use of $\Omega_{\hat{\rho}_{safe,q}}$ and the detection strategy from~\cite{Oyama072020} which are related to LEMPC, the general concept that a control law might be complemented by redundant estimators to attempt to identify attacks, as well as other thresholds on the state which could reflect changes in the dynamics, is not restricted to the use of LEMPC.  However, we expect it to be possible to develop rigorous theoretical guarantees regarding the conditions under which the proposed method using LEMPC is able to prevent the closed-loop state from leaving $\Omega_{\hat{\rho}_{safe,q}}$ for a certain time period after an attack or model change begins.  A technique with rigorous theoretical guarantees may hold benefits for cyberattack and model change handling if developments can be made which enable the theoretical guarantees to be validated as having been achieved by a given control law design for a specific process. Theoretical guarantees relevant to this strategy have been presented in \cite{RANGAN2021147}.
\end{rem}

\begin{rem}
Both stealthy attacks and faulty sensors provide distorted state measurements to the controller.  The two-tier strategy is not able to distinguish faulty sensors from sensor attacks when it flags an attack.  However, attacks and sensor faults may behave differently in practice.  For example, sensor failures may not provide updated data or may provide only a constant or biased state measurement \cite{Khorrami}. In contrast, attacks may be facilitated by an intelligent adversary that can modify the sensor measurements through attack policies. A stealthy attack therefore has the potential to be a ``process-aware policy'' that could fly under the radar of any reasonable detection method. On the other hand, a faulty sensor corresponds to a measurement defect that is not inherently ``dynamics-based/process-aware.''  One idea for attempting to prevent sensor faults being flagged as attacks is to try to prevent sensor readings that occur during routine plant operation, even with some degradation, from falling outside of the detection bounds of the cyberattack detection and model handling policy.  Then, with frequent sensor maintenance, it could become less likely that the sensor fault would be flagged as an attack using the cyberattack and model change handling strategy.  That again impacts the tuning of the strategy.  Another potential idea for checking if the process has a sensor failure, rather than an attack, is to replace the sensors (or switch to redundant sensors or state estimators that are accurate enough) once they are detected to be potentially under attack to attempt to remove either of the issues, though this may pose the challenge of needing to have backup hardware that can be switched to immediately at any time that a possible attack or model change is flagged. 
\end{rem}

\begin{rem}
The trade-offs in what can be achieved as parameters of the strategy are adjusted, as described above, are experienced partially because the attack detection/control strategy is not flexible enough to allow all goals one might desire to achieve to be met.  For example, while it may be possible to flag an attack with a certain magnitude, that might at the same time cause model changes that would not be desired to be flagged to be noted.  The example is not meant to demonstrate that it is not possible to find a satisfactory design, but rather that it may not be possible to achieve arbitrary objectives simultaneously with this strategy, or may take a variety of simulations to find values of tuning parameters which are satisfactory for a given set of objectives, unless these can be determined via theory.  Because a cyberattack handling strategy has to remove all vulnerabilities to be valuable, it has to be able to handle in some fashion (either by preventing safety issues if an attack is not detected, at least for some time, or flagging the attack) both stealthy as well as non-stealthy attacks.
\end{rem}

\begin{rem}
	Though the discussion of cyberattack discoverability in Section~\ref{sec:defineDiscoverability} was presented in relationship to a reasonable detection mechanism that would not flag an attack, in practice, the discoverability of an attack will depend on the detection mechanism, as shown above (e.g., Fig.\ref{fig:StateSpace_Biases}).  The ability to design a ``stealthy'' attack then in practice is not necessarily limited to whether it reproduces the process dynamics, but is detection mechanism-dependent.  Any attack that is not detected by the detection mechanism in use would be stealthy for that case.
\end{rem}

\subsection{Challenges in Actuator Cyberattack-Handling using Smart Actuator Signals} \label{sec:ActuatorHandling}

While the prior sections discussed the challenges when false sensor measurement cyberattacks and evolving process dynamics may occur individually or simultaneously, this section examines the case where actuator cyberattacks are considered and investigates concepts for handling these cyberattacks temporarily using pre-specified stabilizing signals, which could also be used to tackle attacks on controller code. We use the same CSTR process model described in Section \ref{sec:defineDiscoverability} to demonstrate the impacts of cyberattacks on actuators, which has a different nature compared to the false sensor measurement cyberattack.  Specifically, the input actions are applied to the plant by the actuator attack, regardless of the control actions computed by the controller (it is essentially an open-loop system under actuator hijacking), as an attempt to either drive the system state out of a safe operating region or force the system to lose significant profit over time. In this example, the actuator attack policy applies random input values (which follow a normal distribution) around the steady-state input value to the CSTR. If the process is operated at a stable steady-state, the system state may or may not continue to be maintained around the operating steady-state under the attack depending on how large the bounds on the actuator outputs are and how small the sampling period is. 

%(a remark is presented at the end of this section to highlight the case where evolving dynamics in actuators are present) 

To show this, consider the CSTR process model represented by Eqs.~\ref{eq:CSTRDynamicsNumericallyEvaluated_Conc}-\ref{eq:CSTRDynamicsNumericallyEvaluated_Temp}. The steady-state with $C_{As} = 1.22$ kmol/m$^3$, $T_s = 438.2~\text{K}$, $C_{A0s} = 4$ kmol/m$^3$, and $Q_s = 0$ kJ/h is a stable equilibrium point. The process parameters are listed in Table~\ref{tbl:CSTRParameters_1}.  
The noise is represented by a standard normal distribution with mean zero, standard deviations of 0.03 kmol/m$^3$ and 5 K, and bounds of 0.03 kmol/m$^3$ and 5 K for the concentration of the reactant and reactor temperature, respectively. In addition, process disturbances were added to the right-hand side of the differential equations describing the rates of change of $C_A$ and $T$ with zero mean and standard deviations of 100 kmol/m$^3$ h and 2200 K/h, and bounds of 10 kmol/m$^3$ h and 10 K/h, respectively. 

To perform the simulation of the system described above under the actuator attacks, the random actuator input attack policy is implemented on both corresponding inputs, $u_1$ and $u_2$, with a sampling period of 0.01 h and with zero mean and standard deviation $5$ kmol/m$^3$ and $10^5$ kJ/h, respectively, and $|u_1|<0.1$ kmol/m$^3$  and $|u_2|<10^4$ kJ/h.  We simulate the process under the attack policy over 10 h of operation with the process state initialized off steady-state from $x_{init} = [-0.4$ kmol/m$^3$ 8 K$]^T$ in MATLAB R2017b using fmincon. The integration step used was $10^{-4}$ h. Fig.~\ref{fig:DevStates_Case1} depicts the simulation results which show that the system state trajectory with the process under the actuator cyberattack policy was maintained close to the origin (stable equilibrium point). This is due to a combination of factors, including that the input bounds were small enough to keep the state around the operating steady-state (fundamentally, random inputs are applied to a nonlinear system and they achieve the behavior demonstrated). However, if for the same simulation description, the actuator attack policy uses a larger input bound, $|u_1|<0.2$ kmol/m$^3$, the system state leaves a region around the operating steady-state. This is shown in Fig.~\ref{fig:DevStates_Case2}.

\begin{figure}
	\centering
	\includegraphics[width=0.5\columnwidth,clip]{fig/DevStates_Case1.eps}
	\caption{System state trajectory with the process under an actuator cyberattack policy with smaller input bounds.}
	\label{fig:DevStates_Case1}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.5\columnwidth,clip]{fig/DevStates_Case2.eps}
	\caption{System state trajectory with the process under an actuator cyberattack policy with larger input bounds.}
	\label{fig:DevStates_Case2}
\end{figure}

The simulations above raise the question of how large the actuator input bounds must be and how often new values of the input must be computed by the random attack policy to cause a problem for the process. Specifically, there exists a complex interaction between the input bounds, time period over which the input is held constant, and the nonlinear process dynamics. For example, even when the actuator input attack bounds are large, if the sampling period is sufficiently small, the process operated at a stable steady-state may be kept at this operating steady-state. To see this, consider the latter case described above where $|u_1|<0.2$ kmol/m$^3$, but we use $\Delta=0.005$ h and the same time length for the prediction horizon. Fig.~\ref{fig:DevStates_Case2_SmallDelta} outlines this scenario, in which the sampling period was small enough to have the rogue inputs applied more frequently, but around the steady-state input value, which maintained the system state around the stable steady-state.  

\begin{figure}
	\centering
	\includegraphics[width=0.5\columnwidth,clip]{fig/DevStates_Case2_SmallDelta.eps}
	\caption{System state trajectory with the process under an actuator cyberattack policy with smaller sampling period.}
	\label{fig:DevStates_Case2_SmallDelta}
\end{figure}


The above simulations suggest that if the mean value of the stable steady-state input is applied often enough, attacks which seek to apply rogue inputs when the stable steady-state input is not being applied may have difficulty to destabilize the system. Inspired by this, we consider a potential strategy for attempting to deal with attacks where actuators (as well as potentially other aspects of the control loop like sensors and/or controller codes) could be compromised.  In this strategy, which we will henceforth term a ``smart actuator'' device, the smart actuator applies the mean value of the inputs (i.e., steady-state inputs) at certain times of the process operation as an attempt to maintain the system state around the operating steady-state. The advantage of such a system approach is that it does not rely on state measurements to stabilize the process as required for any stabilizing feedback controller. The effects of any cyberattack on the controller code or state measurements would not impact the ``smart actuator'' signals to the plant. To demonstrate this strategy, consider again the second case description where $|u_1|<0.2$ kmol/m$^3$ and $\Delta=0.01$ h. The smart actuator is designed to implement the steady-state input signals after every 50 sampling periods and hold these input values for another 50 sampling periods (i.e., the steady-state input is held for the first 50 sampling periods, then the attack occurs for the next 50, then the steady-state input is held for the next 50 sampling periods, the steady-state input is held for the next 50 sampling periods, and so forth until 450 sampling periods have passed, after which point the smart actuator is no longer employed for the remainder of the 10 h of operation). The result is shown in Fig.~\ref{fig:DevStates_Case2_SmartActuator} and, in this case, the smart actuator was able to maintain the system state around the operating steady-state by injecting stabilizing signals regularly to the process. The use of the proposed strategy, however, may cause undesirable profit loss that must be considered during normal operation compared to a case where a controller is used to compute the control inputs at all times (i.e., the steady-state input is not applied for long time periods when the controller is not used).
% (particularly, there was a loss of 28$\%$ in profit compared to the case where the process is operated under EMPC without the smart actuator strategy under no attack with 5 h of operation and no constraints besides the actuator bounds).  

%In addition to the choice of the sampling period to potentially handle actuator attacks, another strategy that could be used to deal with other cyberattack policies (e.g., false sensor measurements or alteration in controller code) is based on the case studies above where the process under sufficiently close steady-state inputs would keep the system state at the operating (stable) steady-state if applied recurrently. Specifically, we may use a ``smart actuator'' device that applies the mean value of the inputs (i.e., steady-state inputs) at certain times of the process operation as an attempt to maintain the system state around the operating steady-state. The advantage of such a system approach is that it does not rely on state measurements to stabilize the process as required for any stabilizing feedback controller. The effects of any cyberattack on the controller code or state measurements would not impact the ``smart actuator'' signals to the plant. To demonstrate this strategy, consider again the second case description where $|u_1|<0.2$ kmol/m$^3$ and $\Delta=0.01$ h. The smart actuator is designed to implement the steady-state input signals after every 50 sampling periods and hold these input values for another 50 sampling periods. The result is shown in Fig.~\ref{fig:DevStates_Case2_SmartActuator} and, in this case, the smart actuator was capable to maintain the system state at the operating steady-state by injecting stabilizing signals regularly to the process. The use of the proposed strategy, however, may cause undesirable profit loss that must be considered (particularly, there was a loss of 28$\%$ in profit compared to the case where the process is operated under EMPC without the smart actuator strategy under no attack). 

\begin{figure}
	\centering
	\includegraphics[width=0.5\columnwidth,clip]{fig/DevStates_Case2_SmartActuatorRev.eps}
	\caption{System closed-loop state trajectory with the process under the smart actuator with the random actuator attack.}
	\label{fig:DevStates_Case2_SmartActuator}
\end{figure}

Although the considerations above have been made for processes operated at a stable steady-state, many chemical processes are operated around unstable steady-states.  It is therefore important to ask how and/or whether the smart actuator strategy might be applied to processes that operate around an unstable steady-state.  However, though it is possible to stabilize an unstable steady-state with a control law, we are attempting to stabilize this steady-state without needing to know the state measurement (as it could be compromised), which makes the problem challenging given the dynamics of unstable steady-states.  For such a strategy to work, there would need to be some control policy which could be specified \textit{a priori} and which would be known to be capable of maintaining the closed-loop state in a defined region of operation if repeatedly executed in open-loop.  Though one could try to map different initial states in the region of operation to control signals which can cause the Lyapunov function to be negative for all initial conditions in that region of state-space and then to apply these inputs in sequence to see if this is able to stabilize the system overall, there is no guarantee that a sequence that can achieve this is available, or that these actuator inputs would stabilize the operating steady-state in the presence of cyberattacks. The reasons for this are that 1) actuator cyberattacks may provide rogue signals which could drive the closed-loop state away from the operating steady-state when the sequence is not applied; and 2) the location of the actual state over time in general might be crucial for applying the correct control signal.


\begin{rem}
	Due to the profit loss concerns for the smart actuator concept, it might be considered as a backup strategy to employ if a detection algorithm indicates that the actuators have been compromised.  For example, one could measure the actuator outputs and compare them with what should have been computed for a given sensor measurement. If the expected signals differ significantly from each other, the smart actuator could be activated, which may give enough time to keep the process safe until the problem is solved.
\end{rem}

\begin{rem}
Evolving dynamics in actuators have similar effects compared to an actuator attack in the sense that actuator outputs are no longer computed with full accuracy. One might consider checking the actuator output and the expected value of the actuator output after some fraction of a sampling period after the control signal was received by the actuator to account for potential delays until the actuator output is fully equal to its final value due to the dynamics of the actuator itself.
\end{rem}

\section{Conclusion}

This work explored several concepts for countering cyberattacks on nonlinear systems with evolving dynamics.  The concepts explored included one in which redundant state estimators are used as part of a two-tier detection strategy, where either a bound on the difference between the measurement and estimate of the state or a measurement of the state outside of an operating region in state-space would trigger model re-identification after a certain time period and would cause the threshold on the state estimate and measurement difference to be increased.  A second cyberattack handling approach explored was meant to counter attacks directly on actuators via compensating signals which the actuators could apply. However, extensive case studies may be needed to be performed if a simulation-based approach solely is used to tune the design parameters and identify all possible vulnerabilities. An observation suggested by the results with the actuator compensation is that the different sequence of the inputs and what they were impacted whether certain attacks were successful.  This suggests that detection and attack-handling policies tuned in an \textit{ad hoc} fashion based on simulation, rather than theory, may be sensitive to suboptimality or to initial guesses for nonlinear optimization problems if the algorithms only provide local minima.%, and other aspects of optimization problems which impact the values of inputs obtained specifically from optimization-based control could be challenging for ensuring the security of the system because they would impact which inputs are computed for a given state measurement. %, which could drive the state to different conditions which could be subsequently impacted in different ways by the same subsequent attack.


\section*{Acknowledgment}
Financial support from the Air Force Office of Scientific Research (award number FA9550-19-1-0059), National Science Foundation CNS-1932026 and CBET-1839675, and Wayne State University is gratefully acknowledged.

\begin{thebibliography}{35}
	\bibitem{DING20181674} 
	Ding, D, Han, QL, Xiang, Y, Ge, X, Zhang, XM. A survey on security control and attack detection for industrial cyber-physical systems. \textit{Neurocomputing}. 2018; 275:1674-1683.
	
	%\newblock A survey on security control and attack detection for industrial cyber-physical systems
	%\newblock {Neurocomputing}. 2018; 275:1674-1683.
	
	\bibitem{lezzi2018}
	Lezzi, M, Lazoi, M, Corallo, A. Cybersecurity for Industry 4.0 in the current literature: A reference framework. \textit{Computers in Industry}. 2018; 103:97-110.
	%\newblock Cybersecurity for Industry 4.0 in the current literature: A reference framework
	%\newblock {Computers in Industry}. 2018; 103:97-110.
	
	\bibitem{Ren2017CyberSI}
	Ren, A, Wu, D, Zhang, W, Terpenny, J, Liu, P. Cyber security in smart manufacturing: Survey and challenges. \textit{IIE Annual Conference Proceedings}. 2017;716-21. Pittsburgh, Pennsylvania.
	%	\newblock Cyber security in smart manufacturing: Survey and challenges
	%	\newblock {IIE Annual Conference Proceedings}. 2017; 716-21.
	%	
	\bibitem{TUPTUK201893}
	Tuptuk, N, Hailes, S. Security of smart manufacturing systems. \textit{Journal of Manufacturing Systems}. 2018;47:93-106.
	%	\newblock Security of smart manufacturing systems
	%	\newblock {Journal of Manufacturing Systems}. 2018; 47:93-106.
	%	
	%
	\bibitem{WU20183}
	Wu, D, Ren, A, Zhang, W, Fan, F. Liu, P, Fu, X, Terpenny, J. Cybersecurity for digital manufacturing. \textit{Journal of Manufacturing Systems}. 2018;48:3-12.
	%	\newblock Cybersecurity for digital manufacturing
	%	\newblock {Journal of Manufacturing Systems}. 2018; 48:3-12.	
	
	\bibitem{Uchenna2017}
	Ani, UPD, He, H, Tiwari, A. Review of cybersecurity issues in industrial critical infrastructure: manufacturing in perspective. \textit{Journal of Cyber Security Technology}. 2017;1:32-74.
	
	\bibitem{DESMIT20161060}
	DeSmit, Z, Elhabashy, AE, Wells, LJ, Camelio, JA. Cyber-physical vulnerability assessment in manufacturing systems. \textit{Procedia Manufacturing}. 2016;5:1060-1074.
	
	\bibitem{satchidanandan2017dynamic}
	Satchidanandan, B, Kumar, PR. Dynamic watermarking: Active defense of networked cyber--physical systems. \textit{Proceedings of the IEEE}. 2017;105:219-240.
	
	\bibitem{hoehn2016detection}
	Hoehn, A, Zhang, P. Detection of replay attacks in cyber-physical systems. \textit{Proceedings of the American Control Conference}. 2016;290-295. Boston, Massachusetts.
	
	\bibitem{pasqualetti2013attack}
	Pasqualetti, F, D{\"o}rfler, F, Bullo, F. Attack detection and identification in cyber-physical systems. \textit{IEEE Transactions on Automatic Control}. 2013;58:2715-2729.
	
	\bibitem{mclaughlin2016cybersecurity}
	McLaughlin, S, Konstantinou, C, Wang, X, Davi, L, Sadeghi, AR, Maniatakos, M, Karri, R. The cybersecurity landscape in industrial control systems. \textit{Proceedings of the IEEE}. 2016;104:1039-1057.
	
	\bibitem{teixeira2012revealing}
	Teixeira, A, Shames, I, Sandberg, H, Johansson, KH. Revealing stealthy attacks in control systems. \textit{2012 50th Annual Allerton Conference on Communication, Control, and Computing (Allerton)}. 2012;1806-1813. Monticello, Illinois.
	
	\bibitem{Durand2018169}
	Durand, H. A nonlinear systems framework for cyberattack prevention for chemical process control systems. \textit{Mathematics}. 2018;6:169.
	
	\bibitem{durand2020mitigating}
	Durand, H, Wegener, M. Mitigating safety concerns and profit/production losses for chemical process control systems under cyberattacks via design/control methods. \textit{Mathematics}. 2020;8:499.
	
	\bibitem{liu2011false}
	Liu, Y, Ning, P, Reiter, MK. False data injection attacks against state estimation in electric power grids. \textit{ACM Transactions on Information and System Security (TISSEC)}. 2011;14:1-33.
	
	\bibitem{tran2013detection}
	Tran, TT, Shin, OS, Lee, JH. Detection of replay attacks in smart grid systems. \textit{2013 International Conference on Computing, Management and Telecommunications (ComManTel)}. 2013;298-302. Ho Chi Minh City, Vietnam.
	
	\bibitem{karimipour2019deep}
	Karimipour, H, Dehghantanha, A, Parizi, R, Choo, KKR, Leung, H. A deep and scalable unsupervised machine learning system for cyber-attack detection in large-scale smart grids. \textit{IEEE Access}. 2019;7:80778-80788.
	
	\bibitem{taylor2018probing}
	Taylor, A, Leblanc, S, Japkowicz, N. Probing the limits of anomaly detectors for automobiles with a cyberattack framework. \textit{IEEE Intelligent Systems}. 2018;33:54-62.
	
	\bibitem{Qin2003733}
	Qin, SJ, Badgwell, TA. A survey of industrial model predictive control technology. \textit{Control Engineering Practice}. 2003;11:733-764.
	
	\bibitem{Wu20186}
	Wu, Z, Albalawi, F, Zhang, J, Zhang, Z, Durand, H, Christofides, PD. Detecting and handling cyber-attacks in model predictive control of chemical processes. \textit{Mathematics}. 2018;6:22.
	
	
	
	\bibitem{wu2020post}
	Wu, Z, Chen, S, Rincon, D, Christofides, PD. Post cyber-attack state reconstruction for nonlinear processes using machine learning. \textit{Chemical Engineering Research and Design}. 2020;159:248-261.
	
	\bibitem{ellis2014tutorial}
	Ellis, M, Durand, H, Christofides, PD. A tutorial review of economic model predictive control methods. \textit{Journal of Process Control}. 2014;24:1156-1178.
	
	\bibitem{rawlings2012fundamentals}
	Rawlings, JB, Angeli, D, Bates, CN. Fundamentals of economic model predictive control. \textit{Proceedings of the Conference on Decision and Control}. 2012;3851-3861. Maui, Hawaii.
	
	\bibitem{HUANG2011501}
	Huang, R, Harinath, E, Biegler, LT. Lyapunov stability of economically oriented NMPC for cyclic processes. \textit{Journal of Process Control}. 2011;21:501-509.
	
	\bibitem{Heidarinejad2012855}
	Heidarinejad, M, Liu, J, Christofides, PD. Economic model predictive control of nonlinear process systems using {L}yapunov techniques. \textit{AIChE Journal}. 2012;58:855-870.
	
	\bibitem{Oyama072020}
	Oyama, H, Durand, H. Integrated cyberattack detection and resilient control strategies using Lyapunov-based economic model predictive control. \textit{AIChE Journal}. 2020;66:e17084.
	
	\bibitem{bansal2017hamilton}
	Bansal, S, Chen, M, Herbert, S, Tomlin, CJ. {H}amilton-{J}acobi reachability: A brief overview and recent advances. \textit{Proceedings of the Conference on Decision and Control}. 2017;2242-2253. Melbourne, VIC, Australia.
	
	\bibitem{ames2019control}
	Ames, AD, Coogan, S, Egerstedt, M, Notomista, G, Sreenath, K, Tabuada, P. Control barrier functions: Theory and applications. \textit{Proceedings of the European Control Conference}. 2019;3420-3431. Naples, Italy.
	
	%\bibitem{Helen02162020}
	%Durand, H. Responsive Economic Model Predictive Control for Next-Generation Manufacturing. \textit{Mathematics}. 2020;8:259.
	
	\bibitem{Zhang2015}
	Zhang, X, Clark, M, Rattan, K, Muse, J. Controller verification in adaptive learning systems towards trusted autonomy. \textit{Proceedings of the ACM/IEEE Sixth International Conference on Cyber-Physical Systems}. 2015;31-40. Seattle, Washington.
	
	\bibitem{Alanqar2017b}
	Alanqar, A, Durand, H, Christofides, PD. Error-triggered on-line model identification for model-based feedback control. \textit{AIChE Journal}. 2017;63:949-966.
	
	\bibitem{ahrens2009high}
	Ahrens, JH, Khalil, HK. High-gain observers in the presence of measurement noise: A switched-gain approach. \textit{Automatica}. 2009;45:936-943.
	
	\bibitem{rawlings2000tutorial}
	Rawlings, JB. Tutorial overview of model predictive control. \textit{IEEE Control Systems Magazine}. 2000;20:38-52.
	
	\bibitem{Qin2003survey}
	Qin, SJ, Badgwell, TA. A survey of industrial model predictive control technology. \textit{Control Engineering Practice}. 2003;11:733-764.
	
	\bibitem{Alanqar2015816}
	Alanqar, A, Ellis, M, Christofides, PD. Economic model predictive control of nonlinear process systems using empirical models. \textit{AIChE Journal}. 2015;61:816-830.
	
	\bibitem{Alanqar20153353}
	Alanqar, A, Durand, H, Christofides, PD. On identification of well-conditioned nonlinear systems: Application to economic model predictive control of nonlinear processes. \textit{AIChE Journal}. 2015;61:3353-3373.
	
	\bibitem{Giuliani2018}
	Giuliani, L, Durand, H. Data-based nonlinear model identification in economic model predictive control. \textit{Smart and Sustainable Manufacturing Systems}. 2018;2:61-109.
	
	\bibitem{choudhury2005modelling}
	Choudhury, MAAS, Thornhill, NF, Shah, SL. Modelling valve stiction. \textit{Control Engineering Practice}. 2005;13:641-658.
	
	\bibitem{durand2016actuator}
	Durand, H, Christofides, PD. Actuator stiction compensation via model predictive control for nonlinear processes. \textit{AIChE Journal}. 2016;62:2004-2023.
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%REMOVE ONE THE REFERENCES: durand2020responsive OR Helen02162020
	
%	\bibitem{Cardenas2011355}
%	C{\'a}rdenas, AA, Amin, S, Lin, ZS, Huang, YL, Huang, CY, Sastry, S. Attacks against process control systems: Risk assessment, detection, and response. \textit{Proceedings of the ACM Asia Conference on Computer \& Communications Security}. 2011;355-366.
	
	\bibitem{Cardenas2011}
	C{\'a}rdenas, AA, Amin, S, Lin, ZS, Huang, YL, Huang, CY, Sastry, S. Attacks against process control systems: Risk assessment, detection, and response. \textit{Proceedings of the ACM Asia Conference on Computer \& Communications Security}. 2011;355-366. Hong Kong, China.
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\bibitem{hespanha1999certainty}
	Hespanha, JP, Morse, AS. Certainty equivalence implies detectability. \textit{Systems \& Control Letters}. 1999;36:1-13.
	
	\bibitem{moreno2012observability}
	Moreno, JA, Rocha-C{\'o}zatl, E, Wouwer, AV. Observability/detectability analysis for nonlinear systems with unknown inputs-application to biochemical processes. \textit{2012 20th Mediterranean Conference on Control \& Automation (MED)}. 2012;151-156.  Barcelona, Spain.
	
	\bibitem{moreno2012observability}
	Alessio, A, Bemporad, A. A survey on explicit model predictive control. In: Magni L, Raimondo DM, Allg{\"{o}}wer F (eds) \textit{Nonlinear Model Predictive Control}. Lecture Notes in Control and Information Sciences, vol 384.  Berlin, Heidelberg: Springer; 2009:345-369.
	
	\bibitem{oberdieck2017explicit}
	Oberdieck, R, Diangelakis, NA, Pistikopoulos, EN. Explicit model predictive control: A connected-graph approach. \textit{Automatica}. 2017;76:103-112.
	
	\bibitem{lucia2018deep}
	Lucia, S, Karg, B. A deep learning-based approach to robust nonlinear model predictive control. \textit{IFAC-PapersOnLine}. 2018;51:511-516.
	
	\bibitem{DurandIFACWC2020}
	Durand, H. Anomaly-handling in Lyapunov-based economic model predictive control via empirical models. \textit{Proceedings of the 2020 IFAC World Congress}. 2020. Virtual.
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%REMOVE ONE THE REFERENCES: durand2020responsive OR Helen02162020
	
	\bibitem{durand2020responsive}
	Durand, H. Responsive economic model predictive control for next-generation manufacturing. \textit{Mathematics}. 2020;8:259.
	
%	\bibitem{Helen02162020}
%	Durand, H. Responsive Economic Model Predictive Control for Next-Generation Manufacturing. \textit{Mathematics}. 2020;8:259.
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\bibitem{Khalil2002}
	Khalil, HK. Nonlinear Systems. 3rd ed. Prentice Hall; 2002.
	
	\bibitem{heidarinejad2012state}
	Heidarinejad, M, Liu, J, Christofides, PD. State-estimation-based economic model predictive control of nonlinear systems. \textit{Systems \& Control Letters}. 2012;61:926-935.
	
	\bibitem{RANGAN2021147}
	Rangan, KK, Oyama, H, Durand, H. Integrated cyberattack detection and handling for nonlinear systems with evolving process dynamics under Lyapunov-based economic model predictive control. \textit{Chemical Engineering Research and Design}. 2021;170:147-179.
	
	\bibitem{Khorrami}
	Khorrami, F, Krishnamurthy, P, Karri, R. State-estimation-based economic model predictive control of nonlinear systems. \textit{IEEE Design \& Test}. 2016;33:75-83.
	
\end{thebibliography}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is just an example/guide for you to refer to when submitting manuscripts to Frontiers, it is not mandatory to use Frontiers .cls files nor frontiers.tex  %
% This will only generate the Manuscript, the final article will be typeset by Frontiers after acceptance.   
%                                              %
%                                                                                                                                                         %
% When submitting your files, remember to upload this tex file, the pdf generated with it, the bib file (if bibliography is not within the tex) and all the figures.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Version 3.4 Generated 2018/06/15 %%%
%%% You will need to have the following packages installed: datetime, fmtcount, etoolbox, fcprefix, which are normally inlcuded in WinEdt. %%%
%%% In http://www.ctan.org/ you can find the packages and how to install them, if necessary. %%%
%%%  NB logo1.jpg is required in the path in order to correctly compile front page header %%%

\documentclass[utf8]{frontiersSCNS} % for Science, Engineering and Humanities and Social Sciences articles
%\documentclass[utf8]{frontiersHLTH} % for Health articles
%\documentclass[utf8]{frontiersFPHY} % for Physics and Applied Mathematics and Statistics articles

%\setcitestyle{square} % for Physics and Applied Mathematics and Statistics articles
\usepackage{url,hyperref,lineno,microtype,subcaption}
\usepackage[onehalfspacing]{setspace}

\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{subcaption}
%\usepackage[superscript]{cite}
\usepackage{placeins}
\usepackage{siunitx}
%\usepackage{lineno,hyperref}
\usepackage{amsmath}                    % AMS Math package
\usepackage{graphicx}                    % EPS figures
\usepackage{epstopdf}                    % EPS to PDF
\usepackage[T1]{fontenc}                % For font encodings
\usepackage{float}                        % Float package for H option on fig float
\usepackage{caption}                    % Use for captionof command
%\usepackage{titlesec}                    % Change section headings
\usepackage{paracol}                    % (Easily) Split page into columns
\usepackage{booktabs}                    % Publication style tables
%\usepackage[margin=1in]{geometry}        % Page margins
\usepackage{atbegshi}
%\setcounter{secnumdepth}{4}

\theoremstyle{plain}
\newtheorem{thm}{Theorem}
\newtheorem{prop}{Proposition}
\newtheorem{assump}{Assumption}
\theoremstyle{remark}
\newtheorem{rmk}{Remark}
\newtheorem{alg}{Algorithm}
\newtheorem{lemma}{Lemma}
\newtheorem{Definition}{Definition}
% Macros
\newcommand{\m}{\mathbb}
%\providecommand{\keywords}[1]{\noindent\textit{Keywords:} #1}
%\renewcommand{\refname}{Literature Cited}

% Operators
\DeclareMathOperator{\argmin}{arg\,min}
\DeclareMathOperator{\argmax}{arg\,max}

\newcommand{\R}{\mathbb{R}}				% Real numbers
\newcommand{\set}[1]{\mathbb{#1}}		% Set notation
\newcommand{\sr}{\Omega_{\rho}}			% Omega_{rho}
\newcommand{\sre}{\Omega_{\rho_e}}		% Omega_{rho_e}
\newcommand{\srarg}[1]{\Omega_{#1}}

\linenumbers


% Leave a blank line between paragraphs instead of using \\


\def\keyFont{\fontsize{8}{11}\helveticabold}
\def\firstAuthorLast{Oyama {et~al.}} %use et al only if is more than 1 author
\def\Authors{Henrique Oyama\,$^{1}$, Dominic Messina\,$^{1}$, Helen Durand\,$^{1,*}$, and Keshav Kasturi Rangan\,$^{1}$}
% Affiliations should be keyed to the author's name with superscript numbers and be listed as follows: Laboratory, Institute, Department, Organization, City, State abbreviation (USA, Canada, Australia), and Country (without detailed address information such as city zip codes or street names).
% If one of the authors has a change of address, list the new address below the correspondence details using a superscript symbol and use the same symbol to indicate the author in the author list.
\def\Address{$^{1}$Department of Chemical Engineering and Materials Science, Wayne State University, Detroit, MI 48202, USA}
% The Corresponding Author should be marked with an asterisk
% Provide the exact contact address (this time including street name and city zip code) and email of the corresponding author
\def\corrAuthor{Corresponding Author}

\def\corrEmail{helen.durand@wayne.edu}




\begin{document}
\onecolumn
\firstpage{1}

\title[LEMPC for Simultaneous Sensor and Actuator Cyberattacks]{Lyapunov-Based Economic Model Predictive Control for Detecting and Handling Actuator and Simultaneous Sensor/Actuator Cyberattacks on Process Control Systems} 

\author[\firstAuthorLast]{\Authors} %This field will be automatically populated
\address{} %This field will be automatically populated
\correspondance{} %This field will be automatically populated

\extraAuth{}% If there are more than 1 corresponding author, comment this line and uncomment the next one.
%\extraAuth{corresponding Author2 \\ Laboratory X2, Institute X2, Department X2, Organization X2, Street X2, City X2 , State XX2 (only USA, Canada and Australia), Zip Code2, X2 Country X2, email2@uni2.edu}


\maketitle


\begin{abstract}
	\section{}
The controllers for a cyber-physical system may be impacted by sensor measurement cyberattacks, actuator signal cyberattacks, or both types of attacks.  Prior work in our group has developed theory for handling cyberattacks on process sensors.  However, sensor and actuator cyberattacks have a different character from one another.  Specifically, sensor measurement attacks prevent proper inputs from being applied to the process by manipulating the measurements which the controller receives, so that the control law plays a role in the impact of a given sensor measurement cyberattack on a process.  In contrast, actuator signal attacks prevent proper inputs from being applied to a process by bypassing the control law to cause the actuators to apply undesirable control actions.  Despite these differences, this manuscript shows that we can extend and combine strategies for handling sensor cyberattacks from our prior work to handle attacks on actuators and to handle cases where sensor and actuator attacks occur at the same time.  These strategies for cyberattack-handling and detection are based on Lyapunov-based economic model predictive control (LEMPC) and nonlinear systems theory.  We first review our prior work on sensor measurement cyberattacks, providing several new insights regarding the methods.  We then discuss how those methods can be extended to handle attacks on actuator signals, and then how the strategies for handling sensor and actuator attacks individually can be combined to produce a strategy that is able to guarantee safety when attacks are not detected, even if both types of attacks are occurring at once.  We also demonstrate that other combinations of the sensor and actuator attack-handling strategies cannot achieve this same effect.  Subsequently, we provide a mathematical characterization of ``discoverability'' of cyberattacks that enables us to consider the various strategies for cyberattack detection presented in a more general context.  We conclude by presenting a reactor example that showcases aspects of designing LEMPC.
\tiny
 \keyFont{ \section{Keywords:} Cyber-physical system, economic model predictive control, nonlinear systems, cyberattack detection, sensor attack, actuator attack} %All article types: you may provide up to 8 keywords; at least 5 are mandatory.
\end{abstract}

\section{Introduction}

Cyber-physical systems (CPS's) integrate various physical processes with computer and communication infrastructures, which allows enhanced process monitoring and control. Though CPS's open new avenues for advanced manufacturing~\cite{davis2015smart} in terms of increased production efficiency, quality of the production, and cost reduction, this integration also opens these systems to malicious cyberattacks that can exploit vulnerable communication channels between the different layers of the system. In addition to process and network cybesecurity concerns, data collection devices such as sensors and final control elements such as actuators (and signals to or from them) are also potential candidates that can be subject to cyberattacks \cite{TUPTUK201893}. Sophisticated and malicious cyberattacks may affect industrial profits and even pose a threat to the safety of individuals working on site, which motivates attack-handling strategies that are geared toward providing safety assurances for autonomous systems. %commonly referred to as Industry 4.0\cite{davis2015smart} 

There exist multiple points of susceptibility in a CPS framework ranging from communication networks and protocols to sensor measurement and control signal transmission, requiring the development of appropriate control and detection techniques to tackle such cybersecurity challenges \cite{pasqualetti2013attack}. To better understand these concerns, vulnerability identification \cite{Uchenna2017} has been studied by combining people, process, and technology perspectives. A process engineering-oriented overview of different attack events has been discussed in \cite{setola2019overview} to illustrate the impacts on industrial control system platforms. In order to address concerns related to control components, resilient control designs based on state estimates have been proposed for detecting and preventing attacks in works such as \cite{ding2020secure} and \cite{Cardenas2011355}, where in the latter cyberattack-resilient control frameworks compare state estimates based on models of the physical process and state measurements to detect cyberattacks.  \cite{ye2019co} addresses a scenario where actuator faults and cyberattacks on sensors or actuators occur simultaneously by using a control policy based on Lyapunov theory, adaptation, and Nussbaum-type functions.

Cybersecurity-related studies have also been carried out in the context of model predictive control (MPC~\cite{Qin2003733}), an optimization-based control methodology that computes optimal control actions to a process. Specifically, for nonlinear systems, \cite{Durand2018169} investigated various MPC techniques with economics-based objective functions (known as economic MPC's (EMPC's)~\cite{Ellis20141156,Rawlings20123851}) when only false sensor measurements are considered. \cite{chen2020cyber} integrated a neural network-based attack detection approach initially proposed in \cite{Wu20186} with a two-fold control structure, in which the upper layer is a Lyapunov-based MPC designed to ensure closed-loop stability after attacks are flagged. A methodology that may be incorporated as a criterion for EMPC design has been proposed in \cite{narasimhan2021detectability}, in which a control parameter screening based on a residual-based attack detection scheme classifies multiplicative sensor-controller attacks on a process as ``detectable'', ``undetectable'', and ``potentially detectable'' under certain conditions. In addition, a general description of ``cyberattack discoverability'' (i.e., a certain system's capability to detect attacks) without a rigorous mathematical formalism has been addressed in \cite{oyamahandling2021}.  
%as well as develop game-theoretic frameworks to access security risks of cyber-physical systems \cite{amin2013quest}, were undertaken in the past. Moreover, to further understand the the impact of cyberattacks on process and control systems, multiple papers have been published on this topic \cite{pasqualetti2013attack, li2015stochastic}. 
%As a consequence of most real world processes displaying nonlinear dynamics, our research group has directed prior work toward addressing the impact of cyberattacks on systems with nonlinear dynamics. Some of the prior work from our research group include \cite{Oyama2020, rangan2021integrated, Rangan2021actuator} where initial works proposed the formulation of cyberattack detection strategies to guarantee recursive feasibility and stability in the presence of cyberattacks on process sensors. This proposal was then extended to account for nonlinear systems with evolving or changing dynamics which makes it difficult to differentiate from cyberattacks in addition to developing an explicit relationship between the choice of numerical method used in the evaluation of control inputs to its impact on safety and feasibility guarantees. More recent works in this topic address the detection of cyberattacks on process actuators as these components are critical to effective control actions that ensure safety and stability of various processes running in a plant. 

Prior work in our group has explored the interaction between cyberattack detection strategies, MPC/EMPC design, and stability guarantees. In particular, our prior works have primarily focused on studying and developing control/detection mechanisms for scenarios in which either actuators or sensors are attacked \cite{oyama2020integrated,rangan2021integrated,oyamahandling2021,durand2020mitigating}. For example, \cite{oyama2020integrated} proposed three cyberattack detection concepts that are integrated with the control framework Lyapunov-based EMPC~\cite{Heidarinejad2012855}. Advancing this work, \cite{rangan2021integrated} and \cite{oyamahandling2021} proposed ways to consider cyberattack detection strategies and the challenges in cyberattack-handling for nonlinear processes whose dynamics change with time. In the present manuscript, we extend our prior work (which covered sensor measurement cyberattack-handling with control-theoretic guarantees and actuator cyberattack-handling without guarantees) to develop strategies for maintaining safety when actuator attacks are not detected (assuming that no attack occurs on the sensors).  These strategies are inspired by the first detection concept in \cite{oyama2020integrated}, but with a modified implementation strategy to guarantee that even when an undetected actuator attack occurs, the state measurement and actual closed-loop state are maintained inside a safe region of operation throughout the next sampling period. 

The primary challenge addressed by this work is the question of how to develop an LEMPC-based strategy for handling sensor and actuator cyberattacks occurring at once.  The reason that this is a challenge is that some of the concepts discussed for handling sensor and actuator cyberattacks only work if the other (sensors or actuators) is not under an attack.  A major contribution of the present manuscript, therefore, is elucidating which sensor and actuator attack-handling methods can be combined to provide safety in the presence of undetected attacks, even if both undetected sensor and actuator attacks are occurring at the same time.  To cast this discussion in a broader framework, we also present a nonlinear systems definition of cyberattack ``discoverability,'' which provides fundamental insights into how attacks can fly under the radar of detection policies.  Finally, we elucidate properties of cyberattack-handling using LEMPC through simulation studies. 

The manuscript is organized as follows: following some preliminaries which clarify the class of systems under consideration and the control design (LEMPC) from which the cyberattack detection and handling concepts presented in this work are derived, we review the sensor measurement cyberattack detection and handling policies from \cite{oyama2020integrated}, which form the basis for the development of the actuator signal cyberattack-handling and combined sensor/actuator cyberattack-handling policies subsequently developed.  Subsequently, we propose strategies for detecting and handling cyberattacks on process actuators when the sensor measurements remain intact that are able to maintain safety even when actuator cyberattacks are undetected.  We then utilize the insights and developments of the prior sections to clarify which sensor and actuator attack-handling policies can be combined to achieve safety in the presence of combined sensor and actuator cyberattacks.  We demonstrate that there are combinations of methods which can guarantee safety in the presence of undetected attacks, even if these attacks occur on both sensors and actuators at the same time (though the other combinations of the discussed methods cannot achieve this).  Further insights on the interactions between detection strategies and control policies for nonlinear systems are presented via a fundamental nonlinear systems definition of discoverability.  The work closes with a reactor study which probes the question of the practicality of the design of control systems which meet the theoretical guarantees for achieving cyberattack-resilience.

 %Overall, this paper is structured as follows: after describing preliminaries (the class of nonlinear systems considered in this work and observer assumptions), we summarize and highlight important aspects of the control/detection strategies proposed in \cite{oyama2020integrated}, which form the basis for the development of a unified detection/control framework presented in this work. Specifically, we propose a simultaneous probing mechanism for sensor and actuator attacks that integrates the detection strategies presented in our prior works and we explain why a particular combination of the attack detection strategies in \cite{oyama2020integrated} can make CPS's cyberattack-resilient (when other combinations do not provide the same result). A chemical process example is used to illustrate the proposed control/detection framework. Finally, built upon the notion of cyberattack discoverability defined in \cite{oyamahandling2021}, we mathematically characterize and formalize this concept in light of sensor attacks, actuator attacks, and combined sensor and actuator attacks.

%This also has a potential benefit in the context of other prior work in our group from~\cite{durand2020responsive}.  Specifically,~\cite{durand2020responsive} has developed theoretical conditions which guarantee that a pre-specified amount of time can exist for LEMPC before the closed-loop state would leave a safe operating region after a change in the underlying process dynamics is detected.  After that pre-specified time period, the new process dynamics would need to be identified with sufficient accuracy to enable control laws that are stabilizing for the new process dynamics to be able to be placed on-line to continue to ensure stability.  Depending how much time it is desired to leave between when the underlying dynamics change and when the model is re-identified, it may be beneficial to explore a probing strategy like that in~\cite{oyama2021NMPCSubmitted} for guaranteeing stability during attempts to find out as quickly as possible which models could be correct to meet the time requirement for stability in the face of the changing process dynamics.

\section{Preliminaries}
\subsection{Notation}
The Euclidean norm of a vector is indicated by $|\cdot|$ and the transpose of a vector $x$ is denoted by $x^T$. A continuous function $\alpha : [0,a) \rightarrow [0,\infty)$ is said to be of class $\mathcal{K}$ if it is strictly increasing and $\alpha(0) = 0$. Set subtraction is designated by $x \in A / B := \{ x \in R^n : x \in A, x \notin B\}$. Finally, a level set of a positive definite function $V$ is denoted by $\Omega_{\rho} := \{ x\in R^n : V(x) \leq \rho \}$.

\subsection{Class of Systems} \label{sec:ClassOfSystems}
% The class of nonlinear system of Eq.~\ref{eq:ClassofSystems} may also include the dynamics of the actuator. In this case, Eq.~\ref{eq:ClassofSystems} can be rewritten as $\dot{x}(t)= f(x(t),g_{v}(x_{v}(t)),w(t))$, where $g_{v}(x_{v}(t))$ is a vector function based on the actuator/valve position $x_{v}(t)$ \cite{durand2016actuator}. Similarly, we assume that each input $g_{v,i}(x_{v,i}(t))$, $i=1,2,\dots,m$, to the process is bounded within $U$ ($U := g_{v,i}(x_{v,i}(t)) | u_{i,min} \leq g_{v,i}(x_{v,i}(t)) \leq u_{i,max}$).
This work considers the following class of nonlinear systems:
\begin{equation} \label{eq:ClassofSystems}
\begin{aligned}
\dot{x}(t)= f(x(t),u(t),w(t)) 
\end{aligned}
\end{equation}
where $x \in X \subset R^n$ and $w \in W \subset R^z$ ($W :=\{w \in R^z ~|~|w| \leq \theta_w,~\theta_w > 0\}$) are the state and disturbance vectors, respectively. The input vector function $u \in U \subset R^m$, where $U := \{ u \in R^m | ~|u| \leq u^{\max} \}$. $f$ is locally Lipschitz on $X \times U \times W$ and we consider that the ``nominal'' system of Eq.~\ref{eq:ClassofSystems} ($w \equiv 0$) is stabilizable such that there exists an asymptotically stabilizing feedback control law $h(x)$, a sufficiently smooth Lyapunov function $V$, and class $\mathcal{K}$ functions $\alpha_i(\cdot)$, $i=1,2,3,4$, where:
\begin{subequations} \label{eq:constraintsLyapunovA}
	\begin{align}
	&\alpha_{1} (|x|) \le V(x) \le \alpha_{2} (|x|) \label{eq:constraintsLyapunov1} \\
	&\frac {\partial V(x)} {\partial x} \; f (x,h(x),0) \le -\alpha_{3}(|x|) \label{eq:constraintsLyapunov2} \\
	&\biggl|\frac {\partial V(x)} {\partial x} \biggl| \le \alpha_{4}(|x|) \label{eq:constraintsLyapunov3} \\
	&h(x) \in U \label{eq:constraintsLyapunov4}
	\end{align}
\end{subequations}
$\forall ~x\in D \subset R^n$ ($D$ is an open neighborhood of the origin). We define $\Omega_{\rho} \subset D$ to be the stability region of the nominal closed-loop system under the controller $h(x)$ and require that it be chosen such that $x \in X$,  $\forall x \in \Omega_{\rho} $.  Furthermore, we consider that $h(x)$ satisfies:
\begin{equation}
|\hat{h}_{i}(x) - \hat{h}_{i}(\hat{x})| \leq L_h|x - \hat{x}| \label{eq:Lipschitzh}
\end{equation}
for all $x,\hat{x} \in \Omega_{\rho}$, with $L_h > 0$, where $\hat{h}_{i}$ is the $i$-th component of $h$.

Since $f$ is locally Lipschitz and $V(x)$ is a sufficiently smooth function, the following hold:
\begin{subequations} 
	\label{eq:Lipschitz}
	\begin{align}
	&|f(x_1,u,w) - f(x_2,u,0)| \le L_x |x_1 - x_2| + L_w |w| \label{eq:Lipschitz1}\\
	&\biggl|\frac {\partial V(x_1)} {\partial x} \; f ({x_1},u,w) - \frac {\partial V(x_2)} {\partial x} \; f ({x_2},u,0)\biggl| \le L_{x}' |x_1 - x_2| + L_{w}'|w| 	\label{eq:Lipschitz2} \\
	&|f(x_1,u_1,w) - f(x_1,u_2,w)| \leq L_u|u_1 - u_2| \label{eq:LipschitzInu}
	\end{align}
\end{subequations}
\begin{equation}
|f(x,u,w)| \le M_f \label{eq:FBound}
\end{equation}
$ \forall x_1,x_2 \in \Omega_{\rho}$, $u, u_1, u_2 \in U$ and $w \in W$, where $L_x, L_{x}', L_{w},$ $ L_{w}'$, and $M_f$ are positive constants.

We also assume that there are $M$ sets of measurements $y_i \in R^{q_i}$, $i=1,\ldots,M$, available at $t_k$ as follows:
\begin{equation}
y_i(t) = k_i(x(t)) + v_i(t) \label{eq:Measurementi}
\end{equation}
where $k_i$ is a vector-valued function, and $v_i$ represents the measurement noise associated with the measurements $y_i$.  We assume that the measurement noise is bounded (i.e., $v_i \in V_i :=\{ v_i \in R^{q_i} ~|~ |v_i| \leq \theta_{v,i},~\theta_{v,i} > 0$) and that measurements of each $y_i$ are continuously available.  For each of the $M$ sets of measurements, we assume that there exists a deterministic observer (e.g., a high-gain observer~\cite{AHRENS2009936}) described by the following dynamic equation:
\begin{equation}
\dot{z}_i = F_i(\epsilon_i,z_i,y_i) \label{eq:Observeri}
\end{equation}
where $z_i$ is the estimate of the process state from the $i$-th observer, $i=1,\ldots,M$, $F_i$ is a vector-valued function, and $\epsilon_i > 0$.  When a controller $h(z_i)$ with Eq.~\ref{eq:Observeri} is used to control the closed-loop system of Eq.~\ref{eq:ClassofSystems}, we consider that Assumptions~\ref{assum:Assum1}-\ref{assum:Assum2} below hold.
\begin{assump} \label{assum:Assum1} \cite{ELLIS2014101,Lao20153374} 
	There exist positive constants $\theta_{w}^*$, $\theta_{v,i}^*$, such that for each pair $\{ \theta_{w},\theta_{v,i} \}$ with $\theta_{w} \leq \theta_{w}^*$, $\theta_{v,i} \leq \theta_{v,i}^*$, there exists $0 < \rho_{1,i} < \rho$, $e_{m0i} > 0$ and $\epsilon_{Li}^* > 0$, $\epsilon_{Ui}^* > 0$ such that if $x(0) \in \Omega_{\rho_{1,i}}$, $|z_i(0) - x(0)| \leq e_{m0i}$ and $\epsilon_i \in (\epsilon_{Li}^*,\epsilon_{Ui}^*)$, the trajectories of the closed-loop system are bounded in $\Omega_{\rho}$, $\forall~ t \geq 0$.
\end{assump}
\begin{assump} \label{assum:Assum2} \cite{ELLIS2014101,Lao20153374}
	There exists $e_{mi}^* > 0$ such that for each $e_{mi} \geq e_{mi}^*$, there exist $t_{bi}(\epsilon_i)$ such that $|z_i(t) - x(t)| \leq e_{mi}$, $\forall ~ t\geq t_{bi}(\epsilon_i)$.
\end{assump} 

\section{Economic Model Predictive Control}

EMPC~\cite{Ellis20141156} is an optimization-based control design for which the control actions are computed via the following optimization problem:
\begin{subequations} 
	\label{eq:MPCEqn}
	\begin{align}
	\min_{u(t) \in S(\Delta)}\hspace{3mm} & \int_{t_k}^{t_{k+N}} L_{e}(\tilde{x}(\tau),u(\tau)) \, d\tau  \label{eq:MPCEqn:Objective} \\
	\text{s.t.} \hspace{3mm} & \dot{\tilde{x}}(t) = f(\tilde{x}(t),u(t),0)  \label{eq:MPCEqn:Model} \\
	& \tilde{x}(t_k) = x(t_k)  \label{eq:MPCEqn:Measurement} \\
	& \tilde{x}(t) \in X, \, \forall \, t \in [t_k, t_{k+N}) \label{eq:MPCEqn:StateConstraint}  \\
	& u(t) \in U, ~ \forall \, t \in [t_k, t_{k+N}) \label{eq:MPCEqn:InputConstraint} 
	\end{align}
\end{subequations}
where $N$ is called the prediction horizon, and $u(t)$ is a piecewise-constant input trajectory with $N$ pieces, where each piece is held constant for a sampling period with time length $\Delta$. The economics-based stage cost $L_e$ of Eq.~\ref{eq:MPCEqn:Objective} is evaluated throughout the prediction horizon using the future predictions of the process state $\tilde{{x}}$ from the model of Eq.~\ref{eq:MPCEqn:Model} (the nominal model of Eq.~\ref{eq:ClassofSystems}) initialized from the state measurement at $t_k$ (Eq.~\ref{eq:MPCEqn:Measurement}). The process constraints of Eqs.~\ref{eq:MPCEqn:StateConstraint}-\ref{eq:MPCEqn:InputConstraint} are state and input constraints, respectively. A receding or moving horizon implementation strategy is employed, i.e., the optimization problem is solved every $\Delta$ time units (at each sampling time $t_k$) such that the first of the $N$ pieces of the input vector trajectory that is the optimal solution is applied to the process. The optimal solution at $t_k$ is denoted by ${u}^*(t_i|t_k)$, where $i=k,\ldots,k+N-1$. 

Additional constraints which can be added to the formulation in Eq.~\ref{eq:MPCEqn} to produce a formulation of EMPC that takes advantage of the Lyapunov-based controller $h(\cdot)$, called Lyapunov-based EMPC (LEMPC~\cite{Heidarinejad2012855}), are as follows: %~\cite{Heidarinejad2012855}
\begin{subequations} \label{eq:LEMPCConstraints}
	\begin{align}
	& V(\tilde{{x}}(t)) \le \rho_{e}',\; \; \forall \, t \in [t_k, t_{k+N}), ~~ \text {if}~ {x}(t_k) ~ \in ~\Omega_{{\rho}_{e}'} \label{eq:LEMPCEqnconstraints:1} \\
	& \frac{\partial V(\tilde{x}(t_k))} {\partial {x}}f({\tilde{x}}(t_k),u(t_k),0)  \le \frac {\partial V(\tilde{x}(t_k))} {\partial {x}} \; {f}(\tilde{x}(t_k),h(\tilde{x}(t_k)),0), ~~ \text {if} \;\; \tilde{x}(t_k) \in \Omega_{{\rho}} / \Omega_{{\rho}_{e}'} \label{eq:LEMPCEqnconstraints:2}
	\end{align}
\end{subequations}	
where $\Omega_{{\rho}_{e}'} \subset \Omega_{{\rho}}$ is a subset of the stability region that makes $\Omega_{{\rho}}$ forward invariant under the controller of Eqs.~\ref{eq:MPCEqn}-\ref{eq:LEMPCConstraints}. 

\section{Cyberattack Detection and Control Strategies using LEMPC under Single Attack Type Scenarios: Sensor Attacks} \label{sec:LEMPCsensors}

The major goal of this work is to extend the strategies for LEMPC-based sensor measurement cyberattack detection and handling from \cite{oyama2020integrated} to handle actuator attacks and simultaneous sensor measurement and actuator attacks.  For clarity of this discussion, we first review the three cyberattack detection mechanisms from \cite{oyama2020integrated}.  

This section therefore considers a single attack type scenario (i.e., only the sensor readings are impacted by attacks). The first control/detection strategy proposed in \cite{oyama2020integrated} switches between a full state feedback LEMPC and variations on that control design that are randomly generated over time to probe for cyberattacks by evaluating state trajectories for which it is theoretically known that a Lyapunov function must decrease over subsequent sampling times. The second control/detection strategy also uses full state feedback LEMPC, but the detection is achieved by evaluating the state predictions based on the current and prior state measurements to flag an attack while maintaining the closed-loop state within a predefined safe region over one sampling period after an undetected attack is applied. The third control/detection strategy was developed using output feedback LEMPC and the detection is attained by checking among multiple redundant state estimates to flag that an attack is happening when the state estimates do not agree while still ensuring closed-loop stability under sufficient conditions (which include the assumption that at least one of the estimators cannot be affected by the attack). In addition to reviewing key features of this design, this section will provide several clarifications that were not provided in \cite{oyama2020integrated} to enable us to build upon these methods in future sections.

%In this work, we take advantage of the first detection/control strategy proposed in \cite{oyama2020integrated} and modify it for the single attack case where only actuator outputs are compromised (i.e., sensors are not impacted by any attack). This has particular value since safety can be maintained even in the presence of actuator attacks (this could not be achieved with a similar strategy for the case when only the sensors are compromised as the falsified state measurements do not reflect the actual states) as long as the Lyapunov function decreases over time as expected by this control implementation. In the next sections, we summarize and provide important comments on the detection strategies presented in \cite{oyama2020integrated} as they form the basis for the combined control/detection framework developed in this paper. 

%\subsection{Control/Detection Strategies using LEMPC in the Presence of Sensor Attacks} \label{sec:LEMPCsensor}
\subsection{Control/Detection Strategy 1-S using LEMPC in the Presence of Sensor Attacks} \label{sec:LEMPCsensor1}

The control/detection strategy 1-S, which corresponds to the first detection concept proposed in \cite{oyama2020integrated}, uses full state feedback LEMPC as the baseline controller and randomly develops other LEMPC formulations with Eq.~\ref{eq:LEMPCEqnconstraints:2} always activated that are used in place of the baseline controller for short periods of time to potentially detect if an attack is occurring. We define specific times at which the switching between the baseline 1-LEMPC and the $j$-th LEMPC, $j > 1$, happens. Particularly, $t_{s,j}$ is defined as the switching time at which the $j$-LEMPC is used to drive the closed-loop state to the randomly generated $j$-th steady-state, and $t_{e,j}$ is the time at which the $j$-LEMPC switches back to operation under the $1$-LEMPC. 

The baseline 1-LEMPC is formulated as follows, which is used if $t_{e,j-1} \leq t < t_{s,j}$, $j=2,\ldots$, where $t_{e,1} = 0$:
\begin{subequations} \label{eq:p-LEMPCEqn1s}
	\begin{align}
	\min_{u_1(t) \in S(\Delta)}\hspace{3mm} & \int_{t_k}^{t_{k+N}} L_{e}(\tilde{x}_1(\tau),u_1(\tau)) \, d\tau  \label{eq:p-LEMPCEqn1s:Objective} \\
	\text{s.t.} \hspace{3mm} & \dot{\tilde{x}}_1(t) = f_1(\tilde{x}_1(t),u_1(t),0)  \label{eq:p-LEMPCEqn1s:Model} \\ %f_i(x(t)) + g_i(x(t))u_i(t)
	& \tilde{x}_1(t_k) = x_{1}(t_k)  \label{eq:p-LEMPCEqn1s:Measurement} \\
	& \tilde{x}_1(t) \in X_1, \, \forall \, t \in [t_k, t_{k+N}) \label{eq:p-LEMPCEqn1s:StateConstraint}  \\
	& u_1(t) \in U_1, ~ \forall \, t \in [t_k, t_{k+N}) \label{eq:p-LEMPCEqn1s:InputConstraint} \\
	& V_1(\tilde{x}_1(t)) \le \rho_{e,1}',\; \; \forall \, t \in [t_k, t_{k+N}), ~ \text {if}~ \tilde{x}_1(t_k) ~ \in ~\Omega_{\rho_{e,1}'} \label{eq:p-LEMPCEqn1sconstraints:1} \\
	& \frac{\partial V_1(\tilde{x}_1(t_k))} {\partial x} f_1(\tilde{x}_1(t_k),u_1(t_k),0) \le \frac {\partial V_1(\tilde{x}_1(t_k))} {\partial x} \;  f_1(\tilde{x}_1(t_k),h_1(\tilde{x}_1(t_k)),0),~ \text {if} \;\; \tilde{x}_1(t_k) \in \Omega_{\rho_1} / \Omega_{\rho_{e,1}'} \label{eq:p-LEMPCEqn1sconstraints:2}
	\end{align}
\end{subequations}
where $x_{1}(t_k)$ is used, with slight abuse of notation, to reflect the state measurement in deviation variable form from the operating steady-state. In addition, in the remainder of this work, $f_i$ ($i \ge 1$) represents the right-hand side of Eq.~\ref{eq:ClassofSystems} when it is written in deviation variable form from the $i$-th steady-state.  $u_i$ represents the input vector in deviation variable form from the steady-state input associated with the $i$-th steady-state.  $X_i$ and $U_i$ correspond the state and input constraint sets in deviation variable form from the $i$-th steady-state. In addition, $\rho_i$ and $\rho_{e,i}'$ are associated with the $i$-th steady-state.  Addition of a subscript $i$ to the functions in Eq.~\ref{eq:constraintsLyapunovA} (to form $h_i$, $V_i$, and $\alpha_{j,i}$, $j=1,2,3,4$) or $M_f$ also signifies association with the $i$-th steady-state.

The $j$-th LEMPC, $j > 1$, which is used for $t \in [t_{s,j}, t_{e,j})$, is formulated as follows:
\begin{subequations} \label{eq:p-LEMPCEqn2s}
	\begin{align}
	\min_{u_j(t) \in S(\Delta)}\hspace{3mm} & \int_{t_k}^{t_{k+N}} L_{e}(\tilde{x}_j(\tau),u_j(\tau)) \, d\tau  \label{eq:p-LEMPCEqn2s:Objective} \\
	\text{s.t.} \hspace{3mm} & \dot{\tilde{x}}_j(t) = f_j(\tilde{x}_j(t),u_j(t),0)   \label{eq:p-LEMPCEqn2s:Model} \\
	& \tilde{x}_j(t_k) = x_{j}(t_k)  \label{eq:p-LEMPCEqn2s:Measurement} \\
	& \tilde{x}_j(t) \in X_j, \, \forall \, t \in [t_k, t_{k+N}) \label{eq:p-LEMPCEqn2s:StateConstraint}  \\
	& u_j(t) \in U_j, ~ \forall \, t \in [t_k, t_{k+N}) \label{eq:p-LEMPCEqn2s:InputConstraint} \\
	& \frac{\partial V_j(\tilde{x}_j(t_k))} {\partial x} f_j(\tilde{x}_j(t_k),u_j(t_k),0) \le \frac{\partial V_j(\tilde{x}_j(t_k))} {\partial x} \;  f_j(\tilde{x}_j(t_k),h_j(\tilde{x}_j(t_k)),0)  \label{eq:p-LEMPCEqn2constraints:2}
	%& \quad \text {if} \;\; x(t_k) \in \Omega_{\rho,j} / \Omega_{\rho_{e,j}} ~ or ~ t_{s,i} \leq t_k \leq t_{e,i} \label{eq:p-LEMPCEqn1constraints:2}
	\end{align}
\end{subequations}	
where $x_{j}(t_k)$ represents the state measurement in deviation variable form from the $j$-th steady-state. 

The implementation strategy for this detection method is as follows (the stability region subsets are thoroughly detailed in \cite{oyama2020integrated}, but reviewed in Remark~\ref{NestedRegions}):

\begin{enumerate}
	\item \label{step:Step1c} At a sampling time $t_k$, the baseline $1$-LEMPC receives the state measurement $\tilde{x}_{1}(t_k)$. Go to Step \ref{step:Step2c}.
	\item \label{step:Step2c} At $t_k$, a random number $\zeta$ is generated.  If this number falls within a range that has been selected to start probing for cyberattacks, randomly generate a $j$-th steady-state, $j > 1$, with a stability region $\Omega_{\rho_j} \subset \Omega_{\rho_{samp2,1}}$ that has a steady-state input within the input bounds, contains the state measurement $\tilde{x}_{j}(t_k)$, and where $\tilde{x}_j(t_k) \in \Omega_{\rho_{h,j}} / \Omega_{\rho_{s,j}}$. Set $t_{s,j} = t_{k}$, choose $t_{e,j} = t_{k+1}$, and go to Step~\ref{step:Step3yc}. Otherwise, if $\zeta$ falls in a range which has not been chosen to start probing for cyberattacks or the $j$-th steady-state cannot be generated to meet the conditions above (which include the consideration of the different levels of stability regions), go to Step \ref{step:Step3c}.
	\item \label{step:Step3c} If $\tilde{x}_{1}(t_k) \in \Omega_{\rho_{e,1}'}$, go to Step~\ref{step:Step3.1c}. Else, go to Step~\ref{step:Step3.2c}.
	\begin{enumerate}
		\item \label{step:Step3.1c} Compute control signals for the subsequent sampling period with Eq.~\ref{eq:p-LEMPCEqn1sconstraints:1} of the $1$-LEMPC activated. Go to Step \ref{step:Step6c}.
		\item \label{step:Step3.2c} Compute control signals for the subsequent sampling period with Eq.~\ref{eq:p-LEMPCEqn1sconstraints:2} of the $1$-LEMPC activated. Go to Step~\ref{step:Step6c}.	
	\end{enumerate}
	\item \label{step:Step3yc} The $j$-LEMPC receives the state measurement $\tilde{x}_{j}(t_k)$ and controls the process according to Eq.~\ref{eq:p-LEMPCEqn2s}.  Evaluate the Lyapunov function profile throughout the sampling period. If $V_j$ does not decrease by the end of the sampling period following $t_{s,j}$, or if $\tilde{x}_j(t) \notin \Omega_{\rho_1}$ at any time for $t\in[t_k,t_{k+1})$, detect that the process is potentially under a cyberattack and mitigating actions may be applied. Otherwise, go to Step~\ref{step:Step5c}.
	\item \label{step:Step5c} At $t_{e,j}$, switch back to operation under the baseline $1$-LEMPC. Go to Step~\ref{step:Step6c}.
	\item \label{step:Step6c} Go to Step \ref{step:Step1c} ($k \leftarrow k+1$).
\end{enumerate}

The first theorem presented in \cite{oyama2020integrated} and replicated below guarantees closed-loop stability of the process of Eq. \ref{eq:ClassofSystems} under the LEMPC's of Eqs. \ref{eq:p-LEMPCEqn1s}-\ref{eq:p-LEMPCEqn2s} under the implementation strategy described above in the absence of sensor cyberattacks. To follow this and the other theorems that will be presented in this work, the impacts of bounded measurement noise and disturbances on the process state trajectory are characterized in Proposition \ref{prop:TrajectoryDifm} below, and the bound on the value of the Lyapunov function at different points in the stability region is defined in Proposition \ref{prop:VDifm}. 
\begin{prop} \label{prop:TrajectoryDifm}  
	\cite{ELLIS2014101,Lao20153374} Consider the systems below
	\begin{subequations} \label{eq:subsystemsm}
		\begin{align} 
		&\dot{x}_{i} = f_i(x_{i} (t), u_i(t), w(t)) \label{eq:subsystems1m} \\
		&\dot{\tilde{x}}_{i} = f_i(\tilde{x}_{i}(t), u_i(t), 0) \label{eq:subsystems2m}
		\end{align}
	\end{subequations}
	where $|x_{i}(t_0) - \tilde{x}_{i}(t_0)| \le \delta$ with $t_0 = 0$. If $x_{i} (t), \tilde{x}_{i} (t) \in \Omega_{{\rho_i}}$ for $t \in [0,T]$, then there exists a function $f_{W,i} (\cdot,\cdot)$ such that:
	\begin{equation}
	\begin{aligned}
	& |x_{i}(t) - \tilde{x}_{i}(t)| \le f_{W,i}(\delta, t-t_0)
	\end{aligned}
	\end{equation}
	for all $x_{i} (t), \tilde{x}_{i} (t) \in \Omega_{{\rho_i}}$, $u_i \in U_i$, and $w \in W$, with 
	\begin{equation}
	\begin{aligned}
	& f_{W,i} (s,\tau) := \left(s + \frac{L_{w,i} \theta_{w}} {L_{x,i}}\right) e^{L_{x,i} \tau} - \frac{L_{w,i} \theta_w} {L_{x,i}}
	\end{aligned}
	\end{equation}
\end{prop}
\begin{prop} \label{prop:VDifm} \cite{ELLIS2014101} %\cite{Mhaskar2012Book} 
	Let $ V_i(\cdot)$ represent the Lyapunov function of the nominal system of Eq. \ref{eq:ClassofSystems}, in deviation form from the $i$-th steady-state, under the controller $h_i(\cdot)$ that satisfies Eqs.~\ref{eq:constraintsLyapunov1}-\ref{eq:constraintsLyapunov4} and~\ref{eq:Lipschitzh} for the system of Eq.~\ref{eq:ClassofSystems} when it is in deviation variable form from the $i$-th steady-state.  Then there exists a function $f_{V_i}$ such that:	
	\begin{equation}
	\begin{aligned}
	& V_i(\bar{x}) \le V_i(\bar{x}') + f_{V_i} (|\bar{x}- \bar{x}'|)
	\end{aligned}
	\end{equation}
	$ \forall \bar{x}, \bar{x}' \in \Omega_{\rho_i}$ where $f_{V_i}(\cdot)$ is given by:	
	\begin{equation}
	\begin{aligned}
	& f_{V_i} (s) := {\alpha}_{4,i}({\alpha}_{1,i}^{-1}({\rho_i}))s + M_{V_i} s^2 \label{eq:prop21:eq2}
	\end{aligned}
	\end{equation}	
	where $M_{V_i}$ is a positive constant.	
\end{prop}	

\begin{thm} \label{thm:thm1} \cite{oyama2020integrated}
	Consider the closed-loop system of Eq. \ref{eq:ClassofSystems} under the implementation strategy described above and in the absence of a false sensor measurement cyberattack where each controller $h_j(\cdot)$, $j \ge 1$, used in each $j$-LEMPC meets the inequalities in Eqs. \ref{eq:constraintsLyapunov1}-\ref{eq:constraintsLyapunov4} and~\ref{eq:Lipschitzh} with respect to the $j$-th dynamic model. Let $\epsilon_{W_j} >0$, $\Delta >0$, $N \ge 1$, $\Omega_{\rho_j} \subset \Omega_{\rho_{samp2,1}} \subset \Omega_{\rho_1} \subset X_1$ for $j>1$, $\rho_j > \rho_{h,j} >\rho_{\min,j} > \rho_{s,j} > \rho_{s,j}'> 0$, where $\Omega_{\rho_{h,j}}$ is defined as the smallest level set of $\Omega_{\rho_j}$ that guarantees that if $V_j(\tilde{x}_{j}(t_k)) \leq \rho_{h,j}$, $V_j(x_{j}(t_k)) \leq \rho_j$, and $\rho_1 > \rho_{samp2,1} > \rho_{samp,1} > \rho_{e,1}' > \rho_{\min,1} > \rho_{s,1} > \rho_{s,1}'> 0$ (where $\Omega_{\rho_{samp,1}}$ is defined as a level set of $\Omega_{\rho_1}$ that guarantees that if $x_{1}(t_k) \in \Omega_{\rho_1}/\Omega_{\rho_{samp,1}}$, then $\tilde{x}_{1}(t_k) \in \Omega_{\rho_1}/\Omega_{\rho_{e,1}'}$) satisfy:
	\begin{equation}
	-\alpha_{3,j}(\alpha_{2,j}^{-1}(\rho_{s,j}')) + L'_{x,j}M_{f,j}\Delta \leq -\epsilon_{w,j}/\Delta, ~ j = 1, 2, \ldots \label{eq:Thm2Eq2}
	\end{equation}
	\begin{equation}
	\rho_{e,1}' + f_{V,1}(f_{W,1}(\delta, \Delta)) \leq \rho_{samp2,1} \label{eq:Thm2Eq3}
	\end{equation}
	\begin{equation}
	-\alpha_{3,1}(\alpha_{2,1}^{-1}(\rho_{e,1}')) + L'_{x,1} M_{f,1} \Delta + L'_{x,1}\delta + L'_{w,1}\theta_w \leq -\epsilon_{w,1}'/\Delta \label{eq:Thm2Eq4}
	\end{equation}
	\begin{equation}
	-\alpha_{3,j}(\alpha_{2,j}^{-1}(\rho_{s,j})) + L'_{x,j} M_{f,j} \Delta + L'_{x,j}\delta + L'_{w,j}\theta_w \leq -\epsilon_{w,j}'/\Delta, ~ j = 1, 2, 3, \ldots \label{eq:Thm2Eq4b}
	\end{equation}
	\begin{equation}
	\rho_{\min,j} = \max\{V_j(x_{j}(t)): x_{j}(t_k) \in \Omega_{\rho_{s,j}'}, ~t\in[t_k,t_{k+1}),~u_j \in U_j \}, ~ j = 1, 2, \ldots \label{eq:Thm2Eq6}
	\end{equation}
	\begin{equation}
	\rho_{samp2,1} \geq \max\{V_1(x_{1}(t)): x_{1}(t_k) \in \Omega_{\rho_{samp,1}}/\Omega_{\rho_{e,1}'}, ~t\in[t_k,t_{k+1}),~u_1 \in U_1 \} \label{eq:Thm2Eq5}
	\end{equation}
	\begin{equation}
	\rho_1 \geq \max\{V_1(\tilde{x}_{1}(t_k)) : x_{1}(t_k) \in \Omega_{\rho_{samp2,1}}\} \label{eq:Thm2Eq7}
	\end{equation}
	\begin{equation}
	\rho_{j} = \max\{V_j(x_{j}(t_k)) : \tilde{x}_{j}(t_k) \in \Omega_{\rho_{h,j}}\}, ~ j = 2, 3, \ldots \label{eq:Thm2Eq7b}
	\end{equation}
	\begin{equation}
	\rho_{s,j}' < \min\{V_j(x_{j}(t_k)) : \tilde{x}_{j}(t_k)\ \in \Omega_{\rho_{j}} / \Omega_{\rho_{s,j}}\}, ~ j = 1, 2, \ldots \label{eq:Thm2Eq8}
	\end{equation}
	If $\tilde{x}_{1}(t_0) \in \Omega_{\rho_{samp2,1}}$, $x_{1}(t_0) \in \Omega_{\rho_{samp2,1}}$, and $|\tilde{x}_{j}(t_k) - x_{j}(t_k)| \leq \delta$, $k=0,1\ldots$, then the closed-loop state is maintained in $\Omega_{\rho_{samp2,1}}$ and the state measurement is in $\Omega_{\rho_1}$ when the $1$-LEMPC is activated at $t_0$ and for $t_{e,j-1} \leq t < t_{s,j}$ or when the $j$-LEMPC is activated for $t_{s,j} \leq t < t_{e,j}$ under the implementation strategy described above, and the closed-loop state and the state measurement are maintained within $\Omega_{\rho_1}$ for $t\geq 0$.  Furthermore, in the sampling period after $t_{s,j}$, if $\tilde{x}_{j}(t_k) \in \Omega_{\rho_j} / \Omega_{\rho_{s,j}}$, $V_j$ decreases and $x_j(t) \in \Omega_{\rho_j}$ for $t\in[t_k,t_{k+1})$. 
\end{thm}

An important clarification regarding the strategy described above that provides more detail compared to~\cite{oyama2020integrated} and aids in understanding extensions of this method developed later in this work for handling actuator attacks is that the decrease in $V_j$ in Theorem~\ref{thm:thm1} is a decrease in $V_j$ along the closed-loop state trajectory of the actual state (not the measurement).  Specifically, that statement in the theorem comes from the following equation in the proof of Theorem~\ref{thm:thm1} in~\cite{oyama2020integrated}, which provides an upper bound on $\dot{V}_j$ along the actual closed-loop state trajectory from $t_k$ to $t_{k+1}$ under an input computed by the $j$-LEMPC when following the implementation strategy described above (i.e., $\tilde{x}_j(t_k) \in \Omega_{\rho_{h,j}}/\Omega_{\rho_{s,j}}$) when Eq.~\ref{eq:Thm2Eq4b} is satisfied:
\begin{equation}
\frac{\partial V_j(x_j(\tau))}{\partial x} f_j(x_j(\tau),u_j(t_k),w(\tau)) \leq -\alpha_{3,j}(\alpha_{2,j}^{-1}(\rho_{s,j})) + L'_{x,j} M_{f,j} \Delta + L'_{x,j}\delta + L'_{w,j}\theta_w \leq -\epsilon_{w,j}'/\Delta \label{eq:VdotReal}
\end{equation}
This expression indicates that $V_j(x_j(t)) \leq V_j(x_j(t_0)) - \frac{\epsilon_{w,j}' (t-t_0)}{\Delta}$, giving a minimum decrease in $V_j$ of $\epsilon_{w,j}'$ over the sampling period.  If this decrease is enough to overcome any measurement noise, such as if:
\begin{equation}
\begin{aligned}
\epsilon_{w,j}' & > \max_{\tilde{x}_j(t_k) \in \Omega_{\rho_{h,j}}/\Omega_{\rho_{s,j}}} \left| \min \{ V_j(\tilde{x}_j(t_k)) : \tilde{x}_j(t_k) \in \Omega_{\rho_{h,j}}/\Omega_{\rho_{s,j}} \} \right. \\
 & \left. - \max \{ V_j(\tilde{x}_j(t_{k+1})) : \tilde{x}_j(t_{k}) \in \Omega_{\rho_{h,j}}/\Omega_{\rho_{s,j}}, ~u_j \in U_j, ~|x_j(t_p) - \tilde{x}_j(t_p)| \leq \theta_{v,1},~p=k,k+1 \} \right| \label{eq:epswjbound}
\end{aligned}
\end{equation} 
when the input is computed by the $j$-LEMPC (where $\theta_{v,1}$ represents the measurement noise when full state feedback is available), then the state measurement also must decrease by the end of the sampling period.  However, at any given time instant, it is not guaranteed to be decreasing due to the noise.  An unusual amount of increasing could help to flag the attack before a sampling period is over, though this would come from recognizing atypical behavior (essentially pattern recognition).  

The reasoning behind the selection of the presented bound on $\epsilon_{w,j}'$ is as follows: the lack of a decrease in the Lyapunov function value between $t_k$ and $t_{k+1}$ is meant to flag an attack.  However, with sensor noise, it is possible that Eq.~\ref{eq:VdotReal} can hold (which reflects a decrease in the value of $V_j$ evaluated along the trajectory of the actual closed-loop state) but that the decrease in $V_j$ caused by Eq.~\ref{eq:VdotReal} is not enough to ensure that $V_j$ evaluated at the measured values of the closed-loop state (instead of the actual values) decreases between $t_k$ and $t_{k+1}$.  For example, consider the case in which the value of $V_j$ barely decreases over a sampling period, so that $V_j$ can be treated as approximately constant.  If the noise in the measurements is large, it may then be possible that $V_j(\tilde{x}_j(t_k)) < V_j(\tilde{x}_j(t_{k+1}))$, even though $V_j$ slightly decreased along the actual closed-loop state trajectory (if, for example, the noise originally takes $V_j(\tilde{x}_j(t_k))$ to the minimum possible value it could be for a given $V_j(x_j(t_k))$, but then at the next sampling time the Lyapunov function evaluated at the measurement is the maximum possible value that it could take).  Eq.~\ref{eq:epswjbound} ensures that even if this occurs, the decrease in $V_j$ along the actual closed-loop state trajectory is enough to ensure that the maximum value of $V_j(\tilde{x}_j(t_{k+1}))$ is less than the minimum value of $V_j(\tilde{x}_j(t_k))$.

% for $t\in [t_k,t_{k+1})$.  Therefore, to note the conditions under which the measured value of $x_j$ (which is what will be available to check if a cyberattack is occurring) will be decreasing, we utilize Proposition~\ref{prop:VDifm} to obtain the following inequalities:
%\begin{subequations}
%	\begin{align}
%V_j(\tilde{x}_j(t)) & \leq V_j(x_j(t)) + f_{V_j}(|\tilde{x}_j(t) - x_j(t)|) \\
%& \leq V_j(x_j(t_0)) - \frac{\epsilon_{w,j}' (t-t_0)}{\Delta} + + f_{V_j}(|\tilde{x}_j(t) - x_j(t)|) \label{eq:VjMeasDecrease}
%\end{align}
%\end{subequations}
%From this equation, for the measured value of $V_j$ to decrease at every time over a sampling period in the absence of an attack as needed for the sensor attack-flagging strategy, it would need to be true that 

\begin{rmk} \label{NestedRegions}
	The following relation between the different stability regions has been characterized for Detection Strategy 1-S: $\rho_1 > \rho_{samp2,1} > \rho_{samp,1} > \rho_{e,1}' > \rho_{\min,1} > \rho_{s,1} > \rho_{s,1}'> 0$ (which must hold when the baseline 1-LEMPC is used) and $\rho_j > \rho_{h,j} >\rho_{\min,j} > \rho_{s,j} > \rho_{s,j}'> 0$ for $j>1$ (which must hold when the $j$-LEMPC is used). The regions $\Omega_{\rho_{samp,1}}$, $\Omega_{\rho_{s,j}}$, and $\Omega_{\rho_{h,j}}$ are important to define due to the presence of measurement noise \cite{oyama2020integrated}. Specifically, $\Omega_{\rho_j}$, $j =1,2,\ldots$ has been defined as an invariant set in which the closed-loop state is maintained, and $\Omega_{\rho_{e,1}'}$ is a region utilized in distinguishing between whether Eq.~\ref{eq:p-LEMPCEqn1sconstraints:1} or~\ref{eq:p-LEMPCEqn1sconstraints:2} is activated in Eq.~\ref{eq:p-LEMPCEqn1s}. $\Omega_{\rho_{s,j}'}$, $j =1,2,\ldots$, is defined as a region such that if the actual state is within $\Omega_{\rho_{s,j}'}$ at a sampling time, the maximum distance that the closed-loop state would be able to go within a sampling period is into $\Omega_{\rho_{\min,j}}$. Furthermore, we define the region $\Omega_{\rho_{s,j}}$ such that if the state measurement is within $\Omega_{\rho_{h,j}} / \Omega_{\rho_{s,j}}$ at $t_k$, the actual state is outside of $\Omega_{\rho_{s,j}'}$. $\Omega_{\rho_{samp,1}}$ is characterized as a region where, if the actual state is inside this region at a sampling time, the maximum distance that the closed-loop state would be able to travel within a sampling period is into $\Omega_{\rho_{samp2,1}}$. $\Omega_{\rho_{samp2,1}}$ is then defined to be a subset of $\Omega_{\rho_1}$ so that the maximum distance that the closed-loop state could go when the state measurement is within $\Omega_{\rho_{e,1}'}$ but the actual state is outside of this region is still inside $\Omega_{\rho_1}$. To ensure that the actual state at $t_k$ is inside $\Omega_{\rho_j}$, we define the region $\Omega_{\rho_{h,j}} \subset \Omega_{\rho_j}$ such that if the state measurement is within $\Omega_{\rho_{h,j}}$ at $t_k$, the actual state is inside $\Omega_{\rho_j}$. 
\end{rmk}

\subsection{Control/Detection Strategy 2-S using LEMPC in the Presence of Sensor Attacks} \label{sec:LEMPCsensor2}

The control/detection strategy 2-S, which corresponds to the second detection concept in \cite{oyama2020integrated}, has been developed using only the 1-LEMPC of Eq.~\ref{eq:p-LEMPCEqn1s} and it flags false sensor measurements based on state predictions from the process model from the last state measurement. If the norm of the difference between the state predictions and the current measurements is above a threshold, the measurement is identified as a potential sensor attack. Otherwise, if the norm is below this threshold, even if the measurement was falsified, the closed-loop state can be maintained inside $\Omega_{\rho_1}$, under sufficient conditions \cite{oyama2020integrated}, for a sampling period after the attack is applied for the process operated under an LEMPC that follows the implementation strategy below, where $\tilde{x}_{1}(t_k|t_{k-1})$ denotes the prediction of the state $\tilde{x}_{1}$ at $t_k$ evaluated by integrating the process model of Eq.~\ref{eq:p-LEMPCEqn1s:Model} from a measurement at $t_{k-1}$ until $t_k$: 
\begin{enumerate}
	\item \label{step:D2Step1} At sampling time $t_k$, if $|\tilde{x}_{1}(t_k|t_{k-1}) - \tilde{x}_{1}(t_k|t_k)| > \nu$, flag that a cyberattack is happening and go to Step~\ref{step:D2Step1a}.  Else, go to Step~\ref{step:D2Step1b}.
	\begin{enumerate}
		\item \label{step:D2Step1a} Mitigating actions may be applied (e.g., a backup policy such as the use of redundant controller or an emergency shut-down mode).
		\item \label{step:D2Step1b} Operate the process under the 1-LEMPC of Eq.~\ref{eq:p-LEMPCEqn1s} while implementing an auxiliary detection mechanism to attempt to flag any undetected attack at $t_k$.  $t_k \leftarrow t_{k+1}$.  Go to Step~\ref{step:D2Step1}. 
	\end{enumerate}
\end{enumerate}

The second theorem presented in \cite{oyama2020integrated}, which is replicated below, guarantees closed-loop stability of the process of Eq. \ref{eq:ClassofSystems} under the 1-LEMPC of Eq. \ref{eq:p-LEMPCEqn1s} under the implementation strategy described above before a sensor attack occurs and for at least one sampling period after the attack.

\begin{thm}~\cite{oyama2020integrated} \label{thm:Theorem1}
	Consider the system of Eq.~\ref{eq:ClassofSystems} in closed-loop under the implementation strategy described in Section \ref{sec:LEMPCsensor2} based on a controller $h_1(\cdot)$ that satisfies the assumptions of Eqs.~\ref{eq:constraintsLyapunov1}-\ref{eq:constraintsLyapunov4} and \ref{eq:Lipschitzh}.  Let the conditions of Theorem~\ref{thm:thm1} hold with $t_{s,j} = \infty$, $j=2,3,\ldots$, and $\delta \geq f_{W,1}(\theta_{v,1},\Delta) + \nu$.  If $\tilde{x}_{1}(t_0) \in \Omega_{\rho_{samp2,1}} \subset \Omega_{\rho_1}$ and $x_{1}(t_0) \in \Omega_{\rho_{samp2,1}}$, then $x_{1}(t) \in \Omega_{\rho_{samp2,1}}$ and the state measurement at each sampling time is in $\Omega_{\rho_1}$ for all times before a sampling time $t_{A}$ that a cyberattack falsifies a state measurement, and $x_{1}(t) \in \Omega_{\rho_{samp2,1}}$ for $t \in [t_A,t_{A} + \Delta)$, if the attack is not detected at $t_A$.
\end{thm}
In Theorem \ref{thm:Theorem1}, $\delta$ represents the deviation between the state measurement and the actual state that can be tolerated with the provided closed-loop stability guarantees.  If there is no attack, $\delta$ corresponds to measurement noise.  If there is an attack, then $\delta$ reflects the largest possible deviation of the falsified state measurement from the actual state that can be tolerated while the guarantees in the theorem are obtained.

We now provide some additional insights into this strategy compared to~\cite{oyama2020integrated} in preparation for a discussion about cyberattack ``discoverability'' later in this work.  Specifically, the reason that closed-loop stability can only be guaranteed for a sampling period after an attack in Theorem~\ref{thm:Theorem1} is due to the use of a state prediction in detecting the attack.  Specifically, Theorem~\ref{thm:Theorem1} ensures that $\tilde{x}_{1}(t) \in \Omega_{\rho_{1}}$ and $x_{1}(t) \in \Omega_{\rho_{samp2,1}}$ for $t < t_A$. According to \cite{oyama2020integrated}, to demonstrate that $x_{1}(t) \in \Omega_{\rho_{samp2,1}}$ for $t\in [t_A,t_A + \Delta)$, we consider the measurements $\tilde{x}_{1}(t_{k-1}|t_{k-1})$ and $\tilde{x}_{1}(t_k|t_k)$, and the predicted state $\tilde{x}_{1}(t|t_{k-1})$ from the nominal model of Eq.~\ref{eq:p-LEMPCEqn1s:Model} for $t\in[t_{k-1},t_k]$.  Then, as the measurement noise is bounded, $|\tilde{x}_{1}(t_{k-1}|t_{k-1}) - x_{1}(t_{k-1})| \leq \theta_{v,1}$ and Proposition~\ref{prop:TrajectoryDifm} gives:
	\begin{equation}
	|x_{1}(t_k) - \tilde{x}_{1}(t_k|t_{k-1})| \leq f_{W,1}(\theta_{v,1},\Delta) \label{eq:CyberProofBound1} 
	\end{equation}
	If an attack is not flagged at $t_{k}$:
	\begin{equation}
	\begin{aligned}
	|x_{1}(t_k) - \tilde{x}_{1}(t_k|t_k)| & \leq |x_{1}(t_k) - \tilde{x}_{1}(t_k|t_{k-1}) + \tilde{x}_{1}(t_k|t_{k-1}) - \tilde{x}_{1}(t_k|t_k)| \\
	& \leq f_{W,1}(\theta_{v,1},\Delta) + |\tilde{x}_{1}(t_k|t_{k-1}) - \tilde{x}_{1}(t_k|t_k)| \leq f_{W,1}(\theta_{v,1},\Delta) + \nu \label{eq:CyberProofBound2}
	\end{aligned}
	\end{equation}
	We note that Eqs.~\ref{eq:CyberProofBound1}-\ref{eq:CyberProofBound2} assume that there is no attack or an undetected attack at $t_{k-1}$, respectively, so that $|\tilde{x}_{1}(t_{k-1}|t_{k-1}) - x_{1}(t_{k-1})| \leq \theta_{v,1}$, which is used in deriving the subsequent requirements on $\delta$ that are used to select the parameters of the LEMPC of Eq.~\ref{eq:p-LEMPCEqn1s} to satisfy Theorem~\ref{thm:Theorem1}.  If there is an attack on the sensor measurements at $t_{k-1}$, it is no longer necessarily true that $|\tilde{x}_{1}(t_{k-1}|t_{k-1}) - x_{1}(t_{k-1})| \leq \theta_{v,1}$, so that the remainder of the proof would no longer follow.  One can see this more explicitly by propagating the bounds in Eqs.~\ref{eq:CyberProofBound1}-\ref{eq:CyberProofBound2}.  Specifically, Eq.~\ref{eq:CyberProofBound2} allows for the potential that though $|x_{1}(t_k) - \tilde{x}_{1}(t_k|t_k)| \leq f_{W,1}(\theta_{v,1}) + \nu$, $\tilde{x}_{1}(t_k|t_k)$ could be falsified. To see the bound on the difference between the state measurement and the actual state which could potentially occur at the next sampling time, we use the fact that $|x_{1}(t_k) - \tilde{x}_{1}(t_k|t_k)| \leq \delta $ from Eq.~\ref{eq:CyberProofBound2} to derive the following bound like Eq.~\ref{eq:CyberProofBound1}:
	\begin{equation}
	|x_{1}(t_{k+1}) - \tilde{x}_{1}(t_{k+1}|t_{k})| \leq f_{W,1}(\delta,\Delta) \label{eq:CyberProofBound3} 
	\end{equation}
	Then if an attack is not flagged at $t_{k+1}$, following a procedure similar to that in Eq.~\ref{eq:CyberProofBound2} gives:
	\begin{equation}
	\begin{aligned}
	|x_{1}(t_{k+1}) - \tilde{x}_{1}(t_{k+1}|t_{k+1})|  \leq f_{W,1}(\delta,\Delta) + \nu \label{eq:CyberProofBound4}
	\end{aligned}
	\end{equation}
	It is reasonable to expect that $\nu$ would be set greater than $\theta_{v,1}$ since it is reasonable to expect that $|\tilde{x}_{1}(t_p|t_{p-1}) - \tilde{x}_{1}(t_p|t_p)|$, $p=0,1,\ldots$, could reach values around $\theta_{v,1}$ given the bound on the noise; however, whether or not this is the case, the definition of $f_{W,1}$ indicates that the maximum potential difference between the actual state and the (falsified) state measurement is growing with time (i.e., $\theta_{v,1} < f_{W,1}(\theta_{v,1},\Delta) + \nu < f_{W,1}(\delta,\Delta) + \nu$).  One could also consider developing $\delta$ by performing the analysis of Eqs.~\ref{eq:CyberProofBound1}-\ref{eq:CyberProofBound2}, as is begun in Eqs.~\ref{eq:CyberProofBound3}-\ref{eq:CyberProofBound4}, to obtain a $\delta$ that is larger (resulting in greater conservatism in the selection of the LEMPC parameters in Theorem~\ref{thm:Theorem1} when it is still possible to satisfy the conditions of that theorem with larger values of $\delta$) but that allows multiple sampling periods of the closed-loop state remaining in $\Omega_{\rho_1}$ after an attack if desired.  Though this is only a maximum bound (i.e., the difference does not necessarily grow in the manner described), this analysis highlights a fundamental difference between measurement noise and disturbances and cyberattacks.  Specifically, whereas the conditions of Theorem~\ref{thm:Theorem1} guarantee recursive feasibility and closed-loop stability in the presence of sufficiently small bounded measurement noise and sufficiently small bounded plant/model mismatch, they cannot make long-term stability guarantees in the presence of false sensor measurements because effectively, those destroy feedback over an extended period of time and leave the process operating in a condition where the inputs being applied are not necessarily tied to the actual or even approximate value of the state (whereas the approximate value of the state may be known from sensor readings in the presence of disturbances and measurement noise).  We also highlight that the above discussion can be thought of more generally.  For example,  one could see how it might become challenging to guarantee resilience against attacks that only slightly offset the measured value of the process state from a predicted value by considering the concept that with noise and disturbances, one would expect there to be a set of potential initial states which might all be consistent with the noise and disturbance distribution, process model, and measurements.  From these initial states, there are potential state trajectories that could all be consistent with the noise and disturbance distribution, process model, and measurements.  When feedback is available, it re-restricts the possible range of allowable states from which potentially reasonable final states could be computed once again.  In the absence of feedback, possible final states from the first prediction are then reasonable initial conditions for a second prediction, which in the presence of noise and disturbances, could potentially significantly expand the number of states which could be consistent with the state.  This indicates the mechanism by which an attack could be deceptive.% (and will be further highlighted in the example in Section~\ref{sec:DifMeasFalse} below).


\subsection{Control/Detection Strategy 3-S using LEMPC in the Presence of Sensor Attacks} \label{sec:LEMPCsensor3}

The Detection Strategy 3-S, which corresponds to the third detection concept proposed in \cite{oyama2020integrated}, utilizes multiple redundant state estimators (where we assume that not all of them are impacted by the false sensor measurements) integrated with an output feedback LEMPC, and ensures that the closed-loop state is maintained in a safe region of operation for all times that no attacks are detected. The output feedback LEMPC designed for this detection strategy receives a state estimate $z_1$ from one of the redundant state estimators (the estimator used to provide state estimates to the LEMPC will be denoted as the $i=1$ estimator) at $t_k$, where the notation follows that of Eq.~\ref{eq:p-LEMPCEqn1s} with Eq.~\ref{eq:p-LEMPCEqn1s:Measurement} replaced by $\tilde{x}_1(t_k) = z_1(t_k)$ (we will subsequently refer to this LEMPC as the output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn1s}).

This implementation strategy assumes that the process has already been run successfully in the absence of attacks under the output feedback LEMPC of Eq.~\ref{eq:MPCEqn} for some time such that $|z_i(t) - x(t)| \leq \epsilon_{mi}^*$ for all $i=1,\ldots,M$ before an attack:
\begin{enumerate}
	\item \label{step:Step1s} At sampling time $t_k$, if $|z_i(t_k) - z_j(t_k)| > \epsilon_{\max}$, $i=1,\ldots,M$, $j=1,\ldots,M$, or $z_1(t_k) \notin \Omega_{\rho}$ (where $z_1$ is the state estimate used in the LEMPC design), flag that a cyberattack is occurring and go to Step~\ref{step:Step1sa}. Else, go to Step~\ref{step:Step1sb}.
	\begin{enumerate}
		\item \label{step:Step1sa} Mitigating actions may be applied (e.g., a backup policy such as the use of redundant controller or an emergency shut-down mode).
		\item \label{step:Step1sb} Operate using the output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn1s}.  $t_k \leftarrow t_{k+1}$.  Go to Step~\ref{step:Step1s}. 
	\end{enumerate}
\end{enumerate}

Detection Strategy 3-S guarantees that any cyberattacks which would drive the closed-loop state out of $\Omega_{\rho_1}$ will be detected before this occurs. It flags cyberattacks by evaluating the norm of the difference between state estimates. If this norm is above a threshold, which represents ``normal'' process behavior, the control system is recognized as under a potential sensor attack. To determine a threshold,~\cite{oyama2020integrated} designs the following bound:
\begin{equation} \label{eq:DetectionConditions}
\begin{aligned}
|z_i(t) - z_j(t)| & = |z_i(t) - x(t) + x(t) - z_j(t)|  \leq |z_i(t) - x(t)| + |z_j(t) - x(t)| \\
& \leq \epsilon_{ij} := (e_{mi}^* + e_{mj}^*) \leq \epsilon_{\max} := \max \{\epsilon_{ij}\}
\end{aligned}
\end{equation}
for all $i \neq j$, $i=1,\ldots,M$, $j=1,\ldots,M$, as long as $t \geq t_q = \max\{t_{b1},\ldots,t_{bM}\}$.  Therefore, abnormal behavior can be detected if $|z_i(t_k) - z_j(t_k)| > \epsilon_{\max}$ if $t_k > t_q$ (this avoids false detections). 

The worst-case difference between the state estimate used by the output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn1s} and the actual value of the process state under the implementation strategy above when an attack is not flagged is described in Proposition \ref{prop:OutputFdbkProp1}.
\begin{prop} \cite{oyama2020integrated} \label{prop:OutputFdbkProp1}
	Consider the system of Eq.~\ref{eq:ClassofSystems} under the implementation strategy of Section~\ref{sec:LEMPCsensor3} where $M > 1$ state estimators provide independent estimates of the process state and at least one of these estimators is not impacted by false state measurements (and the attacks do not begin until after $t_q$).  If a sensor measurement cyberattack is not flagged at $t_k$ according to the implementation strategy, then the worst-case difference between $z_{i}$, $i \ge 1$, and the actual state $x(t_k)$ is given by:
	\begin{equation} 
	|z_{i}(t_k) - x(t_k)| \leq \epsilon_{M}^* := \epsilon_{\max} + \max \{ e_{mj}^* \},~j=1,\ldots,M \label{eq:OutputFdbkPropConclusion}
	\end{equation}  
\end{prop}

The third theorem presented in \cite{oyama2020integrated}, which is replicated below, guarantees closed-loop stability of the process of Eq. \ref{eq:ClassofSystems} under the LEMPC of Eq. \ref{eq:p-LEMPCEqn1s} under the implementation strategy described above when a sensor cyberattack is not flagged. 

\begin{thm} \label{thm:Thm3}
	Consider the system of Eq.~\ref{eq:ClassofSystems} in closed-loop under the output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn1s} based on an observer and controller pair satisfying Assumptions~\ref{assum:Assum1}-\ref{assum:Assum2} and formulated with respect to the $i=1$ measurement vector, and formulated with respect to a controller $h(\cdot)$ that meets Eqs.~\ref{eq:constraintsLyapunov1}-\ref{eq:constraintsLyapunov4} and~\ref{eq:Lipschitzh}.  Let the conditions of Proposition~\ref{prop:OutputFdbkProp1} hold, and $\theta_w \leq \theta_w^*$, $\theta_{v,i} \leq \theta_{v,i}^*$, $\epsilon_i \in (\epsilon_{Li}^*,\epsilon_{Ui}^*)$, and $|z_i(t_0) - x(t_0)| \leq e_{m0i}$, for $i=1,\ldots,M$.  Also, let $\epsilon_{W,1} > 0$, $\Delta > 0$, $\Omega_{\rho_1} \subset X$, and $\rho_1 > \rho_{\max} > \rho_{1,1} > \rho_{e,1}' > \rho_{\min,1} > \rho_{s,1} > 0$, satisfy:
	\begin{equation}
	\begin{aligned}
	\rho_{e,1}' & \leq \rho_{\max} - \max\{f_V(f_W(\epsilon_{M}^*,\Delta)), M_f \max\{t_{z1},\Delta \} \alpha_4(\alpha_1^{-1}(\rho_{\max})) \} \label{eq:rhoe}
	\end{aligned}
	\end{equation}
	\begin{equation}
	\rho_{e,1}' \leq \rho_1 - f_V(f_W(\epsilon_{M}^*,\Delta))  - f_V(\epsilon_{M}^*) \label{eq:NewEqn1}
	\end{equation}
	\begin{equation}
	\begin{aligned}
	& -\alpha_3(\alpha_2^{-1}(\rho_{s,1})) + L_x'(M_f \Delta + \epsilon_{M}^*)  + L_w' \theta_w \leq -\epsilon_{W,1}/\Delta \label{eq:cond2}
	\end{aligned}
	\end{equation}
	\begin{equation}
	\rho_{\min,1} = \max \{ V(x(t)) | V(x(t_k)) \leq \rho_{s,1}, ~t\in[t_k,t_{k+1}),~u\in U \} \label{eq:rhoMin}
	\end{equation}	
	\begin{equation}
	\rho_{\min,1} + f_V(f_W(\epsilon_M^*,\Delta)) \leq \rho_1 \label{eq:rhoMin2}
	\end{equation}
	\begin{equation}
	\rho_{\max} + f_V(\epsilon_M^*) \leq \rho_1 \label{eq:NewEqn2}
	\end{equation}	
	where $t_{z1}$ is the first sampling time after $t_{b1}$, and $f_V$ and $f_W$ are defined as in Propositions~\ref{prop:TrajectoryDifm} and~\ref{prop:VDifm} for $i=1$ but with the subscripts dropped. Then, if $x(t_0) \in \Omega_{\rho_{e,1}'}$, $x(t) \in \Omega_{\rho_{\max}}$ for all $t\geq 0$ and $z_1(t_h) \in \Omega_{\rho_1}$ for $t_h \ge \max \{\Delta, t_{z1} \}$ until a cyberattack is detected according to the implementation strategy in Section \ref{sec:LEMPCsensor3}, if the attack occurs after $t_q$.
\end{thm}
Detection Strategy 3-S does not require the knowledge of which state estimate is false or whether or not it is used by the LEMPC; nevertheless, the proposed approach requires at least one estimator to provide accurate estimates of the actual state so that one of them can check the others (to ensure that there is not a case where all could be consistent but incorrect).  As for the other strategies, we conclude with some discussion of this method that provides insights beyond those discussed in~\cite{oyama2020integrated}, here in the form of remarks.

\begin{rmk}
	The role of $\Omega_{\rho_{1,1}}$ is to ensure, according to Assumptions~\ref{assum:Assum1}-\ref{assum:Assum2}, that there exists some time before the closed-loop state, initialized within $\Omega_{\rho_{1,1}}$, leaves $\Omega_{\rho_1}$.  Here, $x(t_0) \in \Omega_{\rho_{e,1}'}$, which is taken to be a subset of $\Omega_{\rho_{1,1}}$ for this reason.  Specifically, Assumption~\ref{assum:Assum1} states that the state of the closed-loop system of Eq.~\ref{eq:ClassofSystems} under inputs computed from state feedback (with the state feedback not yet meeting the bound in Assumption~\ref{assum:Assum2}) remains within $\Omega_{\rho_1}$ at all times by starting within the interior of $\Omega_{\rho_1}$ so that in the time before $t_{b1}$, the fact that $|z_1 - x(t)| > e_{m1}$ does not cause the closed-loop state of the system of Eq.~\ref{eq:ClassofSystems} to reach the boundary of $\Omega_{\rho_1}$ before $|z_1 - x(t)| \leq e_{m1}$, after which point it is assumed that the feedback control law that is stabilizing when it is provided full state feedback is receiving state estimates close enough to $x$ to maintain the closed-loop state within $\Omega_{\rho_1}$ after $t_{b1}$.  This is true in Theorem~\ref{thm:Thm3}, where the set in which the closed-loop state is initialized must be sufficiently small such that before $t_{b1}$, the closed-loop state under the control actions computed by the LEMPC cannot leave $\Omega_{\rho_1}$ (even if the state estimates used as the initial condition in the controller are bad).  This means, however, that the convergence time $t_{b1}$ for the observer must be sufficiently small to prevent $\rho_{e,1}'$ from needing to be prohibitively small to ensure that the closed-loop state would stay within $\Omega_{\rho_1}$ before $t_{b1}$ if initialized within $\Omega_{\rho_{e,1}'}$.
\end{rmk}
\begin{rmk} \label{rem:Remark3}
	Assumptions~\ref{assum:Assum1}-\ref{assum:Assum2} are essentially used in Detection Strategy 3-S to imply the existence of observers with convergence time periods that are independent of the control actions applied (i.e., they converge, and stay converged, regardless of the actual control actions applied).  High gain observers are an example of an observer that can meet this assumption~\cite{AHRENS2009936} for bounded $x$, $u$, and $w$.  This is critical to the ability of the multiple observers to remain converged when the process is being controlled by an LEMPC receiving inputs based on state feedback of only one of them, so that the others are evolving independently of the inputs to the closed-loop system.
\end{rmk}
\begin{rmk}
	We only guarantee in Theorem~\ref{thm:Thm3} that $z_1(t) \in \Omega_{\rho_1}$, rather than that $z_j(t) \in \Omega_{\rho_1}$, for all $t \geq 0$ until a cyberattack is detected.  This is because $z_1(t) \in \Omega_{\rho_1}$ is required for feasibility of the LEMPC, and the other estimates are not used by the LEMPC and thus they do not impact feasibility.  If it was desired to utilize an estimate not impacted by cyberattacks in place of $z_1$ if an attack on $z_1$ is discovered, one could develop the parameters of the $M$ possible LEMPC's to meet the requirements of Theorem~\ref{thm:Thm3} and then select the operating conditions for the $i=1$ estimator to be contained in the intersection of the stability regions of all of the others such that any of the other estimators could begin to be used at a sampling time if the $i=1$ estimator is detected to be compromised at that time.  This would require being able to know which of the estimators is not attacked to switch to the correct one when the $i=1$ estimator is discovered to be attacked.    
\end{rmk}
\begin{rmk}
	Larger values of $e_{mi}^*$ (i.e., less accurate state estimates) lead to a larger upper bound $\epsilon_{M}^*$ in Proposition~\ref{prop:OutputFdbkProp1}, resulting then in a more conservative $\rho_{e,1}'$ according to Theorem~\ref{thm:Thm3}. This indicates that there is a trade-off between the accuracy of the available state estimators to probe for cyberattacks and the design value of $\rho_{e,1}'$ to ensure closed-loop stability under the proposed output feedback LEMPC cyberattack detection strategy.
\end{rmk}

\begin{rmk} \label{FaultComment}
	The methods for attack detection (Strategies 1-S, 2-S, and 3-S) do not distinguish between sensor faults and cyberattacks.  Therefore, they could flag faults as attacks (and therefore it may be more appropriate to use them as anomaly detection with a subsequent diagnosis step).  The benefit, however, is that they provide resilience against attacks if the issue is an attack (which can be designed to be malicious) and not a fault (which may be less likely to occur in a state that an attacker might find particularly attractive).  They also flag issues that do not satisfy theoretical safety guarantees, which may make it beneficial to flag the issues regardless of the cause.   
\end{rmk}
n{Cyberattack Detection and Control Strategies using LEMPC under Single Attack Type Scenarios: Actuator Attacks} \label{sec:ActuatorAttackOnly}

The methods described above from \cite{oyama2020integrated} were developed for handling cyberattacks on process sensor measurements.  In such a case, the actuators receive the signals which the controller calculated, but the signal which the controller calculated is not appropriate for the actual process state.  This requires the methods to, in a sense, rely on the control actions to show that the sensor measurements are not correct.  In contrast, when an attack occurs on the actuator signal, the controller no longer plays a role in which signal the actuators receive.  This means that the sensor measurements must be used to show that the control actions are not correct.  This difference raises the question of whether the three detection strategies of the prior section can handle actuator attacks or not.  This section therefore seeks to address the question of whether it is trivial to utilize the sensor attack-handling techniques from \cite{oyama2020integrated} for handling actuator attacks, or if there are further considerations.

We begin by considering the direct extension of all three methods, in which Detection Strategies 1-S, 2-S, and 3-S are utilized in a case where the sensor measurements are intact but the actuators are attacked.  In this work, actuator output attacks will be considered to happen when: (1) the code in the controller has been attacked and reformulated so that it no longer computes the control action according to an established control law; (2) the control action computed by a controller is replaced by a rogue control signal; or (3) a control action is received by the actuator but subsequently modified at the actuator itself.  

When Detection Strategy 1-S is utilized but the actuators are attacked, then at random times, it is intended to utilize the $j$-LEMPC (however, because of the attack, the control actions from the $j$-LEMPC are not applied).  For an actuator attacker to fly under the radar of the detection strategy, the attacker would need to force a net decrease in $V_j$ along the measured state trajectory between the beginning and end of a sampling period, and would need to ensure that the closed-loop state measurement does not leave $\Omega_{\rho_{1}}$ at any point in the sampling period (according to the implementation strategy in Section~\ref{sec:LEMPCsensor1}).  This restricts the set of inputs which an attacker can provide in place of those coming from the controller without being detecting during a probing maneuver to those which ensure that the closed-loop state does not exit $\Omega_{\rho_1}$ throughout the sampling period (ultimately maintaining the closed-loop state within a safe operating region if that region is a superset of $\Omega_{\rho_1}$).  Thus, during a probing maneuver, Detection Strategy 1-S, with flagging of attacks both when $V_j$ along the measurement trajectory does not decrease by the end of a sampling period and when the state measurement leaves $\Omega_{\rho_1}$ at any point during a sampling period, provides greater protection from impacts of attacks on safety when the actuators are attacked than when the sensors are attacked.  Specifically, whereas there is no guarantee that an undetected sensor attack would not cause a safety issue when using Detection Strategy 1-S, when an actuator attack occurs instead, then over the sampling period during which a probing maneuver is undertaken, an actuator attacker is unable to cause a safety issue for the closed-loop system without being detected (because the sensor measurements are correct and would flag this problematic behavior before the attacker could cause the closed-loop state to leave a safe operating region).  However, because the value of the Lyapunov function at the state measurements are only being checked at the beginning and end of the sampling period, it is possible that the actual closed-loop state could move out of $\Omega_{\rho_1}$ over a sampling period when a rogue actuator output is applied, and furthermore that at such a point, the measurement may not show this due to the noise.  Therefore, to handle the actuator attacks, it is necessary to add conservatism to the design of the safe operating region compared to $\Omega_{\rho_1}$, so that instead of maintaining the state measurements and closed-loop state within $\Omega_{\rho_1}$ only, they are maintained in supersets of it that prevent the closed-loop state from leaving a safe operating region in the presence of noise and problematic inputs before a sampling period is over.  A method for devising such regions is shown in a later section in the context of a combined sensor and actuator attack-handling strategy that makes use of this methodology.  If this conservatism is added, then if an actuator attack occurs in a sampling period during which a probing maneuver occurs but it is undetected, the closed-loop state is maintained within the safe operating region.  When no probing maneuver is occurring, then if the Lyapunov function evaluated at the state measurement is increasing over a sampling period when the closed-loop state is outside of $\Omega_{\rho_{e,1}'}$, it may be possible that an attack is occurring and that this could be flagged to attempt to catch the attack before the closed-loop state leaves $\Omega_{\rho_1}$; however, as discussed in Section~\ref{sec:LEMPCsensor3}, in the presence of bounded measurement noise, it is possible that $V_j$ may not monotonically decrease when evaluated using the state measurements, so that care must be taken in flagging a temporary increase in $V_j$ as a cyberattack to avoid characterizing measurement noise as an attack.

An improved version of Detection Strategy 1-S when there are actuator cyberattacks only would probe constantly for attacks (i.e., the implementation strategy would be the same as that in Section~\ref{sec:LEMPCsensor1}, except that the probing occurs at every sampling time, instead of at random sampling times; this implementation strategy assumes that regions meeting the requirements in Step~\ref{step:Step2c} in Section~\ref{sec:LEMPCsensor1} can be found at every sampling time, though reviewing when this is possible in detail can be a subject of future work).  In this case, since at every sampling time, the attacker would be constrained to choose inputs which cannot cause the state measurement to leave $\Omega_{\rho_1}$, the attacker can never perform an undetected attack that drives the closed-loop state out of a safe operating region before it is detected.  This indicates that this modified version of Detection Strategy 1-S (referred to subsequently as Detection Strategy 1-A) is resilient to cyberattacks on actuators in the sense that it is able to prevent an undetected attack from causing safety issues.  In light of the question of whether it is trivial to extend Detection Strategy 1-S to handle actuator attacks, we note that Detection Strategy 1-A, which performs continuous probing, is performed in a different manner than Detection Strategy 1-S.  Specifically, random probing is used in Detection Strategy 1-S to attempt to surprise an attacker, because the element of surprise is part of what that algorithm has to counter the fact that the sensor measurements are incorrect.  In contrast, Detection Strategy 1-A does not need to have randomized or unpredictable probing; it inherits its closed-loop stability properties from the fact that its design forces the cyberattacker into a corner in terms of what inputs they can apply, even if they fully knew how Detection Strategy 1-A worked, without being detected.  This indicates that there is not a 1-to-1 correspondence between how a sensor cyberattack should be handled and how an actuator cyberattack should be handled, with approximately the same strategy.  Furthermore, for this strategy, we see a flip in its power between the sensor and actuator attack-handling cases in that Detection Strategy 1-S cannot guarantee safety when a falsified state measurement is provided to the $j$-LEMPC, but can guarantee safety in the presence of an actuator attack during the sampling period after a probing maneuver is initiated if the state measurements are correct.

To further explore how the sensor attack-handling strategies from~\cite{oyama2020integrated} extend to actuator cyberattack-handling, we next consider the use of Detection Strategy 2-S for actuator attacks.  This detection strategy is based on state predictions.  These predictions must be computed under some inputs, so it is first necessary to consider which inputs these are for the actuator attack extension.  Several options for inputs which could be used in making the state predictions include an input computed by a redundant control system, an approximation of the expected control output (potentially obtained via fitting data between state measurements and (non-attacked) controller outputs to a data-driven model), or a signal from the actuator if it is reflective of what was actually implemented.  If an actuator signal reflective of the control action that was actually implemented is received and a redundant control system is available, these can be used to cross-check whether the actuator output is correct.  This would rapidly catch an attack if the signals are not the same.  However, if there is not a fully redundant controller (e.g., if actuator signals are available but only an approximation of the expected control output is also available) or if there is concern that the actuator signals may be spoofed (and there is either a redundant control system or approximation of the expected control output also available), then state measurements can be used (in the spirit of Detection Strategy 2-S as described in Section~\ref{sec:LEMPCsensor2}) to attempt to handle attacks. 

The motivation for considering this latter case in which state measurements and predictions are used to check whether an actuator attack is occurring is as follows: the difference between the redundant control system output or approximation of the control system output and the control output of the LEMPC that is expected to be used to control the process can be checked \textit{a priori}, before the controller is put online.  This will result in a known upper bound $\epsilon_u$ between control actions which might be computed by the LEMPC and those of the redundant or approximate controller (for the redundant controller, $\epsilon_u = 0$) for a given state measurement.  If the state measurements are intact, then state measurements and predictions under the redundant or approximate controller can be compared to assess the accuracy of the input that was actually applied.  The redundant or approximate controller can be used to estimate the input that should be applied to the process, and state predictions can be made using the nominal model of Eq.~\ref{eq:ClassofSystems} to check whether the input that was actually applied to the system seems to be sufficiently similar to the input that was expected (in the sense that it causes the control action that was actually applied to maintain the state measurement in an expected operating region), as it would have under the control action in the absence of an actuator attack, and keeps the norm of the difference between the state prediction and measurement below a bound.  Even if $\epsilon_u = 0$, process disturbances and measurement noise could cause the state prediction at the end of a sampling period over which a control action is applied to not fully match the measurement; however, if the error between the prediction and measurement is larger than a bound $\nu_u$ that should hold under normal operation considering the noise, value of $\epsilon_u$, and plant/model mismatch, this signifies that there is another source of error in the state predictions beyond what was anticipated, which can be expected to come from the input applied to the process deviating more significantly from what it should have been than was expected (i.e., an actuator attack is flagged).  Because the state measurements are correct, the state predictions are always initiated from a reasonably accurate approximation of the closed-loop state; therefore, with sufficient conservatism in the design of $\Omega_{\rho_1}$ and constant monitoring of whether the state measurement leaves that region, the closed-loop state can be prevented from leaving a safe operating region within a sampling period before an attack is detected.  We will call the resulting strategy Detection Strategy 2-A.  A method for designing a sufficiently conservative control strategy is shown in a later section in the context of a combined sensor and actuator attack-handling strategy that makes use of this methodology.  In contrast to Detection Strategy 2-S that can only ensure safe operation for at least one sampling period after a sensor attack is implemented, Detection Strategy 2-A, like Detection Strategy 1-A, can be made fully resilient to actuator cyberattacks in the sense that an undetected attack could not cause safety issues. As long as the actual and predicted input are sufficiently close in a norm sense (within $\epsilon_u$ of one another), and the disturbances and measurement noise are bounded, then the deviations between the actual and predicted input act as bounded plant/model mismatch (if no attack is detected) which an LEMPC can be designed to handle such that the actual state and predicted state trajectories can still be kept inside a safe region of operation under actuator attacks with monitoring of whether the state measurement leaves $\Omega_{\rho_1}$.  Once again, we see that the modifications to Detection Strategy 2-S, and casting it in a form applicable to actuator attacks rather than sensor attacks, significantly enhances the power of the strategy compared to what can be guaranteed with sensor attacks only.

%This could be extended to the case of measurement noise to fully capture the conditions required for using Detection Strategy 2-A, and would also demonstrate, like Detection Strategy 1-A, full resilience to actuator cyberattacks in the sense that an undetected attack could not cause safety issues.  

So far, the extended versions of Detection Strategy 1-S and of 2-S to the actuator-handling case have been more powerful against actuator attacks than Detection Strategies 1-S and 2-S have been against sensor attacks.  In contrast, attempting to utilize Detection Strategy 3-S, which enabled safety to be maintained for all times if a sensor measurement attack was undetected (and at least one redundant estimator was not), may result in a strategy that appears to be weaker in the face of actuator attacks.  One of the assumptions of Detection Strategy 3-S in Section \ref{sec:LEMPCsensor3} is that an observer exists which satisfies the conditions in Assumptions~\ref{assum:Assum1}-\ref{assum:Assum2}.  High-gain observers can meet this assumption, and under sufficient conditions, they meet this assumption regardless of the actual value of the input (which was important for achieving the results in Theorem~\ref{thm:Thm3} as noted in Remark~\ref{rem:Remark3}).  However, this means that in the case that only the inputs are awry, the state estimates would still be intact because of the convergence assumption, such that they will not deviate from one another in the desired way and Detection Strategy 3-S could not be used as an effective detection strategy for actuator attacks with such estimators. Though further investigation of whether other types of observer designs or assumptions could be more effective in designing an actuator attack-handling strategy based on Detection Strategy 3-S (to be referred to as Detection Strategy 3-A) could be pursued, these insights again indicate that there are fundamental differences between utilizing the detection strategies for actuator attack-handling compared to sensor attack-handling.  The discussion throughout this section therefore seems to suggest that the integrated control and detection frameworks presented above have structures which make them more or less relevant to certain types of attacks, and which also affect the extent to which they move toward flexible and lean frameworks with minimal redundancy for cyberattack detection, compared to relying on redundant systems.  For example, Detection Strategy 3-S relies on redundant state estimators for detecting sensor attacks, but Detection Strategy 2-A relies on having a redundant controller for detecting actuator attacks.  It is interesting in light of this that Detection Strategies 1-A and 1-S do not require redundant control laws, but do require many different steady-states to be selected over time.  We can also note that the strength of Detection Strategies 1-A and 2-A against actuator attacks above comes partially from the ability of the combined detection and control policies in those cases to set expectations for what the sensor signals should look like that, if not violated, indicate safe operation, and if violated, can flag an attack before safe operation is compromised.  As will be discussed later, this has relevance to notions of cyberattack discoverability in that to cause attacks to be discoverable, integrated detection and control needs to be performed such that the control theory can set the expectations for detection to be different if there is an attack or impending safety issue from an attack compared to if not, to force attacks to show themselves.  Part of the power of a theory-based control law like Detection Strategy 1-A or 2-A against actuator attacks is the ability to perform that expectation-setting.

\section{Motivation For Detection Strategies for Actuator and Sensor Attacks}

The above sections addressed how LEMPC might be used for handling sensor attacks or actuator attacks individually.  In this section, we utilize a process example to motivate further work on exploring how LEMPC might be used to handle both sensor and actuator attacks.  Specifically, consider the nonlinear process model below which consists of a continuous stirred tank reactor (CSTR) with a second-order, exothermic, irreversible reaction of the form $A \to B$ with the following dynamics:
\begin{equation}
\dot C_A = \frac{F}{V} (C_{A0}-C_A) -k_0 e^{-\frac{E}{R_gT}} C_A^2 \label{eq:ExampleSystem:Ca}
\end{equation}
\begin{equation}
\dot T = \frac{F}{V} (T_{0}-T) -\frac{\Delta H k_0}{\rho_{L} C_p} e^{-\frac{E}{R_gT}}C_A^2 + \frac{Q}{\rho_{L} C_p V} \label{eq:ExampleSystem:T}
\end{equation}
where the states are the reactant concentration of species $A$ ($C_A$) and temperature in the reactor ($T$).  The manipulated input is $C_{A0}$ (the reactant feed concentration of species $A$).  The values of the parameters of the CSTR model ($F$, $V$, $k_0$, $E$, $R_g$, $T_0$, $\rho_L$, $\Delta H$, and $C_p$) are taken from~\citep{HEIDARINEJAD2012926}.  The vectors of deviation variables for the states and input from their operating steady-state values, $x_{1s} = [C_{As} ~ T_s]^T = [2.00~ \text{kmol/m}^3 ~ 350.20~\text{K}]^T$, $C_{A0s} = 4.0~ \text{kmol/m}^3$, respectively, are $x_1 = [x_{1,1} ~ x_{1,2}]^T =  [C_A - C_{As}~ T - T_s]^T$ and $u_1 = C_{A0} - C_{A0s}$. The process model represented by Eqs.~\ref{eq:ExampleSystem:Ca}-\ref{eq:ExampleSystem:T} is numerically integrated using the explicit Euler method with integration step of $10^{-4}$ h. The stage cost, for which the time integral is desired to be maximized, is selected to be $L_e = k_0 e^{-E/(RT)} C_A^2$.  The sampling period was set to $\Delta = 0.01$ h, with the prediction horizon was set to $N = 10$.  The initial condition for the closed-loop state was 0.7 kmol/m$^3$ below the steady-state value for $C_A$, and 30 K below the steady-state value for $T$.  The LEMPC simulations were performed using fmincon on a Lenovo model 80XN x64-based ideapad 320 with an Intel(R) Core(TM) i7-7500U CPU at 2.70 GHz, 2904 Mhz, running Windows 10 Enterprise, in MATLAB R2016b.  To ensure that the fmincon solver status was that it stated it had found a local minimum, a variety of initial guesses for the solver were made at a sampling time if it did not find a local minimum using the first guess.

Lyapunov-based stability constraints in Eqs.~\ref{eq:LEMPCEqnconstraints:1}-\ref{eq:LEMPCEqnconstraints:2} were designed using a quadratic Lyapunov function $V_1 = x^T P x$, where $P= [110.11~0; 0 ~ 0.12]$.  The Lyapunov-based controller utilized was a proportional controller of the form $h_1(x_1) = -1.6 x_{1,1} - 0.01 x_{1,2}$ \citep{HEIDARINEJAD2012926} subject to input constraints ($|u_1| \leq 3.5$ kmol/m$^3$). The stability region was set to ${\rho_1} = 440$ (i.e., $\Omega_{{\rho_1}} = \{ x \in R^2 : V_1(x) \leq {\rho_1} \}$) and $\rho_{e,1}' = 330$. The LEMPC receives full state feedback which is sent to the LEMPC at synchronous time instants $t_k$. The controller receives a state measurement subject to bounded measurement noise and the process is subject to bounded disturbances. Specifically, the noise is represented by a standard normal distribution with mean zero, standard deviations of 0.0001 kmol/m$^3$ and 0.001 K, and bounds of 0.00001 kmol/m$^3$ and 0.0005 K for the concentration of the reactant and reactor temperature, respectively. In addition, disturbances were added to the right-hand side of the differential equations describing the rates of change of $C_A$ and $T$ with zero mean and standard deviations of 0.05 kmol/m$^3$ h and 2 K/h, and bounds of 0.005 kmol/m$^3$ h and 1 K/h, respectively.  Normally distributed random numbers were implemented using the randn function in MATLAB, with a seed of 10 to the random number generator rng.

We first seek to gain insight into the differences between single attack type cases and simultaneous sensor and actuator attacks.  To gain these insights, we will use strategies inspired by the detection strategies discussed above, but not meeting the theoretical conditions, so that these are not guaranteed to have resilience against any types of attacks (some discussion of moving toward getting theoretical parameters for LEMPC, which elucidates that obtaining the parameters which guarantee cyberattack-resilience for LEMPC formulations in practice should be a subject of future work, will be provided later in this work).  Despite the fact that there are no guarantees that any of the strategies used in this example which attempt to detect attacks will do so with the parameters selected, this example still provides a number of fundamental insights into the different characteristics of single attack types compared to simultaneous sensor and actuator attacks, providing motivation for the next results in this work.  We also consider that the attack detection mechanisms are put online at the same time as the cyberattack occurs (0.4 h), so that we do not consider that they would have flagged, for example, the changes in the sensor measurements under a sensor measurement attack between times prior to 0.4 h and 0.4 h.

The case studies to be undertaken in moving toward understanding differences between single and multiple attack type scenarios involve an LEMPC where the constraint of Eq.~\ref{eq:LEMPCEqnconstraints:2} is enforced at the sampling time, followed by constraints of the form of Eq.~\ref{eq:LEMPCEqnconstraints:1} enforced at the end of all sampling periods.  The first study involves an attack monitoring strategy that involves checking whether the closed-loop state is overall driven toward the origin over a sampling period (if it is not, a possibility of an attack will be flagged).  We implement attacks at 0.4 h; sensor attacks are implemented such that the measurement received by the sensor at 0.4 h would be faulty, and an actuator attack would be implemented by replacing the input computed for the time period between 0.4 to 0.41 h with an alternative input.  When no attack occurs in the sampling period following 0.4 h of operation, the Lyapunov function evaluated at the actual state and at the state measurement decreases over the subsequent sampling period, as shown in Figs.~\ref{fig:ActualV1}-\ref{fig:EvaluatedV1}.  

If instead we consider the case where only a rogue actuator output with the form $u = 0.5$ kmol/m$^3$ is provided to the process for a sampling period after 0.4 h of operation, Figs.~\ref{fig:ActualV1}-\ref{fig:EvaluatedV1} show that the Lyapunov function profile increases over one sampling period after the attack policy is applied, when the Lyapunov function is evaluated for both the actual state and the measured state, and thus, this single attack event would be flagged by the selected monitoring methodology.  Consider now the case where only a false state measurement for reactant concentration, with the form $x_1 + 0.5$ kmol/m$^3$, is continuously provided to the controller after 0.4 h of operation.  This false sensor measurement causes the Lyapunov function value to decrease along the measurement trajectory, as can be seen in Fig.~\ref{fig:EvaluatedV1}, showing that this attack would not be detected by the strategy.  However, it also decreases along the actual closed-loop state trajectory in this case (Fig.~\ref{fig:ActualV1}), so that no safety issues would occur in this sampling period.  This is thus a case when individual attacks would either be flagged over the subsequent sampling period or would not drive the closed-loop state toward the boundary of the safe operating region over that sampling period.  Due to the large (order-of-magnitude) difference in the value of $V_1$ evaluated along the measured state trajectory between the case that the sensor attack is applied and that no attack occurs, as shown in Fig.~\ref{fig:ActualV1}, it could be argued that this type of attack could be flagged by the steep jump in $V_1$ between times prior to the sensor attack that occurs at 0.4 h and 0.4 h.  However, because we assumed that the method for checking $V_1$ was not put online until 0.4 h, we assume that it does not have a record of the prior value of $V_1$, so that we can focus on the trends in this single sampling period after the attacks.

We now consider two scenarios involving combinations of sensor and actuator attacks.  First, we combine the two attacks just described (i.e., false measurements are continuously provided to the controller and detection policy, which have the form $x_1 + 0.5$ kmol/m$^3$, and rogue actuator outputs with the form $u = 0.5$ kmol/m$^3$ are provided directly to the actuators to replace any inputs computed by the controller).  This attack is applied to the process after 0.4 h of operation, and subsequently referred to as the ``baseline'' combined actuator and sensor attack because it is a straightforward extension of the two separate attack policies.  In this case, the value of $V_1$ increases along the measurement trajectory and also increases for the actual closed-loop state, so that this attack would be flagged by the proposed policy.  In some sense, the addition of the actuator attack made the fact that the system was under some type of attack ``more visible'' to this detection policy than in the sensor attack-only case (though the individual sensor attack was not causing the closed-loop state to move toward the boundary of the safe operating region, so that the lack of detection of an attack in that case would not be considered problematic).  

We next consider an alternative combined sensor and actuator attack policy, which we will refer to as a ``stealthy'' policy.  In this case, the attacker provides the exact state trajectory to the detection device that would have been obtained if there was no attack, while at the same time falsifying the inputs to the process.  In the case that this same false actuator trajectory was applied to the process and the sensor readings were accurate, we considered that it could be flagged.  With the falsified sensor readings occurring at the same time, however, the attack is both undetected and driving the closed-loop state closer to the boundary of the safe operating region over a sampling period.  From this, it can be seen that a major challenge arising from combining the attacks is that actuator attack detection policies based on state measurements may fail when attacks are combined, so that the state measurements may imply that the process is operating normally when problematic inputs are being applied. 

\begin{figure}
	\centering
	\includegraphics[width=0.7\columnwidth,clip]{fig/ActualV1.eps}
	\caption{Actual $V_1$ profiles over one sampling period after 0.4 h of operation for the process example described above in the presence of no attacks (``None''), only actuator cyberattacks (``Actuator''), only sensor attacks (``Sensor''), the baseline combined actuator and sensor attacks (``Combined''), and the stealthy combined sensor and actuator attack (``Stealthy'').  The plots for the actuator attack, baseline combined actuator and sensor attack, and stealthy sensor and actuator attack are overlaid due to all having the same input (the false actuator signal) over the sampling period.}
	\label{fig:ActualV1}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.7\columnwidth,clip]{fig/EvaluatedV1.eps}
	\caption{$V_1$ profiles evaluated using the state measurements over one sampling period after 0.4 h of operation for the process example described above in the presence of no attacks (``None''), only actuator cyberattacks (``Actuator''), only sensor attacks (``Sensor''), the baseline combined actuator and sensor attacks (``Combined''), and the stealthy combined sensor and actuator attack (``Stealthy'').  The plots for no attack and for the stealthy combined sensor and actuator attack are overlaid because the stealthy attack provides the no-attack sensor trajectory to the detection device to evade detection.}
	\label{fig:EvaluatedV1}
\end{figure}

This raises the question of whether there are alternative detection policies that might flag combined attacks, including those of the stealthy type just described that was ``missed'' by the detection policy described above where an overall decrease in the Lyapunov function value for the measured state across a sampling period was considered.  For example, some of the detection methods described in the prior sections are able to flag actuator attacks before safety issues occur, whereas others flag sensor attacks.  This suggests that detection strategies with different strengths might be combined into two-part detection strategies that involve multiple detection methods.  To explore the concept of combining multiple methods of attempting to detect attacks (where again this example does not meet theoretical conditions required for resilience and is meant instead to showcase concepts underlying simultaneous attack mechanisms), we consider designing a state estimator for the process to use to compare state estimates against full state feedback.  If the difference between the state estimates and state measurements is larger than a threshold considered to represent abnormal behavior, we will flag that an attack might be occurring.  In addition, we will monitor the decrease in the Lyapunov function evaluated along the trajectory of the state measurement over time, and flag a potential attack if it is noticeably increasing across a sampling period.

To implement such a strategy, we must first design a state estimator.  We will use the high-gain observer from \citep{HEIDARINEJAD2012926} with respect to a transformed system state obtained via input-output linearization.  This estimator (which is redundant because full state feedback is available) will be used to estimate the reactant concentration of species $A$ from continuously available temperature measurements. The observer equation using the set of new coordinates is as follows:
\begin{equation}
\begin{aligned}
\dot{\hat{z}} = A \hat{z} + L (y - C \hat{z})  \label{eq:observereqn}
\end{aligned}
\end{equation}
where $\hat{z}$ is the state estimate vector in the new coordinate $z = [x_2~\dot{x}_2]^T$~\cite{Khalil19965}, $y$ is the output measurement, $A=[0~1;0~0]$, $C = [1~0]$, and $L = [100~10000]^T$. To obtain the state estimate of the system $z$, the inverse transformation $T^{-1}(\hat{z})$ is applied.  

The next step in designing the detection strategy is to decide on a threshold for the norm of the difference between the state estimate and the state feedback.  As a rough attempt to design one that avoids flagging measurement noise and process disturbances as attacks, data from attack-free scenarios is gathered by simulating the process under different initial conditions and inputs within the input bounds. Particularly, we simulate attack-free events with an end time of 0.4 h of operation for initial conditions in the following discretization: $x_1$ ranges from -1.5 kmol/m$^3$ to 3 kmol/m$^3$ in increments of 0.1 kmol/m$^3$, with $x_2$ ranging from -50 K to 50 K in increments of 5 K.  When these initial conditions are within the stability region, the initial value of the state estimate is found in the transformed coordinates based on assuming that that initial condition holds.  Then, inputs must be generated to apply to the process with noise and disturbances.  To explore what the threshold on the difference between the state measurement and estimate might be after 0.4 h to set a threshold to use when the state estimation-based attack detection strategy comes online at that time, we try several different input policies.  One is to try $h_1(x)$ at every integration step; if this is done, then the maximum value of the norm of the difference between the state estimate and state measurement at 0.4 h among the scenarios tested is 0.026.  If instead a random input policy is used (i.e., at every integration step, a new value of $u$ is generated with mean zero and standard deviation of 2, and bounds on the input of -3.5 and 3.5 kmol/m$^3$), then the maximum value of the difference between the state estimate and state measurement at 0.4 h among the scenarios tested is 0.122.  If instead the random inputs are applied in sample-and-hold with a sampling period of length 0.01 h, the maximum value of the difference between the state estimate and state measurement at 0.4 h is 0.885.  If the norm of the error between the state estimate and state measurement is checked at 1 h instead of 0.4 h in the three cases above, the results are 0.003, 0.107, and 0.923, respectively.  Though a limited data set was used in these simulations and theoretical principles of high-gain observer convergence were not reviewed in developing this threshold, 0.923 was selected for the cyberattack detection strategy based on the simulations that had been performed.  One could also set the threshold by performing simulations for 0.4 h for a number of different initial states, specifically operated under the LEMPC, instead of the alternative policies above.  Changing the threshold in the following discussion could have an impact on attack detection, though there would still be fundamental differences between single attack-type scenarios and simultaneous attack-type scenarios as discussed below.  

We next consider application of the same form of the baseline attacks as described in the prior example occurring at once, i.e., false measurements are continuously provided to the controller, which have the form $x_1 + 0.5$ kmol/m$^3$, and rogue actuator outputs with the form $u = 0.5$ kmol/m$^3$ are provided to the process at 0.4 h of operation.  In this combined attack scenario, the norm of the difference between the (falsified) state measurement and the state estimate at 0.4 h is 0.5016, and at 0.41 h is 0.5233, demonstrating that if the threshold is set to a larger number such as 0.923, the state estimate-based detection mechanism does not flag this attack at 0.4 or 0.41 h.  Fig.~\ref{fig:Case1a} plots the closed-loop state trajectory against the state estimate trajectory over one sampling period after 0.4 h of operation, showing the closeness of the trajectories in that time period despite the sensor and actuator attacks at 0.4 h.  In fact, if this system is simulated with an actuator attack only, then the difference in the state estimate and state measurement at 0.41 h (the time at which the effects of the actuator attack could first be observed in the process data) is 0.05, showing that with the selected threshold for flagging an attack based on the difference between the state estimate and measurement, the actuator attack only would not be flagged at 0.41 h (despite that there is a net increase in the Lyapunov function value along the measured state trajectory in this case, because that is not being checked with only the state estimate-based detection strategy).  Considering that the threshold was set based on non-attacked measurements and many different input policies for the threshold set, it is reasonable to expect that an attack would not be flagged if only the input was to change.

For the baseline combined sensor and actuator case, Fig.~\ref{fig:Case1a_Vx} shows that the Lyapunov function increases over the sampling period after 0.4 h along the measurement trajectory.  Therefore, like the case where only the Lyapunov function was checked to attempt to flag this baseline combined attack, the baseline combined sensor and actuator attack can be detected here as well between 0.4 and 0.41 h.  Though the attack occurs and is flagged, the closed-loop state was still kept inside the stability region $\Omega_{\rho_1}$ over the sampling period that the attacks were applied, as indicated in Fig.~\ref{fig:Case1a_StabilityRegion}.  

\begin{figure}
	\centering
	\includegraphics[width=0.7\columnwidth,clip]{Case1a.eps}
	\caption{Comparison between the closed-loop state trajectory under attack (solid line) and the closed-loop state estimate trajectory (dashed lines) over one sampling period after 0.4 h of operation under the state feedback LEMPC.}
	\label{fig:Case1a}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=0.7\columnwidth,clip]{fig/Case1a_Vx.eps}
	\caption{$V_1$ profile along the measurement trajectory over one sampling period after 0.4 h of operation for the process example in the presence of multiple cyberattack policies (baseline case).}
	\label{fig:Case1a_Vx}
\end{figure}
\begin{figure}
	%\centering
	%	      \framebox{\parbox{3in}{}}
	%\includegraphics[width=0.8\columnwidth]{fig/Ca-T.eps}
	\centering
	\includegraphics[width=0.7\columnwidth,clip]{Case1a_StabilityRegion.eps}
	\caption{Stability region and closed-loop state trajectory for the process example in the presence of multiple cyberattack policies (baseline case).}
	\label{fig:Case1a_StabilityRegion}
\end{figure}

If the stealthy combined sensor and actuator attack from the prior section is applied, the Lyapunov function value along the closed-loop state trajectory is again increasing, but again it is decreasing along the estimated trajectory between 0.4 and 0.41 h.  However, if this simulation is run longer, then the attack is eventually detected via the deviation of the state estimates from the state measurements exceeding the 0.923 threshold, at 0.45 h.  In the case that only the Lyapunov function value along the measured state trajectories is checked until 0.45 h, no attack is yet detected, as the Lyapunov function value continues to decrease from 0.4 to 0.45 h along the measured state trajectory.  These examples indicate the complexities of having combined sensor and actuator attacks, and also showcase that different detection policies may be better suited for detecting the combined attacks than others.  This motivates further study of techniques and theory for handling the combined attacks, which is the subject of the next section.

\begin{rmk}
	The combined methods illustrated in the examples above do not determine the source of the attacks (e.g., the reason why the Lyapunov function increases could be either due to false sensors, incorrect actuator outputs, or both).  However, the nature of a sensor attack differs from a sensor fault. A faulty sensor creates a state trajectory that is not inherently ``dynamics-based'' and intelligently designed to harm a process.  
\end{rmk}

\section{Integrated Cyberattack Detection and Control Strategies using LEMPC under Multiple Attack Type Scenarios} \label{sec:LEMPCboth}

The detection concepts described in the prior sections (and summarized in Table~\ref{Detection_Strategies}) have been developed to handle only single attack type scenarios (i.e., either false sensor measurements or rogue actuator signals). However, to make a CPS resilient against different types of cyberattacks, the closed-loop system must be capable of detecting and mitigating scenarios where multiple types of attacks may happen simultaneously.  As in the prior sections, detection approaches that not only enable detection of attacks, but that also prevent safety breaches when an attack is undetected, are most attractive.  This section extends the discussion of the prior sections to ask whether the detection strategies from~\cite{oyama2020integrated} that were developed for sensor cyberattack-handling and extended to actuator cyberattack-handling above can be used in handling simultaneous sensor and actuator attacks on the control systems.

\begin{table}
	\begin{center}
		\begin{tabular}{|p{3cm}|p{3cm}|p{8cm}|} \hline
			% \multicolumn{3}{|c|}{Major Detection Strategies} \\ \hline
			\textbf{Detection Strategy} & \textbf{Component Attacked} & \textbf{Detection/Control Policy}\\ \hline
			Strategy $1-$S & Sensor & Random updates to LEMPC \\ \hline
			Strategy $2-$S & Sensor & Based on state predictions from last state measurement received \\ \hline
			Strategy $3-$S & Sensor & Based on cross-checks of state estimates between multiple redundant state estimators \\ \hline 
			Strategy $1-$A & Actuator & Updates to LEMPC at every sampling time \\ \hline
			Strategy $2-$A & Actuator & Based on state predictions under expected inputs \\ \hline
			Strategy $3-$A & Actuator & Based on cross-checks of state estimates between multiple redundant state estimators\\ \hline
		\end{tabular}		
		\caption{Single attack-type cyberattack detection strategies described.} \label{Detection_Strategies}
	\end{center}
\end{table}

We first note that based on the discussion in Section~\ref{sec:ActuatorAttackOnly}, we do not expect only a single method previously described (Detection Strategies 1-S, 2-S, 3-S, 1-A, 2-A, or 3-A) to be capable of handling both sensor and actuator cyberattacks occurring simultaneously.  Instead, to handle the possibility that both types of attacks may occur, we expect that we may need to combine these strategies.  However, care must be taken to select and design integrated control/detection strategies such that cyberattack detection and handling are guaranteed even when sensors and/or actuators are under attack.  This is because the two types of attacks can interact with one another to degrade the performance of some of the attack detection/handling strategies that work for single attack types as suggested in the example of the prior section.  For example, as noted in Section~\ref{sec:ActuatorAttackOnly}, in general, sensor measurement cyberattack-handling strategies may make use of correct actuator outputs in identifying attacks, and actuator attack-handling strategies may make use of ``correct'' (except for the sensor noise) sensor measurements in identifying attacks.  If the actuators are no longer providing a correct output, it is then not a given that a sensor measurement cyberattack-handling strategy can continue to be successful, and if the sensors are attacked, it is not a given that an actuator cyberattack-handling strategy can continue to be successful.  In this section, we analyze how the various methods in this work perform when these interactions between the sensor and actuator attacks may serve to degrade performance of strategies that worked successfully for only one attack type.

We discuss below the nine possible pairings of actuator and sensor attack-handling strategies based on the detection strategies discussed in this work.  The goal of this discussion is to elucidate which of the combined strategies may be successful at preventing simultaneous sensor and actuator attacks from causing safety issues, and which could not be based on counterexamples:
\begin{itemize}
	\item Pairing Detection Strategies 1-S and 1-A: These two strategies have essentially the same construction (where when both are activated, there must be constant changing of the steady-states around which the $j$-LEMPC's are designed for constant probing to satisfy the requirements of using Detection Strategy 1-A), in which a decrease in the Lyapunov function value along the measured state trajectories is looked for to detect both the actuator and sensor attacks.  Consider a scenario in which an attacker provides sensor measurements that show a decrease in the Lyapunov function value when that would be expected, thus preventing the attack from being detected by the sensors.  At the same time, the actuators may be producing inputs unrelated to what the sensors show, which could cause safety issues even if the sensors are not indicating any safety issues, due to attacks occurring on both the sensors and actuators.  This pairing therefore is not resilient against combined attacks on the actuators and sensors (i.e., it is not guaranteed to detect attacks that would cause safety issues).
	\item Pairing Detection Strategies 1-S and 2-A: Detection Strategy 1-S relies on the value of the Lyapunov function decreasing between the beginning and end of a sampling period when the Lyapunov function is evaluated at the state measurement.  Detection Strategy 2-A relies on the difference between a state prediction (from the last state measurement and under the expected input corresponding to that measurement) and a state measurement being less than a bound.  This design faces a challenge for resilience against simultaneous sensor and actuator attacks in that the detection strategies for both types of policies depend on the state measurements.  Since the state measurements here are falsified, this gives room for any actuator signal to be utilized, and then the sensors to provide readings which suggest that the Lyapunov function is decreasing and that the prediction error is within a bound.  Thus, in this strategy, because there is not a way to cross-check whether the sensor measurements are correct when there is also an actuator attack, safety is not guaranteed when there are undetected simultaneous attacks.
	\item Pairing Detection Strategies 1-S and 3-A: Detection Strategy 1-S relies on the state measurement creating a decrease in the Lyapunov function, while Detection Strategy 3-A relies on redundant state estimates being sufficiently close to one another.  If Detection Strategy 1-S is not constantly activated (i.e., there is not continuous probing), then because Detection Strategy 3-A is not guaranteed to detect actuator attacks and Detection Strategy 1-S may not detect them between probing times as described in Section~\ref{sec:ActuatorAttackOnly}, this strategy may not be resilient against actuator attacks (and thus also may not be against simultaneous actuator and sensor attacks).  However, a slight modification to the strategy to achieve constant probing under Detection Strategy 1-S, forming the pairing of Detection Strategies 3-S and 1-A (because Detection Strategies 3-A and 3-S are equivalent in how they are performed) is resilient against simultaneous sensor and actuator attacks, as is further discussed below.  If instead of probing, $\Omega_{\rho_1}$ is designed to be a sufficiently conservative subset of a safe operating region, then it could be checked whether at any time, the state measurement leaves $\Omega_{\rho_1}$ to flag the attacks; this strategy would also follow similarly to the strategy for detecting attacks using the combination of Detection Strategies 3-S and 1-A for which a proof is provided in a subsequent section.
	\item Pairing Detection Strategies 2-S and 1-A: This strategy faces similar issues to the combination of Detection Strategies 1-S and 2-A above.  Specifically, these strategies again utilize state measurements only to flag attacks, allowing rogue actuator inputs to be applied at the same time as false state measurements without allowing the attacks to be flagged.
	\item Pairing Detection Strategies 2-S and 2-A: This is a case where only state measurements are being used to flag attacks, so like other methods above where this is insufficient to prevent the masking of rogue actuator trajectories by false sensor measurements, this strategy is also not resilient against attacks.
	\item Pairing Detection Strategies 2-S and 3-A: Detection Strategy 2-S is based on the expected difference between state predictions and actual states and Detection Strategy 3-A is based on checking the difference between multiple redundant state estimates.  If the threshold for Detection Strategy 2-S is redesigned (forming a pairing that we term as the combination of Detection Strategies 2-A and 3-S below since the threshold redesign must account for actuator attacks as described for Detection Strategy 2-A above to avoid false alarms), the strategy would be resilient to simultaneous actuator and sensor attacks.  This is further detailed in the subsequent sections (though it requires that at least one state estimator is not impacted by the attacks).
	\item Pairing Detection Strategies 3-S and 1-A: This detection strategy can be made resilient against simultaneous actuator and sensor attacks, and receives further attention in the following sections to demonstrate and discuss this (though at least one state estimator cannot be impacted by the attacks).
	\item Pairing Detection Strategies 3-S and 2-A: This strategy can be made resilient for adequate thresholds on the state prediction and state estimate-based detection metrics, and will be further detailed below.
	\item Pairing Detection Strategies 3-S and 3-A: This strategy faces the challenge that it may not enable actuator attacks to be detected because both Detection Strategy 3-S and Detection Strategy 3-A are dependent only on state estimates, which may not reveal incorrect inputs as discussed in Section~\ref{sec:ActuatorAttackOnly}.  Therefore, it would not be resilient for a case when actuator and sensor attacks could both occur if the redundant observer threshold holds regardless of the applied input.
\end{itemize}

The above discussion highlights that to handle both the sensor and actuator attacks, a combination strategy cannot be based on sensor measurements alone.  In the following sections, we detail how the combination strategies using Detection Strategies 3-S and 1-A, and 3-S and 2-A, can be made resilient against simultaneous sensor and actuator attacks in the sense that, as long as at least one state estimate is not impacted by a false sensor measurement attack, the closed-loop state is always maintained within a safe operating region if attacks are undetected, even if both attack types occur at once.  We note that the assumptions that the detectors are intact (e.g., that at least one estimator is not impacted by false sensor measurements, or that a state prediction error-based metric is evaluated against its threshold) implies that other information technology (IT)-based defenses at the plant are successful, indicating that the role of these strategies at this stage of development is not in replacing IT-based defenses, but in providing extra layers of protection if there are concerns that the attacks could reach the controller itself (while leaving some sensor measurements and detectors un-compromised).

\subsection{Simultaneous Sensor and Actuator Attack-Handling Via Detection Strategies 3-S and 1-A: Formulation and Implementation} \label{sec:SimultaneousLEMPCImplementationStrategy}

In the spirit of the individual strategies Detection Strategy 3-S and Detection Strategy 1-A, a combined policy (to be termed Detection Strategy 1/3) can be developed that uses redundant state estimates to check for sensor attacks (assuming that at least one of the estimates is not impacted by any attack), and also uses different LEMPC's at every sampling time that are designed around different steady-states but contained within a subset of a safe operating region $\Omega_{\rho_{safe}}$ (the subsets are called $\Omega_{\rho_{i}} \subset \Omega_{\rho_{safe}}$).  Under sufficient conditions (which will be clarified in the next section), both the closed-loop state and state estimate are maintained in $\Omega_{\rho_{safe}}$ for all time for the process without attacks or with undetected attacks. The notation to be used for the LEMPC for Detection Strategy 1/3 has the form in Eq.~\ref{eq:p-LEMPCEqn2s} with Eq.~\ref{eq:p-LEMPCEqn2s:Measurement} replaced by $\tilde{x}_i(t_k) = z_{1,i}(t_k)$ (in this subsection, we will refer to this LEMPC as the $i$-th output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn2s}). The output feedback LEMPC design of Eq.~\ref{eq:p-LEMPCEqn2s} receives a state estimate $z_{1,i}$ at $t_k$.  In the following, $i$ will be used as a subscript for some of the previously introduced notation to reflect that the quantity is defined for the system in deviation variable form from the $i$-th steady-state.


%For the latter case, although the closed-loop system may be under attack, undetected rogue input or sensor signals must still cause the Lyapunov function $V_i$ along the actual closed-loop state trajectory to decrease over the next sampling period (because the detection policies force any incorrect signals to close enough to the true values to enable computation of control actions which are still stabilizing).  As in Section~\ref{sec:LEMPCsensor1}, we also must ensure a sufficient decrease in $V_i$ under the proposed control law to ensure that $V_i$ evaluated at the state predictions decreases as part of this strategy between the beginning and end of a sampling period.

The implementation strategy for Detection Strategy 1/3 assumes that the process has already been run successfully in the absence of attacks under the $i=1$ output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn2s} for some time ($t_{q}$) such that $|z_{j,i}(t) - x_i(t)| \leq \epsilon_{mj}^*$ for all $j=1,\ldots,M$. In consonance with \cite{oyama2020integrated}, we consider bounded measurement noise (i.e., $|x_i(t_k) - \tilde{x}_i(t_k)| \leq \theta_{v,i}$). For bounded measurement noise, subset regions of $\Omega_{\rho_i} \subset \Omega_{\rho_{safe}}$, termed $\Omega_{\rho_{g,i}}$ and $\Omega_{\rho_{h,i}}$, $i \ge 1$, must be considered in the implementation strategy, and they are selected such that if the state measurement is in $\Omega_{\rho_{g,i}} \subset \Omega_{\rho_{h,i}} \subset \Omega_{\rho_1}$, then the closed-loop state and the state measurement are maintained in $\Omega_{\rho_{safe}}$ under sufficient conditions. We assume that no attacks occur before $t_{q}$.
\begin{enumerate}
	\item \label{step:StepPre} Before $t_{q}$, operate the process under the $1$-LEMPC of Eq.~\ref{eq:p-LEMPCEqn2s}.  Go to Step~\ref{step:Step0a}. 
	\item \label{step:Step0a} At sampling time $t_k$, when the $i$-th output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn2s} was just used over the prior sampling period to control the process of Eq.~\ref{eq:ClassofSystems}, if $|z_{j,i}(t_k) - z_{p,i}(t_k)| > \epsilon_{\max}$, $j=1,\ldots,M$, $p=1,\ldots,M$, or $\tilde{x}_i(t_k) = z_{1,i}(t_k) \notin \Omega_{\rho_i} \subset \Omega_{\rho_{safe}}$, detect that a cyberattack is occurring and go to Step~\ref{step:Step1a}. Else, go to Step~\ref{step:Step1b} ($i \leftarrow i+1$).
	\item \label{step:Step1a} Mitigating actions may be applied (e.g., a backup policy such as the use of redundant controller or an emergency shut-down mode).  
	\item \label{step:Step1b} Select a new $i$-th steady-state.  This steady-state must be such that the closed-loop state measurement in deviation from from the new steady-state $\tilde{x}_i(t_k)$ is not in a neighborhood $\Omega_{\rho_{s,i}}$ of the $i$-th steady-state.  This steady-state must be such that $\tilde{x}_i(t_k) \in \Omega_{\rho_{g,i}} \subset \Omega_{\rho_{h,i}} \subset \Omega_{\rho_{i}} \subset \Omega_{\rho_{1}} \subset \Omega_{\rho_{safe}}$ and the steady-state input is within the input bounds ($\Omega_{\rho_{g,i}}$ is selected such that if the state measurement at $t_k$ is in $\Omega_{\rho_{g,i}}$ then the closed-loop state and the state estimate are maintained in $\Omega_{\rho_{i}} \subset \Omega_{\rho_{safe}}$ over the subsequent sampling period under sufficient conditions). Go to Step~\ref{step:Step3b}.

	\item \label{step:Step3b} The control actions computed by the $i$-LEMPC of Eq.~\ref{eq:p-LEMPCEqn2s} for the sampling period from $t_k$ to $t_{k+1}$ is used to control the process according to Eq.~\ref{eq:p-LEMPCEqn2s}. Go to Step \ref{step:Step4b}.
	\item \label{step:Step4b} Evaluate the Lyapunov function at the beginning and end of the sampling period, using the state measurements. If $V_i$ does not decrease over the sampling period or if $\tilde{x}_i(t_{k+1}) = z_{1,i}(t_{k+1})$ is not within $\Omega_{\rho_{i}} \subset \Omega_{\rho_{safe}}$ or $\Omega_{\rho_1}$, detect that the process is potentially under a cyberattack. Go to Step~\ref{step:Step1a}. Else, go to Step~\ref{step:Step5b}.
	\item \label{step:Step5b} ($t_k \leftarrow t_{k+1}$). Go to Step \ref{step:Step0a}.
\end{enumerate}
\begin{rmk}
	Though the focus of the discussions has been on preventing safety issues, it is possible that the detection and control policies described in this work may sometimes detect other types of malicious attacks that attempt to spoil products or cause a process to operate inefficiently to attack economics. The impacts of the probing strategies on process profitability (compared to routine operation) can be a subject of future work. 
\end{rmk}

\subsubsection{Simultaneous Sensor and Actuator Attack-Handling Via Detection Strategies 3-S and 1-A: Stability and Feasibility Analysis} \label{sec:Detection_Strategy:Stability}

In this section, we prove recursive feasibility and safety of the process of Eq.~\ref{eq:ClassofSystems} under the LEMPC formulations of the output feedback LEMPC's of Eq.~\ref{eq:p-LEMPCEqn2s} whenever no sensor or actuator attacks are detected according to the implementation strategy in Section~\ref{sec:SimultaneousLEMPCImplementationStrategy} in the presence of bounded measurement noise. The theorem below characterizes the safety guarantees (defined as maintaining the closed-loop state in $\Omega_{\rho_{safe}}$) of the process of Eq.~\ref{eq:ClassofSystems} for all time under the implementation strategy of Section~\ref{sec:SimultaneousLEMPCImplementationStrategy} when no sensor and actuator cyberattacks are detected.  

\begin{thm} \label{thm:DS1_Stability}
	Consider the closed-loop system of Eq. \ref{eq:ClassofSystems} under the implementation strategy of Section~\ref{sec:SimultaneousLEMPCImplementationStrategy} (which assumes the existence of a series of steady-states which can satisfy the requirements in Step~\ref{step:Step1b}), where the switching of the controllers at sampling times starts after $t_{q}$ and no sensor or actuator cyberattack is detected with the $i$-th output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn2s} based on an observer and controller pair satisfying Assumptions~\ref{assum:Assum1}-\ref{assum:Assum2} (in which at least one of the state estimators is not affected by false state measurements) and formulated with respect to the $j=1$ measurement vector, and where each controller $h_i(\cdot)$, $i \ge 1$, used in each $i$-LEMPC meets the inequalities in Eqs. \ref{eq:constraintsLyapunov1}-\ref{eq:constraintsLyapunov4} and~\ref{eq:Lipschitzh} with respect to the $i$-th dynamic model. Let $\theta_{w,i} \leq \theta_{w,i}^*$, $\theta_{v,i} \leq \theta_{v,i}^*$, $\epsilon_i \in (\epsilon_{Li}^*,\epsilon_{Ui}^*)$, and $|z_{j,i}(t_0) - x_i(t_0)| \leq e_{m0j,i}$, for $j=1,\ldots,M$. Let $\epsilon_{W,i} >0$, $\Delta >0$, $N \ge 1$, $\rho_{safe} > \rho_{samp4} > \rho_{samp3} > \rho_1 > \rho_{h,1} > \rho_{h,1}'$, $\Omega_{\rho_p} \subset \Omega_{\rho_1} \subset X_1$ for $p \ge 2$, $\rho_i > \rho_{h,i} > \rho_{g,i} > \rho_{\min,i} > \rho_{s,i} > \rho_{s,i}'> 0$, where $\Omega_{\rho_{g,i}}$ is defined as a level set within $\Omega_{\rho_i} \subset \Omega_{\rho_1} \subset \Omega_{\rho_{safe}} $ that guarantees that if $V_i(z_{1,i}(t_k)) \leq \rho_{g,i}$, $V_i(x_i(t_k)) \leq \rho_{h,i}$.  Let the following inequalities be satisfied:
	\begin{equation}
	\rho_{g,i} = \max \{ V_i(z_{1,i}(t_k)) : V_i(x_i(t_k)) \leq \rho_{h,i}, ~ i = 2, \ldots,~ |z_{1,i}(t_k) - x_i(t_k)| \leq \epsilon_{M,i}^* \} \label{eq:newrhoG}
	\end{equation}		
	\begin{equation}
	\begin{aligned}
	\rho_{h,1}' & \leq \rho_{h,1} - M_{f,1} \max\{t_{z1},\Delta \} \alpha_{4,1}(\alpha_{1,1}^{-1}(\rho_{1})) \label{eq:rhoh}
	\end{aligned}
	\end{equation}
	\begin{equation}
	\begin{aligned}
	& -\alpha_{3,i}(\alpha_{2,i}^{-1}(\rho_{s,i}')) + L_{x,i}'(M_{f,i} \Delta + \epsilon_{M,i}^*)  + L_{w,i}' \theta_{w,i} \leq -\epsilon_{W,i}/\Delta, ~ i = 1, 2, \ldots \label{eq:newcond2}
	\end{aligned}
	\end{equation}
	\begin{equation}
	\rho_{h,i} + f_{V,i}(\epsilon_{M,i}^*) < \rho_{i}, ~ i = 1, 2, \ldots \label{eq:cond3}
	\end{equation}
	\begin{equation}
	\rho_{\min,i} = \max \{ V_i(x_i(t)) : x_i(t_k) \in \Omega_{\rho_{s,i}'} \}, ~t \in [t_k,t_{k+1}),~u_i\in U_i, ~ i = 1, 2, \ldots \label{eq:newrhoMin}
	\end{equation}
	%\begin{equation}
	%\rho_{samp2,1} \geq \max \{ V_i(x_(t_k)) : \tilde{x}_i(t_k) \in \Omega{\rho_{\min,i}} \}, ~ i = 1, 2, \ldots \label{eq:newrhoMin2}
	%\end{equation}
	\begin{equation}
	\rho_{s,i}' < \min \{ V_i(x_i(t_k)) : z_{1,i}(t_k) \in \Omega_{\rho_{g,i}} / \Omega_{\rho_{s,i}},~ |z_{1,i}(t_k) - x_i(t_k)| \leq \epsilon_{M,i}^* \}, ~ i = 1, 2, \ldots \label{eq:newrhoS}
	\end{equation}	

	%	\begin{equation}
	%	\rho_{i}' < \min \{ V_i(x(t_k)) | \tilde{x}_i(t_k) \in \rho_{i} \}, ~ i = 1, 2, \ldots  \label{eq:newrhoi'}
	%	\end{equation}
	%	\begin{equation}
	%	\rho_{i}' \ge \max \{ V_i(x(t)) | \tilde{x}_i(t_k) \in \rho_{h,i}' \} \label{eq:newrhoi}
	%	\end{equation}
	\begin{equation}
	\begin{aligned}
	\epsilon_{W,i} & > \max_{z_{1,i}(t_k) \in \Omega_{\rho_{g,i}}/\Omega_{\rho_{s,i}}} \left| \min \{ V_i(z_{1,i}(t_k)) : z_{1,i}(t_k) \in \Omega_{\rho_{g,i}}/\Omega_{\rho_{s,i}} \} \right. \\
	& \left. - \max \{ V_i(z_{1,i}(t_{k+1})) : z_{1,i}(t_{k}) \in \Omega_{\rho_{g,i}}/\Omega_{\rho_{s,i}}, ~u_i \in U_i, ~|x_i(t_p) - z_{1,i}(t_p)| \leq \epsilon_{M,i}^*,~p=k,k+1 \} \right| \label{eq:epsWibound}
	\end{aligned}
	\end{equation} 
	\begin{equation}
	\rho_{samp3} = \max \{ V_i(x_i(t_k)) : z_{1,i}(t_k) \in \Omega_{\rho_1}, ~ i = 2, \ldots,~ |z_{1,i}(t_k) - x_i(t_k)| \leq \epsilon_{M,i}^*\} \label{eq:rhosamp3}
	\end{equation}	
	\begin{equation}
	\rho_{samp4} = \max \{ V_i(x_i(t)) : V_i(x_i(t_k)) \leq \rho_{samp3}, ~ i = 2, \ldots, ~u_i(t_k) \in U_i, ~t \in [t_k,t_{k+1}) \} \label{eq:rhosamp4}
	\end{equation}	

	where $t_{z1}$ is the first sampling time after $t_{b1}$, $i=1,\ldots,M$. Then, if $x_1(t_0) \in \Omega_{\rho_{h,1}'}$, $x_i(t) \in \Omega_{\rho_{safe}}$ for all $t\geq 0$ and $z_{1,i}(t) \in \Omega_{\rho_{safe}}$ for $t \ge \max \{\Delta, t_{z1} \}$ until a cyberattack is detected according to the implementation strategy in Section~\ref{sec:SimultaneousLEMPCImplementationStrategy}, if the attack occurs after $t_{q}$ under the $i$-th LEMPC.
\end{thm}
\begin{proof} 
	The proof consists of four parts.  In \textit{Part 1}, feasibility of the $i$-th output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn2s} is proven when $z_{1,i}(t_k) \in \Omega_{\rho_{i}}$. In \textit{Part 2}, we show that the closed-loop state trajectory is contained in $\Omega_{\rho_{h,1}} \subset \Omega_{\rho_{safe}}$ for $t \in [t_0, \max \{\Delta, t_{z1}\})$. In \textit{Part 3}, we prove that for $t > \max \{\Delta, t_{z1} \}$ but before an attack occurs, $x_i(t)$ and $z_{1,i}(t)$ are bounded within $\Omega_{\rho_{1}}$, and that $(V_i(t_{k+1}) - V_i(t_k)) < 0$. In \textit{Part 4}, we prove that if there is an attack (either a false sensor measurement attack, actuator attack, or both) at $t_k$ but it is not detected using the proposed control/detection strategy (i.e., $|z_{j,i}(t) - z_{p,i}(t)| \leq \epsilon_{\max_i}$ and $(V_i(t_{k+1}) - V_i(t_k)) < 0$, for all $j = 1,\ldots,M$, $p=1,\ldots,M$), $x_i(t)$ and $z_{1,i}(t)$ are bounded in $\Omega_{\rho_{safe}}$.
	
	\textit{Part 1.} The Lyapunov-based controller $h_i$ implemented in sample-and-hold is a feasible solution to the $i$-th output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn2s} when $\tilde{x}_i(t_k) = z_{1,i}(t_k) \in \Omega_{\rho_{i}} \subset \Omega_{\rho_{safe}}$. Specifically, $h_i(\tilde{x}(t_p))$, $p=k,\ldots,k+N-1$, $t \in [t_p,t_{p+1})$, is a feasible solution to the $i$-th output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn2s} because it meets the input constraints of Eq.~\ref{eq:p-LEMPCEqn2s:InputConstraint} according to Eq.~\ref{eq:constraintsLyapunovA}, it trivially satisfies Eq.~\ref{eq:p-LEMPCEqn2constraints:2}, and it satisfies Eq.~\ref{eq:p-LEMPCEqn2s:StateConstraint} when $\tilde{x}_i(t) \in \Omega_{\rho_i} \subset X_i$ according to the implementation strategy in Section~\ref{sec:SimultaneousLEMPCImplementationStrategy}.  $h_i(\tilde{x}(t_p))$, $p=k,\ldots,k+N-1$, $t \in [t_p,t_{p+1})$, ensures that $\tilde{x}_i(t) \in \Omega_{\rho_i}$ by the properties of the Lyapunov-based controller~\cite{de2008lyapunov} where, if the conditions of Eqs.~\ref{eq:newcond2} and \ref{eq:newrhoMin} are met, then if $\tilde{x}_i(t_p) \in \Omega_{\rho_i}/\Omega_{\rho_{s,i}'}$, $V_i(\tilde{x}_i)$ decreases throughout the following sampling period (keeping the closed-loop state in $\Omega_{\rho_i}$), or if $\tilde{x}_i(t_p) \in \Omega_{\rho_{s,i}'}$, $\tilde{x}_i(t) \in \Omega_{\rho_{\min,i}} \subset \Omega_{\rho_i}$ for $t\in[t_p,t_{p+1})$. 
	
	\textit{Part 2.} To demonstrate boundedness of the closed-loop state in $\Omega_{\rho_1} \subset \Omega_{\rho_{safe}}$ for $t \in [t_0, \max \{\Delta, t_{z1}\})$, the Lyapunov function along the closed-loop state trajectory can be evaluated as follows:
	\begin{equation}  \label{eq:LyapunovEvalution}
	\begin{aligned}
	V_1(x_1(t)) & = V_1(x_1(t_0)) + \int_{t_0}^{t} \frac{\partial V_1(x_1(\tau))}{\partial \tau} \, d\tau = V_1(x_1(t_0)) + \int_{t_0}^{t} \frac{\partial V_1({x}_1(\tau))} {\partial x} \dot{x}_1(\tau) \, d\tau \\
	& \le \rho_{h,1}' + M_{f,1} \max \{\Delta, t_{z1}\} \alpha_{4,1}(\alpha_{1,1}^{-1}(\rho_{1}))
	\end{aligned}
	\end{equation} 
	for all $t \in [t_0,  \max \{\Delta, t_{z1}\})$, where the latter inequality follows from Eq.~\ref{eq:constraintsLyapunovA}, Eq.~\ref{eq:FBound}, and $x(t_0) \in \Omega_{\rho_{h,1}'} \subset \Omega_{\rho_{1}}$. If $\rho_{h,1}'$ satisfies Eq.~\ref{eq:rhoh}, then $V_1(x_1(t)) \leq \rho_{h,1},~ \forall t \in [t_0, \max \{\Delta, t_{z1}\})$, i.e., $x_1(t) \in \Omega_{\rho_{h,1}} \subset \Omega_{\rho_1}$ for all $t \in [t_0, \max \{\Delta, t_{z1}\})$. The state estimate is also maintained within $\Omega_{\rho_1}$ at $t_{z1}$ if Eq. \ref{eq:cond3} and Proposition~\ref{prop:VDifm} hold and there is no attack, because then:
	\begin{equation}
	\begin{aligned}
	V_1(z_{1,1}(t_{z1})) & \leq V_1(x_1(t_{z1})) + f_{V,1}(|z_{1,1}(t_{z1}) - x_{1}(t_{z1})|) \leq \rho_{h,1} + f_{V,1}(\epsilon_{M,1}^*) < \rho_1 \label{eq:DifBytz1}
	\end{aligned}
	\end{equation}	
	
	\textit{Part 3.} To demonstrate boundedness of the closed-loop state and state estimate in $\Omega_{\rho_{safe}}$ for $t \ge [t_0, \max \{\Delta, t_{z1}\})$, we first consider that the process is not experiencing a cyberattack (i.e., $|z_{j,i}(t_k) - x_i(t_k)| \leq \max(e_{mj,i})$, for all $j=1,\ldots,M$).  Since $x_1(t_{z1}) \in \Omega_{\rho_{h,1}} \subset \Omega_{\rho_1}$ and $z_{1,1}(t_{z1}) \in \Omega_{\rho_1}$ from Part 1, the implementation strategy of Section~\ref{sec:SimultaneousLEMPCImplementationStrategy} can be executed at $t_{z1}$, and according to Step~\ref{step:Step1b}, $x_i(t_{z1})$ will be contained in $\Omega_{\rho_{h,i}}$.  Similar to the steps presented in the third theorem in \cite{oyama2020integrated}, considering Eqs.~\ref{eq:p-LEMPCEqn2constraints:2}, \ref{eq:constraintsLyapunovA}, and \ref{eq:Lipschitz2}, the bound on $w_i$, and adding and subtracting the term $\frac{\partial V_i(\tilde{x}_i(t_k))} {\partial x} f_i(\tilde{x}_i(t_k), u_i(t_k),0)$ to/from $\dot{V}_i(x_i(t)) = \frac{\partial V_i(x_i(t))} {\partial x} f_i(x_i(t),u_i(t_k),w_i(t))$ and using the triangle inequality, we obtain:
	\begin{equation}
	\begin{aligned}
	\dot{V}_i(x_i(t)) & \le -\alpha_{3,i}(|\tilde{x}_i(t_k)|) + L_{x,i}'|x_i(t)-\tilde{x}_i(t_k)| + L_{w,i}' \theta_{w,i} \label{eq:Thm3Part3VdotPrelimBound}
	\end{aligned}
	\end{equation}
	From $|x_i(t)-\tilde{x}_i(t_k)| \le |x_i(t)-x_i(t_k)| + |x_i(t_k)-\tilde{x}_i(t_k)|$, and from Eq.~\ref{eq:p-LEMPCEqn2s:Measurement} with $\tilde{x}_i(t_k) = z_{1,i}(t_k)$, we obtain that:
	\begin{equation}
	\begin{aligned}
	|x_i(t)-\tilde{x}_i(t_k)| \le |x_i(t)-x_i(t_k)| + \epsilon_{M,i}^* \label{eq:Theorem3Part3Bounder}
	\end{aligned}
	\end{equation}
	From Eqs.~\ref{eq:FBound},~\ref{eq:Theorem3Part3Bounder}, and~\ref{eq:Thm3Part3VdotPrelimBound}, and considering $\tilde{x}_i(t_k) \in \Omega_{\rho_{g,i}} / \Omega_{\rho_{s,i}}$: 
	\begin{equation}
	\begin{aligned}
	\dot{V}_i(x_i(t)) \le -\alpha_{3,i}(\alpha_{2,i}^{-1}(\rho_{s,i})) + L_{x,i}'(M_{f,i} \Delta + \epsilon_{M,i}^*) + L_{w,i}' \theta_{w,i} \label{eq:Theorem3Part3Bounder2}
	\end{aligned}
	\end{equation}
	for all $t \in [t_k,t_{k+1})$. According to the implementation strategy in Section~\ref{sec:SimultaneousLEMPCImplementationStrategy}, when $z_{1,i}(t_k) \in \Omega_{\rho_{g,i}} / \Omega_{\rho_{s,i}}$, then $x_i(t_k) \in \Omega_{\rho_{h,i}} / \Omega_{\rho_{s,i}'}$ by Eqs.~\ref{eq:newrhoG} and \ref{eq:newrhoS}. If the condition of Eq.~\ref{eq:newcond2} is satisfied, Eq.~\ref{eq:Theorem3Part3Bounder2} gives:
	\begin{equation}
	\begin{aligned}
	V_i(x_i(t)) \le V_i(x_i(t_{k})) - \frac{\epsilon_{W,i}(t-t_k)}{\Delta},~t~\in [t_k,t_{k+1}) \label{eq:VdotDecrease}
	\end{aligned}
	\end{equation}
	Thus, when $x_i(t_k) \in \Omega_{\rho_{h,i}} / \Omega_{\rho_{s,i}'}$ and $z_{1,i}(t_k) \in \Omega_{\rho_{g,i}} / \Omega_{\rho_{s,i}}$, $x_i(t_{k+1}) \in \Omega_{\rho_{h,i}} \subset \Omega_{\rho_{1}}$.   
	
	To ensure that the estimate for $t \in [t_k,t_{k+1})$ is within $\Omega_{\rho_{i}} \subset \Omega_{\rho_{1}}$, Proposition \ref{prop:VDifm} gives the following inequality:
	\begin{equation}
	\begin{aligned}
	V_i(z_{1,i}(t_{k+1})) & \leq V_i(x_i(t_{k+1})) + f_{V,i}(|x_i(t_{k+1}) - z_{1,i}(t_{k+1})|) \leq V_i(x_i(t_{k+1})) + f_{V,i}(\epsilon_{M,i}^*) \label{eq:FinalThmPart3C}
	\end{aligned}
	\end{equation}
	When $x_i(t_{k+1}) \in \Omega_{\rho_{h,i}}$ as was just demonstrated for the case that no attacks occur, this gives that $V_i(z_{1,i}(t_{k+1})) \le \rho_{i}$ if Eq.~\ref{eq:cond3} holds.  If instead $x_i(t_k) \in \Omega_{\rho_{s,i}'}$, Eq.~\ref{eq:newrhoMin} ensures that $V_i(x_i(t_{k+1})) \in \Omega_{\rho_{\min,i}} \subset \Omega_{\rho_{h,i}}$ and therefore we conclude by the same logic as above that $V_i(z_{1,i}(t_{k+1})) \le \rho_{i}$ if Eq.~\ref{eq:cond3} holds.
	
	To see that the implementation strategy with updates of $i$ and the LEMPC at every sampling time maintains $x_i(t_k) \in \Omega_{\rho_1}$ and $z_{1,i}(t_k) \in \Omega_{\rho_1}$ for all time, we note that the proof above shows that if $x_i(t_{z1}) \in \Omega_{\rho_{h,1}}$, then $z_{1,i}(t_{k+1})\in \Omega_{\rho_1}$ and $x_i(t_{k+1}) \in \Omega_{\rho_{h,i}} \subset \Omega_{\rho_1}$.  At $t_{k+1}$, under the assumption of the theorem that it is again possible to find all regions for LEMPC design according to Step~\ref{step:Step1b} of the implementation strategy, $\Omega_{\rho_i}$ and its subsets will be selected so that the same proof as above holds throughout the subsequent sampling period and $z_{1,i}(t_{k+2})\in \Omega_{\rho_1}$ and $x_i(t_{k+2}) \in \Omega_{\rho_{h,i}} \subset \Omega_{\rho_1}$.  This indicates that $z_{1,i}$ would be within $\Omega_{\rho_1}$ at all sampling times before an attack, and that $x_i(t) \in \Omega_{\rho_1}$ as well.  To ensure $(V_i(z_{1,i}(t_{k+1})) - V_i(z_{1,i}(t_k))) < 0$ so that flagging an attack in Step~\ref{step:Step4b} of the implementation strategy of Section~\ref{sec:SimultaneousLEMPCImplementationStrategy} would not cause attacks to be detected when none are occurring, the requirement of Eq.~\ref{eq:epsWibound} with the input computed by the $i$-LEMPC should be satisfied, according to the logic of Section~\ref{sec:LEMPCsensor1} of this manuscript.
	
	\textit{Part 4.} Finally, we consider the case that at some $t_k \ge t_{q}$, the process is under either an undetected false sensor measurement cyberattack (Case 1), actuator cyberattack (Case 2) or both (Case 3). 
	
	\textit{Part 4 - Case 1.} If the control system is under only a sensor attack, but it is not detected, $|z_{1,i}(t_k) - x_i(t_k)| \le \epsilon_{M,i}^*$. Thus, from Part 3 above, the closed-loop state and state estimate are guaranteed to be inside $\Omega_{\rho_i} \subset \Omega_{\rho_1}$ by the implementation strategy of Section \ref{sec:SimultaneousLEMPCImplementationStrategy}. 
	
	\textit{Part 4 - Case 2.} If the control system is under only an actuator attack, but it is not detected, then an input that is not that computed by the $i$-LEMPC is being applied to the process over a sampling period.  The actuator attack will be detected if several conditions which are evaluated at the end of a sampling period (at $t_{k+1}$) occur (e.g., $V_j(z_{1,i}(t_{k})) < V_j(z_{1,i}(t_{k+1}))$, $V_j(z_{1,i}(t_{k+1})) > \rho_i$, $|z_{j,i}(t_{k+1}) - z_{p,i}(t_{k+1})| > \epsilon_{\max}$, $j=1,\ldots,M$, $p=1,\ldots,M$, or $V_j(z_{1,i}(t_{k+1})) \notin \Omega_{\rho_1}$).  However, if an actuator attack occurs at $t_k$, this means that its effects will not be observed for flagging an attack until $t_{k+1}$, leaving the possibility that the closed-loop state could exit a desired operating region before the sampling period is over.  To prevent this, we define a worst-case scenario in Eqs.~\ref{eq:rhosamp3}-\ref{eq:rhosamp4}, where it may be possible that the state estimate is within $\Omega_{\rho_1}$ at a sampling time but that the actual state is outside of it (within $\Omega_{\rho_{samp3}}$) and an attack is not flagged since $V_j(z_{1,i}(t_k)) \in \Omega_{\rho_1}$ (i.e., at least one of the detection conditions is not violated, leaving a possibility of non-detection depending on the state of the other detection conditions).  In such a case, under a rogue actuator output, the closed-loop state either remains in $\Omega_{\rho_{samp3}}$, where the estimate may not be outside $\Omega_{\rho_1}$ for detecting the attack based on whether $z_{1,i}(t_k) \in \Omega_{\rho_1}$ or not, or it is within $\Omega_{\rho_{samp4}} \subset \Omega_{\rho_{safe}}$, but in a part of it where the attack can be flagged at $t_{k+1}$.  Then, the attack is flagged while the closed-loop state is still in $\Omega_{\rho_{safe}}$.  In contrast, if the state estimate was in $\Omega_{\rho_1}$, then in the following sampling period, the closed-loop state either enters $\Omega_{\rho_{samp4}}/\Omega_{\rho_{samp3}}$ and is flagged, or it remains in $\Omega_{\rho_{samp3}}$ and this process continues into subsequent sampling periods. The attack would be flagged before the closed-loop state leaves $\Omega_{\rho_{safe}}$ because Eqs.~\ref{eq:rhosamp3}-\ref{eq:rhosamp4} show that the state cannot go farther from the origin than $\Omega_{\rho_{samp4}}$ in a sampling period if the attack is not detected at the beginning of the sampling period, and $\Omega_{\rho_{samp4}} \subset \Omega_{\rho_{safe}}$.  

	\textit{Part 4 - Case 3.} If the control system is under both sensor and actuator attacks, but they are not detected, the rogue actuator and sensor outputs must still maintain the state estimates in $\Omega_{\rho_{1}}$. Since the state estimates must be within $\Omega_{\rho_1}$ and $|z_{1,i}(t_k) - x_i(t_k)| \le \epsilon_{M,i}^*$ must be satisfied (as a sensor attack is not detected) with at least one estimate not being affected by an attack, the reasoning in Part 4 - Case 2 can be used to conclude that the combined attacks cannot cause the closed-loop state or state estimate to exit $\Omega_{\rho_{safe}}$ without the attack being detected.
	
	%If the $i$-th output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn2s} is used according to the implementation strategy of Section \ref{sec:SimultaneousLEMPCImplementationStrategy}, where Eq.~\ref{eq:newrhoS} is satisfied, because Eq.~\ref{eq:newcond2} holds for $x(t) \in \Omega_{\rho_{i}'} / \Omega_{\rho_{s,i}'}$, the Lyapunov function decreases over the next sampling period when the $i$-LEMPC computes control signals to the process. Thus, the closed-loop state and state measurement at the next sampling time are maintained inside $\Omega_{\rho_1} \subset \Omega_{\rho_{safe}}$.
	
	Above, it is demonstrated that whether attacks are occurring or not, the closed-loop state and state estimate cannot leave $\Omega_{\rho_{safe}}$ without an attack being detected in any sampling period.  This indicates that the implementation strategy in Section~\ref{sec:SimultaneousLEMPCImplementationStrategy} maintains the closed-loop state within a safe operating region at all times before an attack is detected, even if undetected sensor and actuator attacks occur during that time period.
\end{proof} 
\begin{rmk}
	The proof for Part 4 - Case 2 described above gives an indication of how the proof of closed-loop stability for actuator-only attacks on an LEMPC of the 1-A form would be carried out, but (noisy) state measurements then might be used in place of state estimates.
\end{rmk}
\begin{rmk} \label{NestedRegions2}
	Several regions have been defined for the proposed detection strategy. $\Omega_{{\rho_i}} \subset \Omega_{{\rho_{safe}}}$, $i =1,2,\ldots$, has been defined as an invariant set in which the closed-loop state is maintained.  We define the region $\Omega_{\rho_{h,i}}$ such that if the state measurement is within $\Omega_{\rho_{g,i}}$ at $t_k$, the actual state is within $\Omega_{\rho_{h,i}} \subset \Omega_{\rho_{i}}$ (Eq.~\ref{eq:newrhoG}). We also define the region $\Omega_{\rho_{s,i}}$ such that if the state measurement is within $\Omega_{\rho_i} / \Omega_{\rho_{s,i}}$ at $t_k$, the actual state is not within $\Omega_{\rho_{s,i}'}$ (Eq.~\ref{eq:newrhoS}).  In addition, $\Omega_{\rho_{\min,i}}$ is characterized as a region where if $x_i(t_k) \in \Omega_{\rho_{s,i}'}$, the actual state is within $\Omega_{\rho_{\min,i}}$ (Eq.~\ref{eq:newrhoMin}). 	The definition of $\Omega_{\rho_{h,i}}$ ensures that the state estimate at $t_{k+1}$ is in $\Omega_{\rho_i}$ when there is no attack, if $x_i(t_k) \in \Omega_{\rho_{h,i}}$.
\end{rmk}

\subsection{Simultaneous Sensor and Actuator Attack-Handling Via Detection Strategies 3-S and 2-A: Formulation and Implementation} \label{ImplementationStrategyDT23}

Following the idea of pairing single detection strategies above, another integrated framework, named Detection Strategy 2/3, can be developed that uses redundant state estimates to check for sensor attacks (again assuming that at least one of the estimates is not impacted by any attack), and relies on the difference between a state prediction based on the last available state estimate (obtained using an expected control action computed by either a fully redundant controller or an approximation of the controller output for a given state estimate) and a state estimate being less than a bound.  The premise of checking the difference between the state estimate and the state prediction is that the state prediction should not be able to deviate too much from a (converged) state estimate (i.e., it approximates the actual process state to within a bound as in Assumption~\ref{assum:Assum2} after a sufficient period of time has passed since initialization of the state estimates) if there are no sensor or actuator attacks, and that therefore seeing the estimate and prediction deviate by more than an expected amount is indicative of an attack.

If the actual state is inside a subset $\Omega_{\rho_{max}}$ of the stability region $\Omega_{\rho}$, then under sufficient conditions (which will be clarified in the next section), both the closed-loop state and state estimate are maintained in a safe operating region $\Omega_{\rho_{safe}}$ for all time for the process without attacks or with undetected attacks. The notation to be used for the LEMPC for Detection Strategy 2/3 follows that of Eq.~\ref{eq:p-LEMPCEqn1s} with Eq.~\ref{eq:p-LEMPCEqn1s:Measurement} replaced by $\tilde{x}(t_k) = z_{1}(t_k)$ (we will subsequently refer to this LEMPC as the output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn1s}). In this control formulation, the output feedback LEMPC design of Eq.~\ref{eq:p-LEMPCEqn1s} receives a state estimate $z_{j}$ ($j=1,\ldots,M$) from one of the redundant state estimators (the estimator used to provide state estimates to the proposed LEMPC that controls the process will be denoted as the $j=1$ estimator) at $t_k$. 

To present the implementation strategy and subsequent proof in the next section that Detection Strategy 2/3 can be made cyberattack-resilient in the sense that it can guarantee safety whenever no sensor or actuator attacks are flagged by this combined detection framework, it is necessary to determine the detection threshold for the difference between the state estimate and state prediction.  Unlike in the case where a bound on the difference between state predictions and state measurements was derived for Detection Strategy 2-S for sensor attacks, we here need to set up mechanisms for detecting whether an actuator and/or sensor attack occurs.  While state estimates are available to aid in detecting sensor attacks, part of the mechanism for detecting whether actuator attacks occur is the use of a fully redundant controller (for which the input computed by the output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn1s} is equivalent to the input computed by the redundant controller used in cross-checking the controller outputs) or fast approximation of the control outputs (for which the input computed by the LEMPC would differ, within a bound, from the input computed by the algorithm used in cross-checking the controller outputs) for a given state measurement.  The definition below defines the notation that will be used in this section to represent the actual state trajectory under the control input computed by the LEMPC and the state prediction obtained from the nominal ($w \equiv 0$) process model of Eq.~\ref{eq:ClassofSystems} under the potentially approximate input used for cross-checking the control outputs.

\begin{Definition} \label{DefinitionDS2A}
	Consider the state trajectories for the actual process and for the predicted state from $t \in [t_0, t_1)$, which are the solutions of the systems:
	\begin{subequations} \label{eq:DefEqs}
		\begin{align} 
		&\dot{x}_{a} = f(x_{a} (t), \bar{u}(t), w(t)) \label{eq:subsystems1M} \\
		&\dot{x}_{b} = f(x_{b}(t), \hat{u}(t), 0) \label{eq:subsystems2M}
		\end{align}
	\end{subequations}
	where $|x_a(t_0) - z_1(t_0)| \le \gamma$.  $x_a$ is the state trajectory for the actual process, where $\bar{u}$ is the optimal the input for $t \in [t_0, t_1)$ computed from the output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn1s} based on the estimate $z_1(t_0)$, where $z_1(t_0)$ is an estimate of the actual state $x_a(t_0)$ at $t_0$.  $\hat{u}$ is a (potentially) different input that is applied to the process that results in the trajectory $x_b$ corresponding to the predicted value of the closed-loop state when $\hat{u}$ is computed by the method for cross-checking the controller inputs.  For any method used for cross-checking the controller inputs computed, the following bound is assumed to be known to hold:	
	\begin{equation}
	\begin{aligned}
	& |\bar{u}(t) - \hat{u}(t)| \le \epsilon_u \label{eq:MaxDevU}
	\end{aligned}
	\end{equation} 
	where $\epsilon_u$ is the maximum deviation in the inputs computed for a given state estimate between the output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn1s} and the method for cross-checking the controller inputs (if a fully redundant controller is utilized, $\epsilon_u = 0$).  
\end{Definition}  

The following proposition bounds the difference between $x_a$ and $x_b$ in Definition \ref{DefinitionDS2A}. 

\begin{prop} \label{PropDS2A}
	Consider the systems in Definition \ref{DefinitionDS2A} operated under the output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn1s} and designed based on a controller $h(\cdot)$, which satisfies Eqs.~\ref{eq:constraintsLyapunovA}-\ref{eq:Lipschitzh}. Then, the following bound holds:
	\begin{equation}
	\begin{aligned}
	& |x_a(t) - x_b(t)| \le f_u(\gamma,t)
	\end{aligned}
	\end{equation}
	and initial states $|x_a(t_0) - x_b(t_0)| \le \gamma$, where $x_b(t_0) = z_1(t_0)$ and $t_0 = 0$:	
	\begin{equation}
	\begin{aligned}
	& f_u (s, \tau) := se^{L_xt} + (e^{L_xt} - 1)\left( \frac{L_u \epsilon_u + L_w \theta}{L_x} \right) \label{eq:fu}
	\end{aligned}
	\end{equation}
\end{prop}

\begin{proof}
	Integrating Eqs.~\ref{eq:subsystems1M}-\ref{eq:subsystems2M} from $t_0$ to $t$, subtracting the second equation from the first, and taking the norm of both sides gives:
	\begin{subequations} 
		\begin{align}
		& |x_a(t) - x_b(t)| \le |x_a(t_0) - z_1(t_0)| + \int_{0}^{t} |f(x_{a} (s), \bar{u}(0), w(s)) - f(x_{b}(s), \hat{u}(0), 0)| ~ds  \\
		&\le \gamma + \int_{0}^{t} [|f(x_{a} (s), \bar{u}(0), w(s)) - f(x_{b}(s), \bar{u}(0), 0)| + |f(x_{b}(s), \bar{u}(0), 0) - f(x_{b}(s),\hat{u}(0), 0)|] ~ds  
		\end{align}
	\end{subequations}
	for $t \in [0, t_1)$. Using Eqs.~\ref{eq:Lipschitz1} and~\ref{eq:LipschitzInu} and the bound on $w$, the following bound is achieved:
	\begin{subequations} 
		\begin{align}
		& |x_a(t) - x_b(t)|   \le \gamma + \int_{0}^{t} [L_u |\bar{u}(0) - \hat{u}(0)| + L_x |x_a(s) - x_b(s)| + L_w|w(s)|] ~ds  \\
		&\le \gamma + L_u |\bar{u}(0) - \hat{u}(0)| (t - 0) + L_x \int_{0}^{t} |x_a(s) - x_b(s)| + L_w\int_{0}^{t} \theta ~ds  \\
		&\le \gamma + (L_u \epsilon_u + L_w \theta) t + L_x \int_{0}^{t} |x_a(s) - x_b(s)| ~ds  
		\end{align}
	\end{subequations}
	for $t \in [0, t_1)$, where the last inequality follows from Eq.~\ref{eq:MaxDevU}. Finally, using the Gronwall-Bellman inequality~\cite{Khalil19965}, it is obtained that:
	\begin{equation}
	\begin{aligned}
	& |x_a(t) - x_b(t)|  \le \gamma e^{L_xt} + (e^{L_xt} - 1)\left( \frac{L_u \epsilon_u + L_w \theta}{L_x} \right)
	\end{aligned}
	\end{equation}
\end{proof}

Proposition \ref{PropDS2A} can be used to develop an upper bound on the maximum possible error which would be expected to be seen between a state prediction and a state estimate at a sampling time if no attacks occur.  This bound is developed in the following proposition.
\begin{prop} \label{prop:nubound}
	Consider $x_a$ and $x_b$ defined as in Definition~\ref{DefinitionDS2A}.  If $|z_{j}(t_k) - z_{p}(t_k)| < \epsilon_{\max}$ and $|z_{j}(t_{k+1}) - z_{p}(t_{k+1})| < \epsilon_{\max}$, $j=1,\ldots,M$, $p=1,\ldots,M$, and Eq.~\ref{eq:MaxDevU} holds in the absence of an attack, then the worst-case error between the state estimate $z_1(t_{k+1})$ and the state prediction $\tilde{x}_b(t_{k+1}|t_k)$ of the state at time $t_{k+1}$ from an estimate obtained at time $t_k$ in the absence of an attack on the actuators or sensors is given by:
	\begin{equation}
	|z_1(t_{k+1}) - \tilde{x}_b(t_{k+1}|t_k)| \leq \epsilon_{M}^* + f_u(\epsilon_M^*,\Delta) \label{eq:propnubound:bound}
	\end{equation}
\end{prop}
\begin{proof}
	Using Propositions~\ref{prop:OutputFdbkProp1} and \ref{PropDS2A} along with Eq.~\ref{eq:DetectionConditions}, we obtain:
	\begin{equation}
		\begin{aligned}
		|z_1(t_{k+1}) - \tilde{x}_b(t_{k+1}|t_k)| & \leq |z_1(t_{k+1}) - x_a(t_{k+1})| + |x_a(t_{k+1}) - \tilde{x}_b(t_{k+1}|t_k)| \\
		& \leq \epsilon_M^* + f_u(|x_a(t_k) - z_1(t_k)|,\Delta) \leq \epsilon_M^* + f_u(\epsilon_M^*,\Delta)
		\end{aligned}
	\end{equation}
\end{proof}

Proposition \ref{prop:nubound} demonstrates that if an upper bound $\nu_u \geq \epsilon_M^* + f_u(\epsilon_M^*,\Delta)$ is placed on $|z_1(t_{k+1}) - \tilde{x}_b(t_{k+1}|t_k)|$, then a cyberattack could be flagged if $|z_1(t_{k+1}) - \tilde{x}_b(t_{k+1}|t_k)| > \nu_u$ without creating false alarms, as $|z_1(t_{k+1}) - \tilde{x}_b(t_{k+1}|t_k)|$ should never become greater than $\nu_u$ if no attack is occurring according to the proof of the proposition.

We now describe the implementation strategy of Detection Strategy 2/3 which assumes that the process has already been run successfully in the absence of attacks under the output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn1s} for some time ($t_{q}$) such that $|z_{j}(t) - x(t)| \leq \epsilon_{mj}^*$ for all $j=1,\ldots,M$. %In addition, we also consider bounded measurement noise (i.e., $|x(t_k) - \tilde{x}_1(t_k)| \leq \theta_{v}$). %For bounded measurement noise, subset regions of $\Omega_{\rho_i} \subset \Omega_{\rho_{safe}}$, termed $\Omega_{\rho_{h,i}}$, $i \ge 1$, must be considered in the implementation strategy, and they are selected such that if the state measurement is in $\Omega_{\rho_{g,i}} \subset \Omega_{\rho_{h,i}} \subset \Omega_{\rho_1}$, then the closed-loop state and the state measurement are maintained in $\Omega_{\rho_{safe}}$ under sufficient conditions. 
\begin{enumerate}
	%\item \label{step:StepPre} Before $t_{z1}$ ($t_{z1} \geq \max\{ t_{b1} \}$), operate the process under the $1$-LEMPC of Eq.~\ref{eq:p-LEMPCEqn2s}.  Go to Step~\ref{step:Step0a}. 
	\item \label{step:Step0a2} At sampling time $t_k$, when the output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn1s} is used to control the process of Eq.~\ref{eq:ClassofSystems}, if $|z_{j}(t_k) - z_{p}(t_k)| > \epsilon_{\max}$ or $|z_{j}(t_{k-1}) - z_{p}(t_{k-1})| > \epsilon_{\max}$, $j=1,\ldots,M$, $p=1,\ldots,M$, or $\tilde{x}(t_k) = z_{1}(t_k) \notin \Omega_{\rho}$ (where $z_{1}$ is the state estimate used in the proposed LEMPC design that controls the process), detect that a cyberattack is occurring and go to Step~\ref{step:Step1a2}.  If no attack is flagged, check whether $|\tilde{x}(t_k|t_{k-1}) -z_1(t_k)| > \nu_u$ (where $\nu_u \geq \epsilon_M^* + f_u(\epsilon_M^*,\Delta)$).  If yes, flag that a cyberattack is happening and go to Step~\ref{step:Step1a2}. Else, go to Step~\ref{step:Step1b2}. 
	\item \label{step:Step1a2} Mitigating actions may be applied (e.g., a backup policy such as the use of redundant controller or an emergency shut-down mode).  
	\item \label{step:Step1b2}  Control the process using the output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn1s}.  Go to Step~\ref{step:Step5b2}.
	\item \label{step:Step5b2} ($t_k \leftarrow t_{k+1}$). Go to Step \ref{step:Step0a2}.
\end{enumerate}	

\subsubsection{Simultaneous Sensor and Actuator Attack-Handling Via Detection Strategies 3-S and 2-A: Stability and Feasibility Analysis}

In this section, we prove recursive feasibility and stability of the process of Eq.~\ref{eq:ClassofSystems} under the proposed output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn1s} whenever no sensor or actuator attacks are detected according to the implementation strategy in Section~\ref{ImplementationStrategyDT23} in the presence of bounded plant/model mismatch, controller cross-check error, and measurement noise. The following theorem characterizes the safety guarantees of the process of Eq.~\ref{eq:ClassofSystems} for all time under the implementation strategy of Section~\ref{ImplementationStrategyDT23} when sensor and actuator cyberattacks are not detected.  As for Detection Strategy 1/3, because the actuator cyberattacks would not be detected according to the implementation strategy in Section~\ref{ImplementationStrategyDT23} until a sampling period after they had occurred (since they are being detected by their action on the state estimates, which would not be obvious until they have had a chance to impact the closed-loop state), it is necessary to define supersets $\Omega_{\rho_{samp3}}$ and $\Omega_{\rho_{samp4}}$ of $\Omega_{\rho}$, but which are contained in $\Omega_{\rho_{safe}}$, to set the size of $\Omega_{\rho}$ with respect to $\Omega_{\rho_{safe}}$ to ensure that $\Omega_{\rho}$ is defined in a sufficiently conservative fashion such that even if the closed-loop state is driven out of $\Omega_{\rho}$, the closed-loop state will still always be in $\Omega_{\rho_{safe}}$ and the state estimate will go out of $\Omega_{\rho}$ before the actual closed-loop state leaves $\Omega_{\rho_{safe}}$. 

\begin{thm} \label{thm:ThmDS23}
	Consider the closed-loop system of Eq.~\ref{eq:ClassofSystems} under the implementation strategy of Section \ref{ImplementationStrategyDT23}, in which no sensor or actuator cyberattack is detected using the proposed output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn1s} based on an observer and controller pair satisfying Assumptions~\ref{assum:Assum1}-\ref{assum:Assum2} and formulated with respect to the $i=1$ measurement vector and a controller $h(\cdot)$ that meets Eqs.~\ref{eq:constraintsLyapunov1}-\ref{eq:constraintsLyapunov4} and~\ref{eq:Lipschitzh}.  Let the conditions of Propositions~\ref{prop:OutputFdbkProp1}-\ref{PropDS2A} hold, and $\theta_w \leq \theta_w^*$, $\theta_{v,i} \leq \theta_{v,i}^*$, $\epsilon_i \in (\epsilon_{Li}^*,\epsilon_{Ui}^*)$, and $|z_i(t_0) - x(t_0)| \leq e_{m0i}$, for $i=1,\ldots,M$.  Also, let $\epsilon_{W,1} > 0$, $\Delta > 0$, $\Omega_{\rho} \subset X$, and $\rho_{safe} > \rho_{samp4} > \rho_{samp3} > \rho > \rho_{\max} > \rho_{1,1} > \rho_{e,1}' > \rho_{\min,1} > \rho_{s,1} > 0$, satisfy:
	\begin{equation}
	\begin{aligned}
	\rho_{e,1}' & \leq \rho_{\max} - \max\{f_V(f_W(\epsilon_{M}^*,\Delta)), M_f \max\{t_{z1},\Delta \} \alpha_4(\alpha_1^{-1}(\rho_{\max})) \} \label{eq:rhoe23}
	\end{aligned}
	\end{equation}
	\begin{equation}
	\rho_{e,1}' \leq \rho - f_V(f_W(\epsilon_{M}^*,\Delta))  - f_V(\epsilon_{M}^*) \label{eq:NewEqn123}
	\end{equation}
	\begin{equation}
	\begin{aligned}
	& -\alpha_3(\alpha_2^{-1}(\rho_{s,1})) + L_x'(M_f \Delta + \epsilon_{M}^*)  + L_w' \theta_w \leq -\epsilon_{W,1}/\Delta \label{eq:cond223}
	\end{aligned}
	\end{equation}
	\begin{equation}
	\rho_{\min,1} = \max \{ V(x(t+\Delta)) | V(x(t)) \leq \rho_{s,1} \} \label{eq:rhoMin23}
	\end{equation}	
	\begin{equation}
	\rho_{\min,1} + f_V(f_W(\epsilon_M^*,\Delta)) \leq \rho \label{eq:rhoMin223}
	\end{equation}
	\begin{equation}
	\rho_{\max} + f_V(\epsilon_M^*) \leq \rho \label{eq:NewEqn223}
	\end{equation}	
	\begin{equation}
	\rho_{samp3} = \max \{ V(x(t_k)) : z_{1}(t_k) \in \Omega_{\rho}, ~ |z_{1}(t_k) - x(t_k)| \leq \epsilon_{M}^*\} \label{eq:rhosamp3Proof2}
	\end{equation}	
	\begin{equation}
	\rho_{samp4} = \max \{ V(x(t)) : V(x(t_k)) \leq \rho_{samp3}, ~u(t_k) \in U, ~t \in [t_k,t_{k+1}) \} \label{eq:rhosamp4Proof2}
	\end{equation}	
	where $t_{z1}$ is the first sampling time after $t_{b1}$, and $f_V$, $f_W$, and $f_u$ are defined as in Propositions~\ref{prop:TrajectoryDifm},~\ref{prop:VDifm} (with the subscripts dropped), and \ref{PropDS2A}. Then, if $x(t_0) \in \Omega_{\rho_{e,1}}$, $x(t) \in \Omega_{\rho_{\max}}$ for all $t\geq 0$ and $z_1(t_h) \in \Omega_{\rho}$ for $t_h \ge \max \{\Delta, t_{z1} \}$ until a cyberattack is detected according to the implementation strategy in Section \ref{ImplementationStrategyDT23}, if the attack occurs after $t_{q}$.
\end{thm}

\begin{proof} 
	The output feedback LEMPC of Eq.~\ref{eq:p-LEMPCEqn1s} has the same form as in~\cite{oyama2020integrated}.  Therefore, in the absence of attacks or in the presence of sensor attacks only, we obtain the same results as in~\cite{oyama2020integrated}.  Specifically, feasibility follows when $z_1(t_k) \in \Omega_{\rho}$ as proven in~\cite{oyama2020integrated}.  Since $z_1(t_k) \notin \Omega_{\rho}$ flags an attack according to the implementation strategy of Section~\ref{ImplementationStrategyDT23}, there will not be a time before an attack is detected that $z_1(t_k) \notin \Omega_{\rho}$ before an attack, so that the problem would not be infeasible before an attack.  Also as demonstrated in~\cite{oyama2020integrated}, the closed-loop state trajectory is contained in $\Omega_{\rho_{\max}}$ for $t \in [t_0, \max \{\Delta, t_{z1}\})$, and before an attack occurs when $t \geq \max \{\Delta, t_{z1} \}$, $x(t)$ is bounded within $\Omega_{\rho_{\max}}$ and $z_1(t)$ is bounded within $\Omega_{\rho}$. Furthermore, it follows from Propositions~\ref{prop:OutputFdbkProp1} and \ref{prop:nubound} that the implementation strategy of Section~\ref{ImplementationStrategyDT23} will not detect measurement noise, controller cross-check error, or bounded plant/model mismatch as attacks, such that there will be no false detections.  It remains to demonstrate that if there is an attack at $t_k$ but it is not detected using the proposed methodology (i.e., $|z_i(t_k) - z_j(t_k)| \leq \epsilon_{\max}$, $|z_i(t_{k-1}) - z_j(t_{k-1})| \leq \epsilon_{\max}$, for all $i = 1,\ldots,M$, $j=1,\ldots,M$, $\tilde{x}(t_k) = z_{1}(t_k) \in \Omega_{\rho}$, and $|\tilde{x}(t_k|t_{k-1}) -z_1(t_k)| \leq \nu_u$), then $z_1(t_{k+1})$ and $x(t)$, $t\in[t_k,t_{k+1})$, are bounded in $\Omega_{\rho_{safe}}$.		
	
	If the control system is under only a sensor attack, but it is not detected, then under the conditions of Theorem~\ref{thm:ThmDS23}, the closed-loop state remains inside $\Omega_{\rho_{\max}} \subset \Omega_{\rho_{safe}}$ and the state estimate remains within $\Omega_{\rho_{safe}}$ under the implementation strategy of Section \ref{ImplementationStrategyDT23}, following~\cite{oyama2020integrated}. 
	
	If the control system is under only an actuator attack, then via the same steps as in the proof of Theorem~\ref{thm:DS1_Stability} for Case 4 - Part 2 with $\Omega_{\rho_1}$ replaced by $\Omega_{\rho}$, the attack will be detected before it drives the closed-loop state out of $\Omega_{\rho_{safe}}$.  The same proof demonstrates that when simultaneous sensor and actuator attacks occur, the closed-loop state will not be driven out of $\Omega_{\rho_{safe}}$ before an attack is detected.  Applying these proofs recursively indicates that under this implementation strategy, an attack is detected before the closed-loop state leaves $\Omega_{\rho_{safe}}$.
\end{proof} 
\begin{rmk}
	The proof for actuator-only attacks for Theorem~\ref{thm:ThmDS23} described above gives an indication of how the proof of closed-loop stability for actuator-only attacks on an LEMPC of the 2-A form would be carried out, but state measurements then might be used in place of state estimates, with the bound developed on the difference between the state estimate and state prediction updated to be between the measurement and prediction.
\end{rmk}

\section{Cyberattack Discoverability for Nonlinear Systems} \label{sec:discoverability}

The above sections reviewed a variety of cyberattack-handling mechanisms which rely on specific detection strategies designed in tandem with the controllers.  None of those strategies, in the manner discussed, detects every attack, but some ensure that safety is maintained when the attacks are not detected.  This raises the question of when detection mechanisms can detect attacks, and when they cannot.  This section is devoted to a discussion of these points.  In \cite{oyamahandling2021}, we first presented notions of cyberattack discoverability for nonlinear systems in a discussionary sense (i.e., a stealthy attack is fundamentally ``dynamics-based'' or a ``process-aware policy'' and could fly under the radar of any reasonable detection method; on the other hand, a ``non-stealthy'' attack can be viewed as the one in which the attack policy is not within the bounds of a detection threshold and could promptly be flagged as a cyberattack using a reasonable detection method).  In this section, we present mathematical characterizations of nonlinear systems cyberattack discoverability that allow us to cast the various attack detection and handling strategies explored in this work in a unified framework and to more deeply understand the principles by which they succeed or do not succeed in attack detection. 

We begin by developing a nonlinear systems definition of cyberattack discoverability as follows:
\begin{Definition} (\textit{Cyberattack Discoverability}): \label{defn:Discoverability} 
	Consider the state trajectories from $t\in[t_0,t_{1})$ that are the solutions of the systems: 
	\begin{equation} \label{eq:DiscoverabilityEq1}
	%\begin{align}
	\dot{x}_a(t) = f(x_a(t),u_a(x_0+v_a),w_a(t)) 
	%\dot{x}_{va}(t) = \hat{\nu}_v(u_b^(x_0+v_a))
	%\end{align}
	\end{equation}
	\begin{equation} \label{eq:DiscoverabilityEq2}
	%	\begin{align}
	\dot{x}_b(t) = f(x_b(t),u_b(x_0+v_b),w_b(t)) 
	%\dot{x}_{vb}(t) = \hat{\nu}_v(u_b^(x_0+v_b))
	%	\end{align}
	\end{equation}
	where $u_a(x_0+v_a)$ and $u_b(x_0+v_b)$ are the inputs to the process for $t\in[t_0,t_{1})$ computed from a controller when the controller receives a measurement $\tilde{x}_a(t_0) = x_0 + v_a$ (with $|v_a| \leq \theta_{v_a}$) or $\tilde{x}_b(t_0) = x_0 + v_b$ (with $|v_b| \leq \theta_{v_b}$), respectively.  If a reasonable detection method would be able to distinguish between the $x_a$ and $x_b$ trajectories, then the system is said to be \textit{cyberattack discoverable}.  Otherwise, it is said to be \textit{cyberattack undiscoverable}. %The inputs $g_{va}(\cdot)$ to the process are the outputs from the actuator based on the actuator position $x_{va}$ or $x_{vb}$.
\end{Definition}

This definition of cyberattack discoverability is related to whether multiple valid measurements or multiple valid inputs could be measured or could be possible from a given state at a certain time, obscuring whether what is presented to the detection algorithm is correct.  Cyberattacks can involve deliberate changes of the information that might make them observable.  Detecting a cyberattack purely from process physics data may be challenging because it requires developing ``expectations'' of what the process data should be, which should be derived either from experience or a model.  If data from which predictions are made or conclusions are drawn is falsified, it may be difficult to determine the appropriate expectation.   

We now present a number of comments on the methods discussed in this work, and how these methods can be understood in light of a broader discoverability context:
\begin{itemize}
	\item If there are sensor attacks only, the functions $u_a$ and $u_b$ in Definition~\ref{defn:Discoverability} may be the same, with the different arguments $x_0+v_a$ and $x_0+v_b$.  If an actuator only is attacked, $x_0+v_a$ and $x_0+v_b$ can be the same.
	\item The detection strategies presented in this work have implicitly relied on Definition~\ref{defn:Discoverability}.  They have attempted, when an attack would cause a safety issue, to force that attack to be discoverable, by making, for example, the state measurement under an expected control action $u_a(x_0+v_a)$ different from the state measurement under a rogue policy $u_b(x_0+v_b)$.  We have seen methods fail to detect attacks when they cannot force this difference to appear.  This fundamental perspective has the benefit of allowing us to better understand where the benefits and limitations of each of the methods arise from, which can guide future work by suggesting what aspects of strategies that fail would need to change to make them viable.  
	\item The definition presented in this section helps to clarify the question of what the fundamental nature of a cyberattack is, in particular a stealthy attack, that may distinguish it from disturbances. Specifically, consider a robust controller designed to ensure that any process disturbance within the bounds of what is allowed for the control system should maintain the closed-loop state inside a safe region of operation for all time if no attack is occurring. In other words, the plant-model mismatch is accounted for during the control design stage and does not cause feedback of the state to be lost. However, a stealthy attack is essentially a process-aware policy or an intelligent adversary that can modify the sensor measurements and/or actuator outputs through attack policies with a specific goal of making it impossible to distinguish between the actual and falsified data. The result of this is that stealthy attacks could fly under the radar of any reasonable detection mechanism and thus control actions applied to the process may not be stabilizing. 	We have previously examined an extreme case of an undiscoverable attack in~\cite{oyamahandling2021}, where the attack was performed on the state measurements of a continuous stirred tank reactor by generating measurements which followed the state trajectory that would be taken under a different realization of the process disturbances and measurement noise and providing these to the controller.  This would make the stealthy sensor attack, at every sampling time, appear valid to a detection strategy that is not generating false alarms.
	\item If a system is continuously monitored before and after an attack and the pair $\{w_b,v_b\}$ does not follow the same disturbance and noise distribution as the pair $\{w_a,v_a\}$ in Definition~\ref{defn:Discoverability}, a cyberattack could conceivably be flagged by a detection method that is able to discern that.  
	\item We note that although Definition \ref{defn:Discoverability} implies that if the attacker knows the process model, disturbance and noise distributions, they could implement an attack policy such that $x_a$ and $x_b$ trajectories cannot be distinguished (in the sense that one cannot be flagged as abnormal), cyberattack undiscoverability does not necessarily imply loss of closed-loop stability. Specifically, if the closed-loop state trajectory ($x_a$) and the false closed-loop state trajectory ($x_b$) are ``close enough'' such that a Lyapunov function decreases along the closed-loop state trajectory in both cases under the inputs computed for both, then the closed-loop state may still be maintained within a desired operating region under the attack.  This is implied by the fact that conservatively designed controllers can handle sufficiently small measurement noise (as, for example, in Detection Strategy 3-S described above).  As a further example, consider that an attacker seeks to develop a falsified state measurement trajectory using disturbances $w_2$ that are in the same distribution as those ($w_1$) impacting the actual process for a closed-loop system under an explicit control policy $h(x)$ with full state feedback:
	\begin{equation}
	\dot{x}_1(t) = f(x_1(t),h(x_2(t)),w_1(t)) \label{eq:ObserverAnalogy1}
	\end{equation} 
	\begin{equation}
	\dot{x}_2(t) = f(x_2(t),h(x_2(t)),w_2(t)) \label{eq:ObserverAnalogy2}
	\end{equation}
	Depending on the trajectories of $w_1$ and $w_2$ (i.e., how the attacker’s simulated noise/disturbance profile deviates from that which is experienced by the true process over time), the closed-loop system of Eqs.~\ref{eq:ObserverAnalogy1}-\ref{eq:ObserverAnalogy2} may maintain $x_1$ in a bounded operating region (i.e., it may be stabilizing for the actual process system) or it may not be. A nonlinear systems analysis (via, for example, Lyapunov stability theory for different potential functions of $w_1(t)$ and $w_2(t)$) could be used to evaluate what types of disturbance/noise realizations and corresponding falsified conditions would enable a ``dynamics-based'' attack with this structure to be destabilizing.  This is the same conclusion as was drawn in cases where one of the detection strategies described above was not effective at detecting an attack; many of the undetected attacks described did not prevent safety issues, which was the premise of the simultaneous actuator and sensor detection policies.	  
	\item Definition~\ref{defn:Discoverability} assumes that no change in the process dynamics occurs. If process dynamics change over time, the state trajectories, which are solutions of the system indicated in the cyberattack discoverability definition, may significantly differ from the state trajectories prior to this change.  If the detection scheme would then be set up to compare expectations under the old and new process models, the change in process dynamics may be erroneously flagged as a cyberattack. In \cite{rangan2021integrated}, for example, we provide a two-fold control/detection mechanism to prevent false attack detection when variations in the process dynamics are considered.
	\item Though methods for making cyberattacks discoverable might benefit from knowledge of the distribution of the noise and disturbances (to better distinguish Eqs.~\ref{eq:DiscoverabilityEq1} and \ref{eq:DiscoverabilityEq2}), the various detection strategies developed in this work make no consideration for statistics; they look only at bounds on disturbances and sensor measurements.  The only requirements made on the attacks are that the sensor measurement cyberattacks keep the state measurements in regions which do not flag the attacks (e.g., subsets of the stability region), and that the inputs remain in the input bounds (which must be true physically).  Strategies such as those described in Sections~\ref{sec:SimultaneousLEMPCImplementationStrategy} and~\ref{ImplementationStrategyDT23} were demonstrated to avoid false positive detections of attacks by using these bounds instead of distributional information for the noise and disturbances.   
\end{itemize}


\section{Probing the Practicality of LEMPC-Based Cyberattack-Resilient Control Design} \label{sec:exampleCombined}

The results above suggest that if controllers can be designed to satisfy the theoretical requirements discussed in the prior sections, there would be benefits to using them from a cybersecurity perspective.  However, an important question which arises from these studies is how easy it might be to design controllers satisfying the theoretical requirements (and if it would be practical at all), and what the answer to this question suggests about how future work in cyberattack-resilient LEMPC should continue.  In our prior work \cite{oyamahandling2021}, a number of simulations of a sensor measurement cyberattack-handling LEMPC which also can account for changes in the process dynamics were performed.  The results indicated that checking that the parameters of the control law and detection strategy (such as thresholds used in the detection policy or $\rho_e$) prevent cyberattacks from being successful can be challenging if it is performed using only a limited number of simulations.  This suggests that either a significant number of simulations may be needed to design cyberattack-resilient LEMPC's (which would be expected to be a challenging way to design these controllers due to the interactions between the various parameters, and also could still potentially leave system vulnerabilities if the simulations are not able to fully cover every possible issue), or a method for obtaining the parameters of the LEMPC's which meet the theory would be needed.

In this section, we seek to provide some initial insights into obtaining parameters for an LEMPC that meet the theory.  To make progress on this, we remove some of the complexity of the problem by focusing on how to obtain the theoretical parameters not of the more specialized LEMPC's for cyberattack-resilient control discussed in this work, but instead for the original LEMPC developed in~\cite{Heidarinejad2012855}.  This discussion is used to motivate future work in seeking to extend the initial results presented here on obtaining LEMPC parameters to more comprehensive methods for obtaining these parameters that could then be scaled to the cyberattack-resilient forms of LEMPC to eliminate the vulnerabilities.


\subsection{LEMPC: Meeting Theoretical Requirements in Control Design}

Before moving to a study working toward obtaining LEMPC parameters for a CSTR example, we first discuss a number of preliminaries regarding this topic.  First, since this section will focus on the standard LEMPC of Eqs.~\ref{eq:MPCEqn}-\ref{eq:LEMPCConstraints}, instead of its cyberattack-resilient form,  we consider Proposition~\ref{prop:VDifm} (where in the remainder of this section, we will neglect the subscript $i$ for simplicity of notation) and the following proposition and theorem.
\begin{prop} \label{prop:prop1}~\cite{mhaskar2012fault,Heidarinejad2012855}
	Consider the following two systems:
	\begin{subequations}\label{eq:prop11}
		\begin{align}
		& \dot{x}_{a}=f(x_{a}(t),u(t),w(t)) \label{eq:prop11:eq1}\\
		& \dot{x}_{b}=f(x_{b}(t),u(t),0) \label{eq:prop11:eq2}
		\end{align}
	\end{subequations}
	with initial states of $x_{a}(t_{0}) \in \Omega_{\rho}$ and $x_{b}(t_{0}) \in \Omega_{\rho}$.
	There exists a class $\mathcal{K}$ function $f_{W}(\cdot)$ that satisfies the following equations $\forall ~x_{a},x_{b} \in \Omega_{\rho}$ and $\forall~ w \in W$:
	\begin{subequations}\label{eq:prop12}
		\begin{align}
		& |x_{a}(t) - x_{b}(t)| \le \bar{f}_{W}(t-t_{0})  \label{eq:prop12:eq1}\\
		\text{where}~ & \bar{f}_{W}(\tau) := \frac{L_{w} \theta_w}{L_{x}} (e^{L_{x} \tau} -1) \label{eq:prop12:eq2}
		\end{align}
	\end{subequations}
\end{prop}
\begin{thm} \label{thm:thmLyap}~\cite{Heidarinejad2012855}
	Consider the system of Eq.~\ref{eq:ClassofSystems} in closed-loop under the LEMPC design of Eqs.~\ref{eq:MPCEqn}-\ref{eq:LEMPCConstraints} based on a controller $h(x)$ that satisfies the conditions of Eq.~\ref{eq:constraintsLyapunovA}. Let $\epsilon_w > 0$, $\Delta > 0$, and $\rho > \rho_e > \rho_{\min} > \rho_s > 0$ satisfy:
	\begin{equation}
	\rho_e' \leq \rho - f_V(\bar{f}_W(\Delta)) \label{eq:thm1:eq1}
	\end{equation}
	and
	\begin{equation}
	-\alpha_3(\alpha_2^{-1}(\rho_s)) + L_x' M_f \Delta + L_w' \theta_w \leq -\epsilon_w / \Delta \label{eq:thm1:eq2}
	\end{equation}
	where
	\begin{equation}
	f_V(s) = \alpha_4(\alpha_1^{-1}(\rho))s + M_v s^2 \label{eq:thm1:eq4}
	\end{equation}
	for $M_v$ as a positive constant.  If $x(t_0) \in \Omega_{\rho}$ and $N \geq 1$ where
	\begin{equation}
	\rho_{\min} = \max \{ V(x(t)) : V(x(t_k)) \leq \rho_s, ~t\in[t_k,t_{k+1}),~u(t_k) \in U \} \label{eq:thm1:eq5}
	\end{equation}
	then the state $x(t)$ of the closed-loop system is always bounded in $\Omega_{\rho}$ and is ultimately bounded in $\Omega_{\rho_{\min}}$. 
\end{thm}

The conditions of Theorem~\ref{thm:thmLyap} involve many functions and parameters which must relate to one another in a specific way.  Finding all of these functions and parameters has the potential to be somewhat cumbersome, particularly for larger systems.  For example, from Eq.~\ref{eq:thm1:eq2}, it can be seen that $\Delta$ cannot be too large (or else the left-hand side of Eq.~\ref{eq:thm1:eq2} will not be negative); however, what ``too large'' means is unclear.  One idea for attempting to satisfy the theory is to set up mechanisms for moving the parameters in desirable directions (e.g., smaller values of $\Delta$), hoping that that will be ``enough.''  One idea like this was explored in our prior work~\cite{durand2020enhancing}.  In that work, we focused specifically on the relationship between $\rho_e'$ and $\Delta$.  From Eq.~\ref{eq:thm1:eq1}, it can be seen that larger values of $\rho_e'$ require smaller values of $\Delta$; however, how large $\rho_e'$ can be for a given value of $\Delta$ is not obvious without obtaining all controller parameters to ensure that they meet the set of all equations in Theorem~\ref{thm:thmLyap}. As the sampling period approaches 0, the value of $\rho_e'$ might be able to be made larger while retaining stability guarantees. 

In practice, the value of $\Delta$ will always be nonzero and is generally limited to the computation time of the LEMPC.  However, we consider that there may be more frequent measurements from sensors than the frequency of the LEMPC computation. Therefore, in~\cite{durand2020enhancing}, we suggested attempting to utilize a desired $\rho_e'$ in the LEMPC, and then to use sensor measurements obtained multiple times throughout each $\Delta$ and activating a back-up explicit stabilizing controller capable of driving the closed-loop state towards the origin when the closed-loop state leaves $\Omega_{\rho_e'}$. Due to the increased frequency of measurements, the amount of time which may elapse between the time the closed-loop state leaves $\Omega_{\rho_e'}$ and the next sensor measurement which detects the departure is decreased, which may allow $\Omega_{\rho_e'}$ to take a wider range of values compared to the standard LEMPC formulation. However, despite that this is a possibility, this still does not rigorously address how to develop an LEMPC that meets the theoretical requirements, and therefore is not a method that would be expected to translate to cyberattack-resilient LEMPC design.

One of the first steps in designing an LEMPC design according to the theory is obtaining functions such as $V$ and $h$.  A variety of studies have been performed related to designing Lyapunov functions and stabilizing control laws.  For example, $h(x)$ could be designed with methods such as the linear quadratic regulator (LQR)~\cite{bemporad2002explicit,griffith2018advances} or Sontag's formula~\cite{lin1991universal} (the latter for input-affine process models). Methods have been explored for constructing Lyapunov functions such as sum of squares (SOS) decomposition~\cite{papachristodoulou2002construction}. For an LEMPC, it is not only functions such as $V$ and $h$ which must be found, but also other functions such as $\alpha_i$, $i=1,2,3,4$, such that all conditions of Theorem~\ref{thm:thmLyap} are satisfied.

However, to design a ``good'' LEMPC meeting Theorem~\ref{thm:thmLyap}, we would like to find parameters such as $h$ and $V$ that have special properties; in particular, we would like them to cause the LEMPC to: 1) have parameters such as $\Delta$ that allow it to be physically implemented on existing systems; and 2) provide significant profit (the most possible with physically-implementable versions of the parameters).  In the study in the next section, we will start with an assumed $h$, $V$, and $\rho$, and then see what values parameters such as $\Delta$ would take, to see if they are physically realizable.  This will provide insight into some potential challenges of practically designing an LEMPC where the theory is met.

\begin{rmk} \label{rmk:ImptRmk}
	As a comment on the last paragraph above, we remark that the requirements noted form a sort of optimization problem for $h$ and $V$.  To gain insight into the task, we could ask whether it would be possible to form the set of every possible $h$ (Lipschitz continuous functions) and $V$ (positive definite functions) and then to search within this set for $h$ and $V$ combinations that not only satisfy fundamental objectives of these functions (such as satisfaction of Eqs.~\ref{eq:constraintsLyapunov1}-\ref{eq:constraintsLyapunov2}) but which also enable the resulting $h$ and $V$ to cause all other parameters of the LEMPC to satisfy the two objectives of the LEMPC in the prior paragraph.  We might begin by considering suggesting forms of $h$ and $V$ and then finding their form via optimization based on techniques in~\cite{brunton2016discovering}. Specifically, \cite{brunton2016discovering} develops potential dynamic models by guessing terms which may appear on the right-hand side and then attempting to use a sparse regression to locate which of those should be used to represent the process dynamics. This begs the question of whether a form for $h$ might be guessed, and then an optimization problem solved in which the coefficients of the terms of the form of $h$ are the decision variables and the constraints enforce $\dot{V}$ to be negative at many points in a discretization of the state-space, to determine a form of $h$ systematically.  Because this relates $h$ and $V$ to an optimization problem, a method like this might have flexibility to then be combined with other strategies for optimizing the $h$ and $V$ choice to attempt to achieve the goals in the paragraph above.  However, even for this preliminary optimization problem concept that does not explicitly account for those alternative goals, without careful structuring, the resulting optimization problem is not guaranteed to be feasible. We can analyze this from a fundamental control-theoretic perspective. First, we note that for a given discretization of the state-space, there does not necessarily exist any input policy that, at all points in the state-space, can drive the closed-loop state to the origin (this only occurs within the region of attraction). Second, even if the discretization of the state-space being examined only includes the region of attraction, the input trajectory that could drive the closed-loop state to the origin from a given initial condition in that portion of the state-space does not necessarily stay within that discretized region or cause a given $V$ to decrease (i.e., the region of attraction is independent from $V$). Therefore, guessing a form of $h$ to search for a control design which might make $\dot{V}$ negative via optimization of its terms (with the subsequent goal of modifying the problem to account for other goals we would like to achieve with these functions) may have limitations. Even if it was possible to suggest a form of $h$ which could approximate many functions, for each $V$, there is an upper bound on it where the level set is in the region of attraction (it is not possible to consider beyond that $\rho$).  The question asked is which $h$ and $V$ combination with an upper bound on $V$ below the threshold for that $V$ gives the maximum EMPC profit and implementable parameters.  This could be explored in a brute force fashion by looking at every possible value of $V$, for each finding the maximum value of $\rho$, testing it for every possible value of $h$, obtaining the resulting control parameters, and seeing the best profit among those with reasonable control parameters, and selecting the one with the best profit.  The challenge with doing this is the need to test every point and every function (and then also there is no guarantee that practically implementable parameters will be obtained).  If there is a finite set of $h$'s, it is not guaranteed that there is one that is stabilizing in that set.  The guarantee is that there is some trajectory $u$ that is stabilizing in the region of attraction, but whether that includes the ones that are allowed once the function is parametrized is not guaranteed.  This discussion indicates that considering how to obtain optimal and practical designs of LEMPC's will require many questions to be addressed beyond what is presented in the subsequent section as a preliminary step in moving toward developing LEMPC's with parameters related to the full control theory.
\end{rmk} 

\subsubsection{Obtaining Control-Theoretic Parameters for LEMPC Applied to a CSTR}

In is section, we provide a brute force-type method for exploring the parameters of an LEMPC which might be more aligned with the theory than assumed values.  The brute force-type approach does not ensure that all of the parameters meet the theory, but it provides many insights into shortcomings of this initial approach for attempting to obtain the parameters to motivate further studies on this topic, and potential challenges with parameters that might be obtained.

We consider the nonlinear process model of Eqs.~\ref{eq:ExampleSystem:Ca}-\ref{eq:ExampleSystem:T}. The manipulated inputs are $C_{A0}$ (the reactant feed concentration of species $A$) and $Q$ (the heat rate input), with bounds of $0.5 \le C_{A0} \le 7.5 ~kmol/m^3$ and $ -5.0 \times 10^5 \le Q \le 5.0 \times 10^5 ~kJ/hr$.  The values of the parameters of the CSTR model are presented in Table~\ref{tbl:CSTRParameters}.  An open-loop asymptotically stable steady-state occurs at $C_{As}=1.2 ~kmol/m^3$ and $T_s= 438.2 ~K$, where the subscript $s$ indicates the steady-state values. In the control formulation, the state and input vectors are represented using deviation variables as $x^T = [C_A-C_{As}~~~T-T_s] $ and $u^T =[C_{A0}-C_{A0s}~~~Q-Q_s] $, respectively. 

%below which consists of a continuous stirred tank reactor (CSTR) with a second-order, exothermic, irreversible reaction of the form $A \to B$ with the following dynamics:
%\begin{equation}
%\dot C_A = \frac{F}{V} (C_{A0}-C_A) -k_0 e^{-\frac{E}{R_gT}} C_A^2 \label{eq:ExampleSystem:Ca}
%\end{equation}
%\begin{equation}
%\dot T = \frac{F}{V} (T_{0}-T) -\frac{\Delta H k_0}{\rho_{L} C_p} e^{-\frac{E}{R_gT}}C_A^2 + \frac{Q}{\rho_{L} C_p V} \label{eq:ExampleSystem:T}
%\end{equation}
%where the states are the reactant concentration of species $A$ ($C_A$) and temperature in the reactor ($T$).  


\begin{table}[h]
	\caption{Parameters for the CSTR model.}\label{tbl:CSTRParameters}
	\begin{center}
		\begin{tabular}{ccc}
			\textbf{Parameter} & \textbf{Value} & \textbf{Unit} \\ \hline
			$V$ & 1 & m$^3$ \\ \hline
			$T_0$ & 300 & K \\ \hline
			$C_p$ & $0.231$ & kJ/kg$\cdot$K \\ \hline
			$k_0$ & $8.46\times 10^6$ & m$^3$/h$\cdot$kmol \\ \hline
			$F$ & $5$ & m$^3$/h \\ \hline
			$\rho_L$ & $1000$ & kg/m$^3$ \\ \hline
			$E$ & $5 \times 10^4$ & kJ/kmol \\ \hline
			$R$ & $8.314$ & kJ/kmol$\cdot$K \\  \hline
			$\Delta H$ & $-1.15 \times 10^4$ & kJ/kmol \\ \hline
		\end{tabular}
	\end{center}
\end{table}

According to Theorem~\ref{thm:thmLyap}, the first step in finding control-theoretic parameters for LEMPC is to find a controller $h(x)$ satisfying Eq.~\ref{eq:constraintsLyapunovA} so that $\Omega_{\rho}$, $V$, and $h$ in the LEMPC of Eq.~\ref{eq:MPCEqn}-\ref{eq:LEMPCConstraints} can be defined.  In general it may be challenging to find the functions $\alpha_1$, $\alpha_2$, $\alpha_3$, $\alpha_4$, and $h(x)$ satisfying the requirements of Eq.~\ref{eq:constraintsLyapunovA}.  The input-affine form of Eqs.~\ref{eq:ExampleSystem:Ca}-\ref{eq:ExampleSystem:T} allows Sontag's formula~\cite{lin1991universal} to be used for $h(x)$ (assuming $\hat{h}_1 = u_1 = 0$ kmol/m$^3$ and that Sontag's formula is then used only for $\hat{h}_2$) with a guaranteed decrease on $V(x)$, and an attempt to use a quadratic form of $V$ as $x^T P x$ with a positive definite $P$ makes it possible to find some $\alpha_1$ and $\alpha_2$ satisfying Eq.~\ref{eq:constraintsLyapunov1} (if that selection of $V$ turns out to be successful; notably, however, the fact that these functions satisfy some of the equations does not mean that they will make it possible or straightforward to satisfy the others).  The manner in which we proceed here is as follows: initially, we select a quadratic form of $V$ with $P = [2000 ~ -10;~ -10~ 3]$.  For a symmetric $P$, $\lambda_{\min}(P) x^T x \leq x^T P x \leq \lambda_{\max}(P) x^T x$, where $\lambda_{\min}(P)$ and $\lambda_{\max}(P)$ represent the minimum and maximum eigenvalues of $P$, respectively.  This indicates that for a symmetric $P$ utilized for $V = x^T P x$, $\alpha_1(|x|)$ can be set to $\lambda_{\min}(P)|x|^2$, and $\alpha_2(|x|)$ can be set to $\lambda_{\max}(P)|x|^2$.  For the given $P$, $\lambda_{\min}(P)$ and $\lambda_{\max}(P)$ can be found using MATLAB's eig function to be 2.95 and 2000.05, respectively.  From this, we will set $a_1 = 2.9$ and $a_2 = 2001$, where $\alpha_1(|x|) = a_1 |x|^2$ and $\alpha_2(|x|) = a_2 |x|^2$.

%https://see.stanford.edu/materials/lsoeldsee263/15-symm.pdf

The next function which we would like to obtain is $\alpha_3$.  According to Eq.~\ref{eq:constraintsLyapunov2}, $\alpha_3(|x|)$ should be a class $\mathcal{K}$ function that provides an upper bound to $\dot{V}$ along the closed-loop state trajectories at all points in the stability region.  While it would be ideal in general to find such a function analytically, we perform an approximate check numerically here using $\hat{h}_1(x) = 0$ kmol/m$^3$ and $\hat{h}_2(x)$ given by Sontag's formula~\cite{lin1991universal}.  Notably, as soon as simulations are introduced to check that theoretical conditions are true, the potential for vulnerabilities in the design (in the sense that the safety results may not hold) opens up.  The more points that are checked within the stability region to ensure that the chosen $\alpha_3$ satisfies Eq.~\ref{eq:constraintsLyapunov2} within that region, the greater the expectation one might have that it does everywhere (though an expectation is not a proof), but simulations are not as rigorous of a check as an analytic check.  However, it may not always be possible to perform the checks analytically.  Still, this is a part of the methodology that will need further improvements for designing safe systems under LEMPC and ultimately building to cyberattack-resilient LEMPC design.

The first thing that we will check is that $\dot{V}$ is negative throughout the stability region that we plan to use, so that we have reason  to check if there is a negative definite upper bounding function on $\dot{V}$ as required by Eq.~\ref{eq:constraintsLyapunov2}.  Specifically, initially, a check was made that $\dot{V}$ was negative throughout $\Omega_{\rho}$ under the proposed $h(x)$ (saturated at the input bounds) for $\rho = 1800$, by discretizing the state-space in increments of 0.01 kmol/m$^3$ in $C_A$ from 0 kmol/m$^3$ to 4 kmol/m$^3$, and in increments of 1 K in $T$ from 340 K to 560 K.  Since $\dot{V}$ was negative at the points tested, we suggest the function $\alpha_3(|x|) = a_3 |x|^2$, with $a_3$ originally set to 100, and then throughout the stability region, check whether $\dot{V}$ is less than the negative of this function.  If it is not (implying that $a_3$ is too large), $a_3$ is changed to be equal to $-\dot{V}/|x|^2$ at the point where $\dot{V}$ was not less than or equal to $-\alpha_3(|x|)$.  This results in $a_3 = 0.00822$; setting $a_3 = 0.008$ ensures that the inequality in Eq.~\ref{eq:constraintsLyapunov2} is satisfied at the points tested for this choice of $\alpha_3(|x|)$.  Notably, $a_3$ is rounded down to obtain a suitable parameter, whereas other parameters discussed below will be rounded up from the values returned by MATLAB, because $a_3$ appears in a term that reflects a worst case when it is smaller, whereas the others appear in terms that reflect worst cases when they are larger.

The next function to be obtained is $\alpha_4(|x|)$.  We again here guess a form for $\alpha_4(|x|)$ and then check whether Eq.~\ref{eq:constraintsLyapunov3} is satisfied at the points in the discretized stability region.  Specifically, assuming that $\alpha_4(|x|) = a_4|x|^2$, we set $a_4$ initially to -100 and then update it to be $\left|\frac{\partial V}{\partial x}\right|/|x|^2$ whenever $\left|\frac{\partial V}{\partial x}\right| > \alpha_4(|x|)$.  This gives that $a_4 = 8156.72$ would work throughout the stability region with $\rho = 1800$.  We will choose $a_4 = 8160$.

Next, the value of $M_f$ is determined to satisfy Eq.~\ref{eq:FBound}.  In this case, it is necessary not only to discretize the state-space within the stability region, but also the input space and disturbance space.  Furthermore, the upper bound on the magnitude of the disturbances will play a role in determining not only $M_f$, but also in determining whether the conditions of Propositions~\ref{prop:VDifm} and \ref{prop:prop1} and Theorem~\ref{thm:thmLyap} are satisfied for the controller parameters.  Again, the larger the value of $\rho$, the larger the value of $M_f$.  To obtain $M_f$ in this simulation, the state-space was discretized in the manner described above, and in addition the range of $C_{A0}$ was discretized in units of 0.5 kmol/m$^3$, while the range of $Q$ was discretized in units of $10^5$ kJ/h.  Furthermore, the disturbances used for this process had disturbance bounds of 2 kmol/m$^3$ h and 5 K/h for disturbances added to the right-hand sides of Eqs.~\ref{eq:ExampleSystem:Ca} and \ref{eq:ExampleSystem:T}, respectively.  The disturbance space was therefore considered to go from -2 to 2 kmol/m$^3$ h in units of 0.1 kmol/m$^3$ h for the disturbances added to the right-hand side of Eq.~\ref{eq:ExampleSystem:Ca} in deviation form, and from -5 to 5 K/h in increments of 0.5 K/h for the disturbances added to the right-hand side of Eq.~\ref{eq:ExampleSystem:T} in deviation form.  $M_f$ was originally set to 0, but then changed to $|f(x,u,w)|$ at any of the discretized points where $|f(x,u,w)|$ was greater than the stored value of $M_f$.  This results in a value of $M_f$ within the stability region $\rho = 1800$ of 4465.75.  The selected value for this simulation is 4466.

$L_x$ and $L_w$ are Lipschitz constants for $f$, as shown in Eq.~\ref{eq:Lipschitz1}.  To obtain these, first, $L_x$ and $L_w$ are obtained on their own by discretizing the state, input, and disturbance spaces, and finding values that work when only the state is changed (for $L_x$) or when only the disturbances are changed (for $L_w$).  Subsequently, it is checked that the resulting $L_x$ and $L_w$ satisfy Eq.~\ref{eq:Lipschitz1} for points in the discretized state-space.  However, using the brute force method in this paper of checking many points (an aspect of this strategy that would scale poorly and therefore pose limitations for larger processes), the computation time can become many hours if the same discretization is used as was used above.  Therefore, to obtain values for $L_x$ and $L_w$ more quickly, the discretization was made coarser; however, it should be understood that this also means that these parameter values (like the others above with other discretizations) are not necessarily the values that would be obtained with a finer discretization, and therefore still leave the potential for safety vulnerabilities if the controller parameters are designed with these imperfect values of $L_x$ and $L_w$.  This provides insight into the challenges also of using strategies like this for safety-critical design of controllers, such as for the cyberattack-resilience extension.

Using a discretization of the input range of 1 kmol/m$^3$ in $C_{A0}$, of $10^5$ kJ/h in $Q$, of 0.1 kmol/m$^3$ in $C_A$, of 1 K in $T$, of 1 kmol/m$^3$ h for the disturbance added to the right-hand side of Eq.~\ref{eq:ExampleSystem:Ca} in deviation form and of 1 K/h for the disturbance added to the right-hand side of Eq.~\ref{eq:ExampleSystem:T} in deviation form, and then only looking at points in the stability region, the value of $L_x$ was initialized at -1 and then re-set to $|f(x,u,w) - f(x',u,w)|/|x - x'|$ whenever $|f(x,u,w) - f(x',u,w)| > L_x |x - x'|$ among the points checked.  This resulted in a value of $L_x = 3008.66$ being selected.  A similar procedure for $L_w$ gave $L_w = 1.00$.  Then, a code that checks that Eq.~\ref{eq:Lipschitz1} is satisfied at the points in the discretization with $L_x = 3009$ and $L_w = 1.1$ was utilized, and the points in the discretization satisfied it.

Subsequently, it is necessary to calculate $L_x'$ and $L_w'$.  Using a similar strategy to that used in computing $L_x$ and $L_w$, with the same discretization of the state, input, and disturbance spaces and only looking at points within the stability region, and setting the initial value of $L_x'$ to -1 but updating it to $|\frac{\partial V(x)}{\partial x} f(x,u,w) - \frac{\partial V(x')}{\partial x} f(x',u,w)|/|x - x'|$ whenever $|\frac{\partial V(x)}{\partial x} f(x,u,w) - \frac{\partial V(x')}{\partial x} f(x',u,w)| > L_x' |x - x'|$ among the points checked, the value $L_x' = 439218.83$ results.  Following a similar procedure for $L_w'$, the value $L_w' = 3747.27$ results.  Subsequently, it is checked that Eq.~\ref{eq:Lipschitz2} is satisfied at the points checked with $L_x' = 439220$ and $L_w' = 3750$.

The final parameter to obtain is $M_v$ in Eq.~\ref{eq:prop21:eq2}.  This is obtained in a similar spirit to the methods above.  Specifically, the range of $C_A$ is discretized in units of 0.01 kmol/m$^3$, while the range of $T$ is discretized in units of 1 K.  $M_v$ was originally set to 0.  Points in this discretization in the stability region are examined.  Subsequently, $M_v$ is set to $(V(x) - V(\hat{x}) - \frac{a_4 \rho}{\lambda_{\min}} |x - \hat{x}|)/(|x - \hat{x}|^2)$ if $(V(x) - V(\hat{x}) )> \frac{a_4 \rho}{\lambda_{\min}} |x - \hat{x}| + M_v (|x - \hat{x}|^2)$.  The value of $M_v$ after this algorithm was run was still 0.  Therefore, $M_v$ was set to $10^{-5}$.

The set of parameters obtained via these methods that is used in the first simulation is shown in Table~\ref{tbl:Example1}.  We note that many of these parameters were obtained within a given $\Omega_{\rho}$, where if that region shrinks, it is possible that some values may change.  To select values of $\rho_e'$, $\Delta$, $\rho_s$, $\epsilon_w$, and $\rho_{\min}$ which satisfy the conditions of Propositions~\ref{prop:VDifm} and \ref{prop:prop1} and Theorem~\ref{thm:thmLyap}, we consider formulating the following optimization problem:
\begin{subequations} \label{eq:LEMPCChoosing}
	\begin{align}
	\max_{\rho_e', \Delta, \rho_s, \bar{\epsilon}_w, \rho_{\min}}\hspace{3mm} & \rho_e' \label{eq:LEMPCChoosing:Obj}  \\
	\text{s.t.}\hspace{5mm} & \rho_e' - \rho + f_V(\bar{f}_W(\Delta)) \leq 0 \label{eq:LEMPCChoosing:Mode1} \\
	& -\alpha_3(\alpha_2^{-1}(\rho_s)) + L_x' M_f \Delta + L_w' \theta_w + \bar{\epsilon}_w \leq 0 \label{eq:LEMPCChoosing:Mode2} \\
	& \rho_s + L_x' M_f \Delta^2 + L_w' \theta_w \Delta - \rho_{\min} \leq 0 \label{eq:LEMPCChoosing:rhos} \\
	& \rho_{\min} -\rho_e' + 0.00001 \leq 0 \label{eq:LEMPCChoosing:rhomin} \\
	& 0 \leq \rho_e' \leq \rho \label{eq:LEMPCChoosing:rhoeBound} \\
	& 0 \leq \Delta \leq 5 \label{eq:LEMPCChoosing:DeltaBound} \\
	& 0 \leq \rho_s \leq \rho \label{eq:LEMPCChoosing:rhosBound} \\
	& 10^{-5} \leq \bar{\epsilon}_w \leq 10^{17} \label{eq:LEMPCChoosing:epsilonwBound} \\
	& 0 \leq \rho_{\min} \leq \rho \label{eq:LEMPCChoosing:rhominBound}
	\end{align}
\end{subequations}
In Eq.~\ref{eq:LEMPCChoosing}, $\bar{\epsilon}_w$ represents $\epsilon_w/\Delta$, so that the value of $\epsilon_w$ can be obtained from $\bar{\epsilon}_w \Delta$ after Eq.~\ref{eq:LEMPCChoosing} is solved.  The objective function of Eq.~\ref{eq:LEMPCChoosing} was selected as $\rho_e'$ to attempt to maximize the size of the region in which process economics is optimized under the constraint of Eq.~\ref{eq:LEMPCEqnconstraints:1}.  Eq.~\ref{eq:LEMPCChoosing:Mode1} was implemented as $\rho_e' - \rho + \frac{a_4 \rho}{a_1} \left[ \frac{L_w \theta_w}{L_x}(e^{L_x \Delta} - 1) \right] + M_v \left[ \frac{L_w \theta_w}{L_x}(e^{L_x \Delta} - 1) \right]^2 \leq 0$, and Eq.~\ref{eq:LEMPCChoosing:Mode2} was implemented as $-a_3 \frac{\rho_s}{a_2} + L_x' M_f \Delta + L_w' \theta_w + \bar{\epsilon}_w \leq 0$, in accordance with Eqs.~\ref{eq:prop12:eq2}, \ref{eq:prop21:eq2}, \ref{eq:thm1:eq1}, and \ref{eq:thm1:eq2}.  Eq.~\ref{eq:LEMPCChoosing:rhos} was developed due to the fact that the closed-loop state may enter $\Omega_{\rho_s}$ under operation of the LEMPC of Eqs.~\ref{eq:MPCEqn}-\ref{eq:LEMPCConstraints} with the constraint of Eq.~\ref{eq:LEMPCEqnconstraints:2} activated, where then:
\begin{equation}
\begin{aligned}
\dot{V}(x(t)) & \leq -\alpha_3(|x(t_k)|) + \frac{\partial V(x(\tau))}{\partial x} f(x(\tau),u(t_k),w(\tau)) - \frac{\partial V(x(t_k))}{\partial x} f(x(t_k),u(t_k),0) \label{eq:Vdotinrhos}
\end{aligned}
\end{equation}
for $t \in [t_k,t_{k+1})$, according to Eq. 18 in~\cite{Heidarinejad2012855}.  In a worst case, $-\alpha_3(|x(t_k)|)$ is close to zero near the origin, so that it can be neglected.  From the requirement of Eq.~\ref{eq:thm1:eq5}, $V(x(t_k)) + \dot{V} \Delta \leq \rho_{\min}$ when $x(t_k) \in \Omega_{\rho_s}$.  Substituting $\rho_s$ and $\dot{V}$ from Eq.~\ref{eq:Vdotinrhos} gives Eq.~\ref{eq:LEMPCChoosing:rhos}.  Eq.~\ref{eq:LEMPCChoosing:rhomin} comes from the requirement that $\Omega_{\rho_{\min}} \subset \Omega_{\rho_e'}$.  The bounds on the decision variables were set based on expectations of the values of the parameters and theoretical requirements.  For example, because $\Omega_{\rho_{\min}} \subset \Omega_{\rho_e'} \subset \Omega_{\rho}$ and $\rho_{\min} > 0$, $\rho_e' > 0$, and $\rho > 0$ Eqs.~\ref{eq:LEMPCChoosing:rhoeBound}, \ref{eq:LEMPCChoosing:rhosBound} and \ref{eq:LEMPCChoosing:rhominBound} were set (if the parameters $\rho_e'$, $\rho_s$, or $\rho_{\min}$ were to equal zero in the result of Eq.~\ref{eq:LEMPCChoosing}, then our conclusion would be that the algorithm did not work properly).  $\Delta$ should be positive (leading to the lower bound of 0 in Eq.~\ref{eq:LEMPCChoosing:DeltaBound}, where again if $\Delta = 0$, it would be considered that the result is problematic), and we expected it to be relatively small given the conditions of Propositions~\ref{prop:VDifm} and \ref{prop:prop1} and Theorem~\ref{thm:thmLyap}, so that an upper bound on $\Delta$ of 5 was selected in Eq.~\ref{eq:LEMPCChoosing:DeltaBound}, but this could be adjusted to be higher if desired.  Finally, due to a lack of knowledge of what value $\bar{\epsilon}_w$ should take besides that it should be positive, a large upper bound was provided to this parameter in Eq.~\ref{eq:LEMPCChoosing:epsilonwBound}, with a lower bound enforcing that the parameter be positive.  The lower bound of $10^{-5}$ was selected to prevent the parameter from decreasing all the way to zero, as it should be positive, but this lower bound could be adjusted.  This optimization problem was solved in MATLAB using fmincon.  From the initial guess $\rho_e' = 1$, $\Delta = 10^{-12}$, $\rho_s = 1$, $\bar{\epsilon}_w = 1$, and $\rho_{\min} = 1$, fmincon returned that the solution had converged to an infeasible point.  To better understand the reason for the infeasibility and how to overcome it, the constraints can be analyzed one-by-one with the parameters shown in Table~\ref{tbl:Example1}.  Several of the constraints are shown in Table~\ref{tbl:Example2}. 

\begin{table}[h]
	\caption{First set of parameters for CSTR model.}\label{tbl:Example1}
	\begin{center}
		\begin{tabular}{cc}
			\textbf{Parameter} & \textbf{Value} \\ \hline
			$\rho$ & 1800  \\ \hline
			$a_1$ & 2.9 \\ \hline
			$a_2$ & 2001 \\ \hline
			$a_3$ & 0.008 \\ \hline
			$a_4$ & 8160 \\ \hline
			$M_f$ &  4466 \\ \hline
			$L_x$ & 3009 \\ \hline
			$L_w$ & 1.1 \\ \hline
			$L_x'$ & 439220 \\ \hline
			$L_w'$ & 3750 \\ \hline
			$M_v$ & $10^{-5}$ \\ \hline
			$\theta_w$ & $\sqrt{29}$ \\ \hline
		\end{tabular}
	\end{center}
\end{table}



\begin{table}[h]
	\caption{Constraints of Eq.~\ref{eq:LEMPCChoosing} using the parameters of Table~\ref{tbl:Example1}.}\label{tbl:Example2}
	\begin{center}
		\begin{tabular}{cc}
			\textbf{Equation Number} & \textbf{Equation Form} \\ \hline
			Eq.~\ref{eq:LEMPCChoosing:Mode1} &  $\rho_e' -11770.90 + 9970.90e^{3009 \Delta} + 3.88 \times 10^{-11}e^{6018\Delta} \leq 0$ \\ \hline
			Eq.~\ref{eq:LEMPCChoosing:Mode2} &  $-4.00 \times 10^{-6} \rho_s + 1961556520 \Delta + 20194.37 + \bar{\epsilon}_w \leq 0$ \\ \hline
			Eq.~\ref{eq:LEMPCChoosing:rhos} &  $\rho_s + 1961556520 \Delta^2 + 20194.37 \Delta - \rho_{\min} \leq 0$ \\ \hline
			Eq.~\ref{eq:LEMPCChoosing:rhomin} & $\rho_{\min} - \rho_e' + 0.00001 \leq 0$ \\ \hline
		\end{tabular}
	\end{center}
\end{table}

Our first task is to analyze what values of the decision variables might satisfy these constraints, particularly those of interest in applying LEMPC (e.g., larger sampling periods and values of $\rho_e'$).  Considering first Eq.~\ref{eq:LEMPCChoosing:Mode1} in Table~\ref{tbl:Example2}, we note that the value of $\Delta$ would need to be small due to the exponential terms in which $\Delta$ appears (for example, $\Delta$ of $10^{-5}$ h would enable Eq.~\ref{eq:LEMPCChoosing:Mode1} to be satisfied with $\rho_e'$ at an example value in its allowable range (from Eq.~\ref{eq:LEMPCChoosing:rhoeBound}) of 1000).  However, moving to Eq.~\ref{eq:LEMPCChoosing:Mode2} in Table~\ref{tbl:Example2}, we see that problems arise.  First, we note that even if $\bar{\epsilon}_w$ takes its smallest value according to Eq.~\ref{eq:LEMPCChoosing:epsilonwBound}, if $\Delta = 10^{-5}$ h, then $\rho_s$ would need to be at least $9,957,459,550$, which is not less than $\rho$ and therefore is not allowable.  However, even if $\Delta$ was 0 (which is asymptotically the smallest value it could reach) and $\bar{\epsilon}_w$ was $10^{-5}$, the term containing the noise bound $\theta_w$ would still cause the requirement on $\rho_s$ to be that it be at least $5,051,116,305$,  which again is much larger than $\rho$ and therefore not allowable.  This provides an indication that for the parameters of the LEMPC to provide guarantees for the selected values of $\rho$, $V$, $h$, $\alpha_1(\cdot)$, $\alpha_2(\cdot)$, $\alpha_3(\cdot)$, and $\alpha_4(\cdot)$, the value of $\theta_w$ needs to be small.  In the following discussion, we will consider that it is 0 (no disturbances/plant-model mismatch).

If $\theta_w = 0$, then values of $\rho_e' = 1799$, $\rho_{\min} = 11$, $\rho_s = 10$, $\Delta = 10^{-15}$ h, and $\bar{\epsilon}_w = 10^{-5}$ satisfy the requirements of Eqs.~\ref{eq:LEMPCChoosing:Mode1}-\ref{eq:LEMPCChoosing:rhominBound}.  However, this small sampling period would likely pose significant implementation challenges, particularly due to the need to execute an optimization problem every $10^{-15}$ h, and then also could be challenging to simulate with these parameters (e.g., it could take a long time to simulate any substantial time length if $10^{-15}$ h was explicitly used as the time period).  The problem with the sampling period size in this case is not only due to $\rho_s$ being small; even if $\rho_s$ was set to its maximum possible value of $\rho = 1800$ from Eq.~\ref{eq:LEMPCChoosing:rhosBound} in this case, $\bar{\epsilon}_w$ was set to its minimum value, and $\theta_w$ was set to 0, then Eq.~\ref{eq:LEMPCChoosing:Mode2} still indicates that $\Delta$ would need to be no more than $3.66 \times 10^{-12}$ h.  This motivates the question of what might happen to $\Delta$ if $\rho$ was made smaller to affect some of the parameters in Table~\ref{tbl:Example1}.

To investigate this, we can redo the procedure above for a different value of $\rho$ that is smaller, to analyze the effects on the parameters of Table~\ref{tbl:Example1}, and also on the feasible space of Eq.~\ref{eq:LEMPCChoosing}.  Selecting $\rho = 200$ (i.e., $\rho$ is about an order of magnitude smaller than above) and neglecting disturbances, we note that $a_1$ and $a_2$ are fixed by $P$ for the selected form of $V$, $\alpha_1(\cdot)$, and $\alpha_2(\cdot)$, so that if these are still ``large'' in the resulting problem, $V$, $\alpha_1(\cdot)$, or $\alpha_2(\cdot)$ would need to change to make an impact on these.  Though $\rho$ is smaller here, we do not update the discretization of the stability region used, as the values that are obtained from the above procedure provide a best case (i.e., additional points in the stability region can only make $a_3$ smaller, making it harder to find a larger $\Delta$ meeting Eq.~\ref{eq:LEMPCChoosing:Mode2}, and cannot make $a_4$, $M_f$, $L_x$, $L_w$, $L_x'$, $L_w'$, and $M_v$ smaller, which can also make it harder to find a larger $\Delta$ meeting Eq.~\ref{eq:LEMPCChoosing:Mode2}.  Therefore, we attempt to obtain a sense of whether changing the size of $\rho$ allows $\Delta$ to be significantly larger than in the case with $\rho = 1800$ with the coarser discretization.

The new parameters from the above procedure with $\rho = 200$ are shown in Table~\ref{tbl:Example3}.  With these updated parameters, Eq.~\ref{eq:LEMPCChoosing} gives a solution this time, specifically the solution in Table~\ref{tbl:Example4}.  The value of $\rho_e'$ is maximized by driving it to its upper bound (since $\rho_e'$ should be less than $\rho$, a constraint could be added in future versions of this problem with a form similar to that in Eq.~\ref{eq:LEMPCChoosing:rhomin} but replacing $\rho_{\min}$ with $\rho_e'$ and $\rho_e$ with $\rho$, to enforce that $\Omega_{\rho_{e}'}$ is a strict subset of $\Omega_{\rho}$).  The value of $\Delta$ in Table~\ref{tbl:Example4} is still incredibly small for process simulation.  To check whether this is a fundamental limit of the parameters in Table~\ref{tbl:Example3} or a function of the maximization of $\rho_e'$ in Eq.~\ref{eq:LEMPCChoosing}, we can perform an analysis of the maximum possible value of $\Delta$ in Eq.~\ref{eq:LEMPCChoosing:Mode2}.  For the parameters in Table~\ref{tbl:Example3}, if $\rho_s$ was its maximum possible value of $\rho = 200$ in Eq.~\ref{eq:LEMPCChoosing:Mode2} and $\bar{\epsilon}_w$ was its minimum possible value of $10^{-5}$, then $\Delta$ in this equation would still need to be no larger than $2.245 \times 10^{-10}$ h (again a very small number).

\begin{table}[h]
	\caption{Second set of parameters for CSTR model.}\label{tbl:Example3}
	\begin{center}
		\begin{tabular}{cc}
			\textbf{Parameter} & \textbf{Value} \\ \hline
			$\rho$ & 200  \\ \hline
			$a_1$ & 2.9 \\ \hline
			$a_2$ & 2001 \\ \hline
			$a_3$ & 1.14 \\ \hline
			$a_4$ & 8160 \\ \hline
			$M_f$ &  2660 \\ \hline
			$L_x$ & 1554 \\ \hline
			$L_w$ & 0 \\ \hline
			$L_x'$ & 190800 \\ \hline
			$L_w'$ & 0 \\ \hline
			$M_v$ & $10^{-5}$ \\ \hline
			$\theta_w$ & 0 \\ \hline
		\end{tabular}
	\end{center}
\end{table}

\begin{table}[h]
	\caption{Eq.~\ref{eq:LEMPCChoosing} parameters from the second set of parameters for CSTR model in Table~\ref{tbl:Example3}.}\label{tbl:Example4}
	\begin{center}
		\begin{tabular}{cc}
			\textbf{Parameter} & \textbf{Value} \\ \hline
			$\rho_e'$ & 200.00  \\ \hline
			$\Delta$ & $1.40 \times 10^{-11}$ \\ \hline
			$\rho_s$ & 37.49 \\ \hline
			$\bar{\epsilon}_w$ & 0.0071 \\ \hline
			$\rho_{\min}$ & 45.092 \\ \hline
		\end{tabular}
	\end{center}
\end{table}

The maximum possible value of $\Delta$ from the case with $\rho = 200$ is about 2 orders of magnitude smaller than the maximum possible value of $\Delta$ for the case with $\rho = 1800$; this begs the question of whether a further reduction of $\rho$ may improve the situation (we note also that the discretization could play a role in this, which was not further explored in the preliminary analyses of this study).  We could consider $\rho = 20$ for which the parameters obtained via the method above and Eq.~\ref{eq:LEMPCChoosing} are provided in Tables~\ref{tbl:Example20}-\ref{tbl:Example20Param}.  In this case though $a_3$ is increased compared to Table~\ref{tbl:Example3} (at least among the points in the discretization used), $\rho$ is smaller, so that the maximum possible value of $\rho_s$ is smaller and therefore the negative term in Eq.~\ref{eq:LEMPCChoosing:Mode2} does not become as large as would be desired to lower $\Delta$.  In this case, the maximum possible value of $\Delta$ is $3.82 \times 10^{-10}$ h, which again is very small.

\begin{table}[h]
	\caption{Third set of parameters for CSTR model.}\label{tbl:Example20}
	\begin{center}
		\begin{tabular}{cc}
			\textbf{Parameter} & \textbf{Value} \\ \hline
			$\rho$ & 20  \\ \hline
			$a_1$ & 2.9 \\ \hline
			$a_2$ & 2001 \\ \hline
			$a_3$ & 11.15 \\ \hline
			$a_4$ & 5601 \\ \hline
			$M_f$ & 2294 \\ \hline
			$L_x$ & 1221 \\ \hline
			$L_w$ & 0 \\ \hline
			$L_x'$ & 126910 \\ \hline
			$L_w'$ & 0 \\ \hline
			$M_v$ & $10^{-5}$ \\ \hline
			$\theta_w$ & 0 \\ \hline
		\end{tabular}
	\end{center}
\end{table}

\begin{table}[h]
	\caption{Eq.~\ref{eq:LEMPCChoosing} parameters from the third set of parameters for CSTR model in Table~\ref{tbl:Example20}.}\label{tbl:Example20Param}
	\begin{center}
		\begin{tabular}{cc}
			\textbf{Parameter} & \textbf{Value} \\ \hline
			$\rho_e'$ & 20.00  \\ \hline
			$\Delta$ & $7.09 \times 10^{-11}$ \\ \hline
			$\rho_s$ & 11.11 \\ \hline
			$\bar{\epsilon}_w$ & 0.021 \\ \hline
			$\rho_{\min}$ & 13.93 \\ \hline
		\end{tabular}
	\end{center}
\end{table}

We see then that for all of the discretizations checked, across several orders of magnitude, decreasing the size of the stability region did not put the magnitude of $\Delta$ in a reasonable range for the selected for $h$, $V$, and $\alpha_i$, $i=1,2,3,4$.  This gives greater insight into Remark~\ref{rmk:ImptRmk}, which indicated that it is necessary to select $h$ and $V$ such that reasonable parameters can be obtained.  Future work could explore other functions $h$, $V$, and $\alpha_i$, $i=1,2,3,4$ for this process to see whether there exist any that could result in more reasonable values of $\Delta$ or not.  The results of this section also shed light on what changes could aid in making $\Delta$ larger (for example, it is seen above that a major reason why $\Delta$ is so small in each simulation is because $a_3$ is small compared to $a_2$ in each case and $\rho_s$ is limited in magnitude by $\rho$, causing the only negative term in Eq.~\ref{eq:LEMPCChoosing:Mode2} to be small, and then since the terms which multiply $\Delta$ are large for the given shape of $\Omega_{\rho}$, $\Delta$ must be small in each case to prevent the positive term containing $\Delta$ from overwhelming the negative term containing $\rho_s$ and preventing $\bar{\epsilon}_w$ from being positive as required by Eq.~\ref{eq:LEMPCChoosing:epsilonwBound}).  Though these results have not focused directly on cybersecurity of control systems, they give some indication of challenges that would be faced in working toward developing the control parameters of a cyberattack-resilient LEMPC meeting the theory in this work.  They indicate that meeting the theory requires better strategies than that used in this section for preventing vulnerabilities.

\section{Conclusion}

This work extended the control/detection strategies developed in \cite{oyama2020integrated} to handle actuator attacks and cases where actuator and sensor attacks can occur simultaneously. For the event where multiple attacks are considered, several integrated control/detection frameworks that pair detection strategies designed for single attack types events were investigated.  It was demonstrated that certain combinations of the detection strategies can be ineffective to flag both types of cyberattacks evaluated in this work, while others create a cyberattack-resilient structure that enables detection of individual or simultaneous sensor and actuator attack types while ensuring safe operation even if undetected attacks occur. In particular, the pairing of Detection Strategies 1-A and 3-S, and the pairing of Detection Strategies 2-A and 3-S, were shown to be resilient against both types of cyberattacks.  The major benefits of these methods are that multiple attack scenarios can be discovered, which adds a layer of protection, and closed-loop stability is guaranteed if an attack policy is not flagged by these two-piece structures. Finally, to characterize the fundamental nature of sensor and actuator attacks, we mathematically defined the concept of cyberattack discoverability in the context of process control and stealthy attack policies, which may provide insights for future detection strategy development.  Potential practical challenges with designing LEMPC's meeting theoretical conditions, a precursor study for getting the parameters of cyberattack-resilient LEMPC's, elucidated some of the potential challenges with obtaining the parameters meeting the theory that could be addressed in future work.

%It uses the capabilities of the Detection Strategy 3-S to identify false sensor measurements via redundant state estimates and it can concomitantly check whether or not incorrect actuator outputs are being applied to the process using Detection Strategy 1-A.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\section{Conflict of Interest Statement}
%All financial, commercial or other relationships that might be perceived by the academic community as representing a potential conflict of interest must be disclosed. If no such relationship exists, authors will be asked to confirm the following statement: 

The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.

\section{Author Contributions}
Henrique Oyama aided in writing the manuscript and developing the concepts in the manuscript. Dominic Messina developed most of the codes for getting parameters of an LEMPC. Helen Durand supervised the work and aided in writing and editing the manuscript and conceptualizing the methodology.  Keshav Kasturi Rangan aided in development of the actuator cyberattack-handling procedure. 

\section{Funding}
Financial support from the Air Force Office of Scientific Research (award number FA9550-19-1-0059), National Science Foundation CNS-1932026 and CBET-1839675, and Wayne State University is gratefully acknowledged.

\section{Acknowledgments}
We would like to thank the reviewers, who provided tremendous help and insights in their comments that aided us greatly in developing the final version of this manuscript.

\section{Data Availability Statement}
The codes generated for this study will be uploaded to: \\ https://durand.eng.wayne.edu/PublicationResources/index.html.
% Please see the availability of data guidelines for more information, at https://www.frontiersin.org/about/author-guidelines#AvailabilityofData

\bibliographystyle{frontiersinSCNS_ENG_HUMS} % for Science, Engineering and Humanities and Social Sciences articles, for Humanities and Social Sciences articles please include page numbers in the in-text citations
%\bibliographystyle{frontiersinHLTH&FPHY} % for Health, Physics and Mathematics articles
\bibliography{DurandCPSBib}

%%% Make sure to upload the bib file along with the tex file and PDF
%%% Please see the test.bib file for some examples of references

\end{document}
